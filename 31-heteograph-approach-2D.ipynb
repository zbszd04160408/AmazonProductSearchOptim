{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25544,"status":"ok","timestamp":1651957614613,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"HLUA9V2uyAyL","outputId":"c38bb2b3-ae41-4786-a0c3-ed8d8a09d8a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Othercomputers/Vivian's MacBook Pro 2021/DS5720/FinalProject\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","cur_path = \"./drive/Othercomputers/Vivian's MacBook Pro 2021/DS5720/FinalProject\"\n","os.chdir(cur_path)\n","!pwd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27094,"status":"ok","timestamp":1651957641696,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"eZt_o-qjx0ns","outputId":"47fe0417-7519-4cf2-8b9b-fd660da44f6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dgl\n","  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 32.3 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n","Installing collected packages: dgl\n","Successfully installed dgl-0.6.1\n","\u001b[33mWARNING: Skipping umap as it is not installed.\u001b[0m\n","Collecting umap-learn\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n","Collecting pynndescent>=0.5\n","  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.64.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n","Building wheels for collected packages: umap-learn, pynndescent\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=640cd8aa656110d8c9da2e8627fd714532284d61964bbd9371a26ca6d253450d\n","  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=af86f3a4bd96598f4895c1aa64d554b829cd484bbbe51fb68b951a8511649d99\n","  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n","Successfully built umap-learn pynndescent\n","Installing collected packages: pynndescent, umap-learn\n","Successfully installed pynndescent-0.5.6 umap-learn-0.5.3\n","Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Using backend: pytorch\n"]}],"source":["! pip install dgl\n","! pip uninstall umap\n","! pip install umap-learn\n","import dgl\n","import torch\n","import pandas as pd \n","import umap.umap_ as umap"]},{"cell_type":"code","source":["reducer = umap.UMAP()"],"metadata":{"id":"VxhGpTyo1HUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BBiHzbsPr-CI"},"source":["# 1. Data Import"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KA7FwfwGmx8-","executionInfo":{"status":"ok","timestamp":1651957687800,"user_tz":300,"elapsed":46109,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["task = pd.read_csv(\"./data/task2/train-v0.2.csv\")\n","mega_table = pd.read_csv(\"./data/product_catalogue-v0.2.csv\")\n","merged_df = pd.merge(task, mega_table, how = 'left', left_on = ['product_id', 'query_locale'], right_on = ['product_id', 'product_locale'])\n","# query_embed = pd.read_csv(\"./data/us50k_query_embedding.csv\")\n","# product_title_embed = pd.read_csv(\"./data/us50k_product_title_embedding.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gIk7nG3X6qFj","executionInfo":{"status":"ok","timestamp":1651957690371,"user_tz":300,"elapsed":2585,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["merged_df = merged_df[merged_df['product_locale'] == 'us']\n","merged_df = merged_df.fillna('')"]},{"cell_type":"markdown","metadata":{"id":"5i0_7sPXzTK4"},"source":["## 1.1 Get nodes"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":2078,"status":"ok","timestamp":1651957698002,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"D5HE_xW87Igb","outputId":"1feb5de6-ede6-451f-875a-40eed697fb60"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       query_id                           Query                combined\n","0             0                   revent 80 cfm  [5.9194746, 11.776406]\n","1             1       # 2 pencils not sharpened  [1.6408201, 12.353349]\n","2             2                # do not disturb  [1.6160169, 12.384887]\n","3             3                      # mom life  [11.277119, 5.4072776]\n","4             4       # sharp not hashtag shirt    [2.64626, 11.746464]\n","...         ...                             ...                     ...\n","68134     68134                    tach adapter  [10.134178, 11.506582]\n","68135     68135  the armorer vintage collection    [9.686235, 5.650066]\n","68136     68136   trojan magnum condoms for men    [5.05511, 6.2999525]\n","68137     68137         white adirondack chairs  [10.901912, 7.3619223]\n","68138     68138            zephyr polishing kit    [9.879838, 9.675754]\n","\n","[68139 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-9d85e30d-78d4-490e-9142-68c169f78966\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>Query</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[5.9194746, 11.776406]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td># 2 pencils not sharpened</td>\n","      <td>[1.6408201, 12.353349]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td># do not disturb</td>\n","      <td>[1.6160169, 12.384887]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td># mom life</td>\n","      <td>[11.277119, 5.4072776]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td># sharp not hashtag shirt</td>\n","      <td>[2.64626, 11.746464]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>68134</th>\n","      <td>68134</td>\n","      <td>tach adapter</td>\n","      <td>[10.134178, 11.506582]</td>\n","    </tr>\n","    <tr>\n","      <th>68135</th>\n","      <td>68135</td>\n","      <td>the armorer vintage collection</td>\n","      <td>[9.686235, 5.650066]</td>\n","    </tr>\n","    <tr>\n","      <th>68136</th>\n","      <td>68136</td>\n","      <td>trojan magnum condoms for men</td>\n","      <td>[5.05511, 6.2999525]</td>\n","    </tr>\n","    <tr>\n","      <th>68137</th>\n","      <td>68137</td>\n","      <td>white adirondack chairs</td>\n","      <td>[10.901912, 7.3619223]</td>\n","    </tr>\n","    <tr>\n","      <th>68138</th>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[9.879838, 9.675754]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>68139 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d85e30d-78d4-490e-9142-68c169f78966')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9d85e30d-78d4-490e-9142-68c169f78966 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9d85e30d-78d4-490e-9142-68c169f78966');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["query_embed = pd.read_csv(\"./data/query_2d_embedding.csv\")\n","query_embed = pd.merge(query_embed, pd.DataFrame(merged_df['query'].unique(), columns=['Query']), on = 'Query')\n","query_embed.insert(0, 'query_id', range(0, 0 + len(query_embed)))\n","query_embed['combined']=query_embed.drop(columns=['query_id', 'Query']).values.tolist()\n","query_embed = query_embed[['query_id', 'Query', 'combined']]\n","query_embed"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":35532,"status":"ok","timestamp":1651957735063,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"YCroXLcK1mh4","outputId":"701a8200-b412-4dc4-ef96-a099a29decce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        product_id                                            Product  \\\n","0                0  Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...   \n","1                1  Broan Very Quiet Ceiling Bathroom Exhaust Fan,...   \n","2                2  Delta BreezSignature VFB25ACH 80 CFM Exhaust B...   \n","3                3  Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...   \n","4                4  Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...   \n","...            ...                                                ...   \n","856998      856998  VY4AOS2 My Hero Academia That Wasn't Very Plus...   \n","856999      856999  Phoetya Women's My Hero Academia Hoodie That's...   \n","857000      857000  Defrosting Tray (Largest Size) for Rapid thaw ...   \n","857001      857001  Danoib Fast Defrosting Tray Rapid Thaw Plate M...   \n","857002      857002  Quadow Defrost Tray,Easy Thaw Tray Defrost Foo...   \n","\n","                       combined  \n","0         [5.493239, 3.9107287]  \n","1         [6.254356, 3.6619837]  \n","2          [8.612531, 2.565822]  \n","3         [18.71445, 4.8168015]  \n","4         [10.318963, 1.769214]  \n","...                         ...  \n","856998   [-3.8597538, 6.813416]  \n","856999  [-4.4385715, 6.5669465]  \n","857000    [7.1394815, 8.121607]  \n","857001    [5.7838974, 8.693619]  \n","857002  [-0.30754632, 9.287247]  \n","\n","[857003 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-f41e42f1-fe10-4d81-8763-c6389a88c0f2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>Product</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>[5.493239, 3.9107287]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>[6.254356, 3.6619837]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>[8.612531, 2.565822]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>[18.71445, 4.8168015]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>[10.318963, 1.769214]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>856998</th>\n","      <td>856998</td>\n","      <td>VY4AOS2 My Hero Academia That Wasn't Very Plus...</td>\n","      <td>[-3.8597538, 6.813416]</td>\n","    </tr>\n","    <tr>\n","      <th>856999</th>\n","      <td>856999</td>\n","      <td>Phoetya Women's My Hero Academia Hoodie That's...</td>\n","      <td>[-4.4385715, 6.5669465]</td>\n","    </tr>\n","    <tr>\n","      <th>857000</th>\n","      <td>857000</td>\n","      <td>Defrosting Tray (Largest Size) for Rapid thaw ...</td>\n","      <td>[7.1394815, 8.121607]</td>\n","    </tr>\n","    <tr>\n","      <th>857001</th>\n","      <td>857001</td>\n","      <td>Danoib Fast Defrosting Tray Rapid Thaw Plate M...</td>\n","      <td>[5.7838974, 8.693619]</td>\n","    </tr>\n","    <tr>\n","      <th>857002</th>\n","      <td>857002</td>\n","      <td>Quadow Defrost Tray,Easy Thaw Tray Defrost Foo...</td>\n","      <td>[-0.30754632, 9.287247]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>857003 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f41e42f1-fe10-4d81-8763-c6389a88c0f2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f41e42f1-fe10-4d81-8763-c6389a88c0f2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f41e42f1-fe10-4d81-8763-c6389a88c0f2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["product_title_embed = pd.read_csv(\"./data/product_2d_embedding.csv\")\n","product_title_embed = product_title_embed[:857004]\n","merged_df['product'] = merged_df['product_title'] +  merged_df['product_description'] +  merged_df['product_bullet_point'] +  merged_df['product_brand'] +  merged_df['product_color_name']\n","product_title_embed = pd.merge(product_title_embed, pd.DataFrame(merged_df['product'].unique(), columns=['Product']), on = 'Product')\n","product_title_embed.insert(0, 'product_id', range(0, 0 + len(product_title_embed)))\n","product_title_embed['combined']=product_title_embed.drop(columns=['product_id', 'Product']).values.tolist()\n","product_title_embed = product_title_embed[['product_id', 'Product', 'combined']]\n","product_title_embed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":4757,"status":"error","timestamp":1651883835967,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"ltouHFYRQ8pu","outputId":"eb9ef261-a19d-49fc-e15f-662d03a346e8"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f44bfc040cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproduct_title_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Product'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mproduct_title_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Product'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'combined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""]}],"source":["product_title_embed = pd.merge(product_title_embed, pd.DataFrame(merged_df['product'].unique(), columns=['Product']), on = 'Product').drop(columns=['Unnamed: 0'])\n","product_title_embed.insert(0, 'product_id', range(0, 0 + len(product_title_embed)))\n","product_title_embed['combined']=product_title_embed.drop(columns=['product_id', 'Product']).values.tolist()\n","product_title_embed = product_title_embed[['product_id', 'Product', 'combined']]\n","product_title_embed"]},{"cell_type":"markdown","metadata":{"id":"X2Nc3vOS4sTY"},"source":["## 1.2 Get edges"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GQHv1R--2mDf","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1651957760509,"user_tz":300,"elapsed":4947,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"ef9e6e23-c427-45a4-8067-c6ce0ceb42de"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                        query  \\\n","0               revent 80 cfm   \n","1               revent 80 cfm   \n","2               revent 80 cfm   \n","3               revent 80 cfm   \n","4               revent 80 cfm   \n","...                       ...   \n","1272622  zephyr polishing kit   \n","1272623  zephyr polishing kit   \n","1272624  zephyr polishing kit   \n","1272625  zephyr polishing kit   \n","1272626  zephyr polishing kit   \n","\n","                                                   product  esci_label  \\\n","0        Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...  irrelevant   \n","1        Broan Very Quiet Ceiling Bathroom Exhaust Fan,...       exact   \n","2        Delta BreezSignature VFB25ACH 80 CFM Exhaust B...       exact   \n","3        Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...       exact   \n","4        Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...       exact   \n","...                                                    ...         ...   \n","1272622  Buffing Wheel Rake Remove Residual Compounds/M...  irrelevant   \n","1272623  Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...  complement   \n","1272624  7 Inch Polishing Pads Kit Car Foam Sponge Pads...  substitute   \n","1272625  Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...  substitute   \n","1272626  KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...       exact   \n","\n","         query_id                 Query          combined_query  product_id  \\\n","0               0         revent 80 cfm  [5.9194746, 11.776406]         0.0   \n","1               0         revent 80 cfm  [5.9194746, 11.776406]         1.0   \n","2               0         revent 80 cfm  [5.9194746, 11.776406]         2.0   \n","3               0         revent 80 cfm  [5.9194746, 11.776406]         3.0   \n","4               0         revent 80 cfm  [5.9194746, 11.776406]         4.0   \n","...           ...                   ...                     ...         ...   \n","1272622     68138  zephyr polishing kit    [9.879838, 9.675754]    766998.0   \n","1272623     68138  zephyr polishing kit    [9.879838, 9.675754]    766999.0   \n","1272624     68138  zephyr polishing kit    [9.879838, 9.675754]    804146.0   \n","1272625     68138  zephyr polishing kit    [9.879838, 9.675754]    767000.0   \n","1272626     68138  zephyr polishing kit    [9.879838, 9.675754]    767001.0   \n","\n","                                                   Product  \\\n","0        Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...   \n","1        Broan Very Quiet Ceiling Bathroom Exhaust Fan,...   \n","2        Delta BreezSignature VFB25ACH 80 CFM Exhaust B...   \n","3        Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...   \n","4        Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...   \n","...                                                    ...   \n","1272622  Buffing Wheel Rake Remove Residual Compounds/M...   \n","1272623  Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...   \n","1272624  7 Inch Polishing Pads Kit Car Foam Sponge Pads...   \n","1272625  Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...   \n","1272626  KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...   \n","\n","                combined_product  \n","0          [5.493239, 3.9107287]  \n","1          [6.254356, 3.6619837]  \n","2           [8.612531, 2.565822]  \n","3          [18.71445, 4.8168015]  \n","4          [10.318963, 1.769214]  \n","...                          ...  \n","1272622    [4.34961, -0.8595931]  \n","1272623    [9.486582, 1.3005674]  \n","1272624  [-0.16398527, 3.089978]  \n","1272625  [5.8060174, -1.1119521]  \n","1272626  [5.9442663, -1.0682176]  \n","\n","[1200961 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-74015da8-b3a2-42d8-b442-8c56a89321ad\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query</th>\n","      <th>product</th>\n","      <th>esci_label</th>\n","      <th>query_id</th>\n","      <th>Query</th>\n","      <th>combined_query</th>\n","      <th>product_id</th>\n","      <th>Product</th>\n","      <th>combined_product</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>revent 80 cfm</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>irrelevant</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[5.9194746, 11.776406]</td>\n","      <td>0.0</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>[5.493239, 3.9107287]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>revent 80 cfm</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[5.9194746, 11.776406]</td>\n","      <td>1.0</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>[6.254356, 3.6619837]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>revent 80 cfm</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[5.9194746, 11.776406]</td>\n","      <td>2.0</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>[8.612531, 2.565822]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>revent 80 cfm</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[5.9194746, 11.776406]</td>\n","      <td>3.0</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>[18.71445, 4.8168015]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>revent 80 cfm</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[5.9194746, 11.776406]</td>\n","      <td>4.0</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>[10.318963, 1.769214]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1272622</th>\n","      <td>zephyr polishing kit</td>\n","      <td>Buffing Wheel Rake Remove Residual Compounds/M...</td>\n","      <td>irrelevant</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[9.879838, 9.675754]</td>\n","      <td>766998.0</td>\n","      <td>Buffing Wheel Rake Remove Residual Compounds/M...</td>\n","      <td>[4.34961, -0.8595931]</td>\n","    </tr>\n","    <tr>\n","      <th>1272623</th>\n","      <td>zephyr polishing kit</td>\n","      <td>Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...</td>\n","      <td>complement</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[9.879838, 9.675754]</td>\n","      <td>766999.0</td>\n","      <td>Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...</td>\n","      <td>[9.486582, 1.3005674]</td>\n","    </tr>\n","    <tr>\n","      <th>1272624</th>\n","      <td>zephyr polishing kit</td>\n","      <td>7 Inch Polishing Pads Kit Car Foam Sponge Pads...</td>\n","      <td>substitute</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[9.879838, 9.675754]</td>\n","      <td>804146.0</td>\n","      <td>7 Inch Polishing Pads Kit Car Foam Sponge Pads...</td>\n","      <td>[-0.16398527, 3.089978]</td>\n","    </tr>\n","    <tr>\n","      <th>1272625</th>\n","      <td>zephyr polishing kit</td>\n","      <td>Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...</td>\n","      <td>substitute</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[9.879838, 9.675754]</td>\n","      <td>767000.0</td>\n","      <td>Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...</td>\n","      <td>[5.8060174, -1.1119521]</td>\n","    </tr>\n","    <tr>\n","      <th>1272626</th>\n","      <td>zephyr polishing kit</td>\n","      <td>KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...</td>\n","      <td>exact</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[9.879838, 9.675754]</td>\n","      <td>767001.0</td>\n","      <td>KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...</td>\n","      <td>[5.9442663, -1.0682176]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1200961 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74015da8-b3a2-42d8-b442-8c56a89321ad')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-74015da8-b3a2-42d8-b442-8c56a89321ad button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-74015da8-b3a2-42d8-b442-8c56a89321ad');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["cleaned_df = merged_df[merged_df['product_locale'] == 'us'][['query', 'product', 'esci_label']]\n","temp_merged = pd.merge(cleaned_df, query_embed, left_on = ['query'], right_on = ['Query'], how = 'left')\n","total_index = pd.merge(temp_merged, product_title_embed, left_on = ['product'], right_on = ['Product'], how = 'left', suffixes = ('_query', '_product') )\n","total_index = total_index.dropna()\n","# total_index\n","query_idx = total_index[['query_id', 'query', 'combined_query', 'esci_label']]\n","product_idx = total_index[['product_id', 'product', 'combined_product', 'esci_label']]\n","total_index"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"PyOobiRHBOld","executionInfo":{"status":"ok","timestamp":1651957762245,"user_tz":300,"elapsed":1740,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["i_edge_q = query_idx[query_idx['esci_label'] == 'irrelevant']\n","i_edge_p = product_idx[product_idx['esci_label'] == 'irrelevant']\n","i_edge_idx = [i_edge_q['query_id'].tolist(), i_edge_p['product_id'].tolist()]\n","\n","e_edge_q = query_idx[query_idx['esci_label'] == 'exact']\n","e_edge_p = product_idx[product_idx['esci_label'] == 'exact']\n","e_edge_idx = [e_edge_q['query_id'].tolist(), e_edge_p['product_id'].tolist()]\n","\n","c_edge_q = query_idx[query_idx['esci_label'] == 'complement']\n","c_edge_p = product_idx[product_idx['esci_label'] == 'complement']\n","c_edge_idx = [c_edge_q['query_id'].tolist(), c_edge_p['product_id'].tolist()]\n","\n","\n","s_edge_q = query_idx[query_idx['esci_label'] == 'substitute']\n","s_edge_p = product_idx[product_idx['esci_label'] == 'substitute']\n","s_edge_idx = [s_edge_q['query_id'].tolist(), s_edge_p['product_id'].tolist()]\n"]},{"cell_type":"markdown","metadata":{"id":"vKlnJGYY4uOK"},"source":["# 2. Create Graph"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ClMfrGUGCCbE","executionInfo":{"status":"ok","timestamp":1651957762246,"user_tz":300,"elapsed":6,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["graph_data = {\n","   ('query', 'irrelevant', 'product'): (torch.tensor(i_edge_idx[0], dtype=torch.int32), torch.tensor(i_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'exact', 'product'): (torch.tensor(e_edge_idx[0], dtype=torch.int32), torch.tensor(e_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'complement', 'product'): (torch.tensor(c_edge_idx[0], dtype=torch.int32), torch.tensor(c_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'substitute', 'product'): (torch.tensor(s_edge_idx[0], dtype=torch.int32), torch.tensor(s_edge_idx[1], dtype=torch.int32))\n","}\n","qp_graph = dgl.heterograph(graph_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":959,"status":"ok","timestamp":1651957826793,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"9nKvaNwv4w42","outputId":"5b4bc724-56ca-47c4-db83-af929eef60dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Graph(num_nodes={'product': 857003, 'query': 68139},\n","      num_edges={('query', 'complement', 'product'): 26648, ('query', 'exact', 'product'): 823409, ('query', 'irrelevant', 'product'): 107122, ('query', 'substitute', 'product'): 243782},\n","      metagraph=[('query', 'product', 'complement'), ('query', 'product', 'exact'), ('query', 'product', 'irrelevant'), ('query', 'product', 'substitute')])"]},"metadata":{},"execution_count":10}],"source":["qp_graph"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"m6TOHP4lRhQX","executionInfo":{"status":"ok","timestamp":1651957828806,"user_tz":300,"elapsed":7,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["qp_graph.nodes['query'].data['embed'] = torch.tensor(query_embed['combined'].tolist())\n","qp_graph.nodes['product'].data['embed'] = torch.tensor(product_title_embed['combined'].tolist())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1651099283487,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"eiK-aQkgK0-T","outputId":"c52d0a17-807f-42d9-fcee-1174d2951a15"},"outputs":[{"data":{"text/plain":["388"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","\n","del task\n","del mega_table\n","del merged_df\n","del cleaned_df\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"a4yINMxKUMc-"},"source":["# 3. Train a model"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"lO5glZJjVhtP","executionInfo":{"status":"ok","timestamp":1651957832291,"user_tz":300,"elapsed":629,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["import dgl.nn as dglnn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class RGCN(nn.Module):\n","    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n","        super().__init__()\n","\n","        self.conv1 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(in_feats, hid_feats)\n","            for rel in rel_names}, aggregate='sum')\n","        self.conv2 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(hid_feats, out_feats)\n","            for rel in rel_names}, aggregate='sum')\n","\n","    def forward(self, graph, inputs):\n","        # inputs are features of nodes\n","        h = self.conv1(graph, inputs)\n","        h = {k: F.relu(v) for k, v in h.items()}\n","        h = self.conv2(graph, h)\n","        return h\n","\n","class HeteroMLPPredictor(nn.Module):\n","    def __init__(self, in_dims, n_classes):\n","        super().__init__()\n","        self.W = nn.Linear(in_dims * 2, n_classes)\n","\n","    def apply_edges(self, edges):\n","        x = torch.cat([edges.src['embed'], edges.dst['embed']], 1)\n","        y = self.W(x)\n","        return {'score': y}\n","\n","    def forward(self, graph, h):\n","        # h contains the node representations for each edge type computed from\n","        # the GNN for heterogeneous graphs defined in the node classification\n","        # section (Section 5.1).\n","        with graph.local_scope():\n","            graph.ndata['h'] = h   # assigns 'h' of all node types in one shot\n","            graph.apply_edges(self.apply_edges)\n","            return graph.edata['score']\n","\n","class Model(nn.Module):\n","    def __init__(self, in_features, hidden_features, out_features, rel_names):\n","        super().__init__()\n","        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n","        self.pred = HeteroMLPPredictor(out_features, len(rel_names))\n","    def forward(self, g, x, dec_graph):\n","        h = self.sage(g, x)\n","        return self.pred(dec_graph, h)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651957835740,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"y1zgKw8NUOMp","outputId":"9de0870c-7f6d-4e8c-b24f-c1ef98edaaad"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]}],"source":["dec_graph = qp_graph['query', :, 'product']\n","edge_label = torch.tensor(dec_graph.edata[dgl.ETYPE], dtype=torch.long)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"x4m9gDuGbWmG","executionInfo":{"status":"ok","timestamp":1651957838744,"user_tz":300,"elapsed":3006,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["dec_graph.edata['train_mask'] = torch.zeros(dec_graph.num_edges('complement+exact+irrelevant+substitute'), dtype=torch.bool).bernoulli(0.7)\n","dec_graph.edata['val_mask'] = torch.tensor([not x for x in dec_graph.edata['train_mask'] ], dtype=torch.bool)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"4Jj9pateWQ8x","executionInfo":{"status":"ok","timestamp":1651957838745,"user_tz":300,"elapsed":6,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["train_mask = dec_graph.edata['train_mask']\n","val_mask = dec_graph.edata['val_mask']"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3172,"status":"ok","timestamp":1651957842455,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"SLKfCjd7rRiq","outputId":"d6c0b8b4-10f0-4bd7-80a5-f256d97df209"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 39.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 40.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 45.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 92 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 133 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 143 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 174 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 184 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 194 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 215 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 225 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 235 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 245 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 256 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 266 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 276 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 286 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 296 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 307 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 317 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 327 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 337 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 348 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 358 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 368 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 378 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 389 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 399 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409 kB 29.1 MB/s \n","\u001b[?25hCollecting pyDeprecate==0.3.*\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n","Installing collected packages: pyDeprecate, torchmetrics\n","Successfully installed pyDeprecate-0.3.2 torchmetrics-0.8.2\n"]}],"source":["! pip install torchmetrics"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":630412,"status":"ok","timestamp":1651959312399,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"7nkUVsnuV_bD","outputId":"d83881b0-92a9-4bba-a5ba-543f40e2cfc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Training Loss = 6.772210597991943\n","Accuracy =  0.09451412409543991 F1 weighted =  0.06095336005091667 F1 macro =  0.09985093772411346\n","Epoch: 1, Training Loss = 6.736729621887207\n","Epoch: 2, Training Loss = 6.7012619972229\n","Epoch: 3, Training Loss = 6.66580867767334\n","Epoch: 4, Training Loss = 6.630366802215576\n","Epoch: 5, Training Loss = 6.594939231872559\n","Epoch: 6, Training Loss = 6.559526443481445\n","Epoch: 7, Training Loss = 6.52412748336792\n","Epoch: 8, Training Loss = 6.488742828369141\n","Epoch: 9, Training Loss = 6.45337438583374\n","Epoch: 10, Training Loss = 6.418020725250244\n","Accuracy =  0.0951794981956482 F1 weighted =  0.06110762804746628 F1 macro =  0.10007606446743011\n","Epoch: 11, Training Loss = 6.382682800292969\n","Epoch: 12, Training Loss = 6.3473591804504395\n","Epoch: 13, Training Loss = 6.312052249908447\n","Epoch: 14, Training Loss = 6.276761531829834\n","Epoch: 15, Training Loss = 6.2414870262146\n","Epoch: 16, Training Loss = 6.206228256225586\n","Epoch: 17, Training Loss = 6.170986175537109\n","Epoch: 18, Training Loss = 6.135760307312012\n","Epoch: 19, Training Loss = 6.100551128387451\n","Epoch: 20, Training Loss = 6.065358638763428\n","Accuracy =  0.09552749991416931 F1 weighted =  0.06112124025821686 F1 macro =  0.10013943165540695\n","Epoch: 21, Training Loss = 6.030182361602783\n","Epoch: 22, Training Loss = 5.995022296905518\n","Epoch: 23, Training Loss = 5.959878921508789\n","Epoch: 24, Training Loss = 5.924752235412598\n","Epoch: 25, Training Loss = 5.889642715454102\n","Epoch: 26, Training Loss = 5.854548454284668\n","Epoch: 27, Training Loss = 5.819471836090088\n","Epoch: 28, Training Loss = 5.784412384033203\n","Epoch: 29, Training Loss = 5.749371528625488\n","Epoch: 30, Training Loss = 5.714346885681152\n","Accuracy =  0.09554699063301086 F1 weighted =  0.06103988736867905 F1 macro =  0.1001153364777565\n","Epoch: 31, Training Loss = 5.679340362548828\n","Epoch: 32, Training Loss = 5.644351959228516\n","Epoch: 33, Training Loss = 5.6093831062316895\n","Epoch: 34, Training Loss = 5.574431419372559\n","Epoch: 35, Training Loss = 5.539500713348389\n","Epoch: 36, Training Loss = 5.504589557647705\n","Epoch: 37, Training Loss = 5.469699382781982\n","Epoch: 38, Training Loss = 5.434828758239746\n","Epoch: 39, Training Loss = 5.3999810218811035\n","Epoch: 40, Training Loss = 5.36515474319458\n","Accuracy =  0.09537994861602783 F1 weighted =  0.06089768186211586 F1 macro =  0.10009026527404785\n","Epoch: 41, Training Loss = 5.330351829528809\n","Epoch: 42, Training Loss = 5.295572757720947\n","Epoch: 43, Training Loss = 5.2608160972595215\n","Epoch: 44, Training Loss = 5.226083755493164\n","Epoch: 45, Training Loss = 5.191377639770508\n","Epoch: 46, Training Loss = 5.156696796417236\n","Epoch: 47, Training Loss = 5.122043609619141\n","Epoch: 48, Training Loss = 5.087418079376221\n","Epoch: 49, Training Loss = 5.052819728851318\n","Epoch: 50, Training Loss = 5.018250942230225\n","Accuracy =  0.09490666538476944 F1 weighted =  0.060644760727882385 F1 macro =  0.09978176653385162\n","Epoch: 51, Training Loss = 4.983712673187256\n","Epoch: 52, Training Loss = 4.949204921722412\n","Epoch: 53, Training Loss = 4.914730072021484\n","Epoch: 54, Training Loss = 4.880287170410156\n","Epoch: 55, Training Loss = 4.8458781242370605\n","Epoch: 56, Training Loss = 4.81150484085083\n","Epoch: 57, Training Loss = 4.777166843414307\n","Epoch: 58, Training Loss = 4.7428669929504395\n","Epoch: 59, Training Loss = 4.708605766296387\n","Epoch: 60, Training Loss = 4.674383640289307\n","Accuracy =  0.09454753249883652 F1 weighted =  0.06049804762005806 F1 macro =  0.09952408075332642\n","Epoch: 61, Training Loss = 4.640203952789307\n","Epoch: 62, Training Loss = 4.6060662269592285\n","Epoch: 63, Training Loss = 4.5719733238220215\n","Epoch: 64, Training Loss = 4.537925720214844\n","Epoch: 65, Training Loss = 4.503925323486328\n","Epoch: 66, Training Loss = 4.469974040985107\n","Epoch: 67, Training Loss = 4.436074733734131\n","Epoch: 68, Training Loss = 4.40222692489624\n","Epoch: 69, Training Loss = 4.368432998657227\n","Epoch: 70, Training Loss = 4.334696292877197\n","Accuracy =  0.09467559307813644 F1 weighted =  0.061156440526247025 F1 macro =  0.09959335625171661\n","Epoch: 71, Training Loss = 4.301018714904785\n","Epoch: 72, Training Loss = 4.267400741577148\n","Epoch: 73, Training Loss = 4.233846187591553\n","Epoch: 74, Training Loss = 4.200356960296631\n","Epoch: 75, Training Loss = 4.166934967041016\n","Epoch: 76, Training Loss = 4.1335835456848145\n","Epoch: 77, Training Loss = 4.100304126739502\n","Epoch: 78, Training Loss = 4.067101001739502\n","Epoch: 79, Training Loss = 4.033975124359131\n","Epoch: 80, Training Loss = 4.000930309295654\n","Accuracy =  0.09605646133422852 F1 weighted =  0.06426284462213516 F1 macro =  0.10059061646461487\n","Epoch: 81, Training Loss = 3.9679696559906006\n","Epoch: 82, Training Loss = 3.93509578704834\n","Epoch: 83, Training Loss = 3.9023122787475586\n","Epoch: 84, Training Loss = 3.869621753692627\n","Epoch: 85, Training Loss = 3.8370277881622314\n","Epoch: 86, Training Loss = 3.8045339584350586\n","Epoch: 87, Training Loss = 3.7721433639526367\n","Epoch: 88, Training Loss = 3.7398602962493896\n","Epoch: 89, Training Loss = 3.707688093185425\n","Epoch: 90, Training Loss = 3.6756300926208496\n","Accuracy =  0.09943623840808868 F1 weighted =  0.07148071378469467 F1 macro =  0.10300987958908081\n","Epoch: 91, Training Loss = 3.643691301345825\n","Epoch: 92, Training Loss = 3.611874580383301\n","Epoch: 93, Training Loss = 3.5801846981048584\n","Epoch: 94, Training Loss = 3.5486247539520264\n","Epoch: 95, Training Loss = 3.5172007083892822\n","Epoch: 96, Training Loss = 3.4859156608581543\n","Epoch: 97, Training Loss = 3.4547739028930664\n","Epoch: 98, Training Loss = 3.423780679702759\n","Epoch: 99, Training Loss = 3.392939329147339\n","Epoch: 100, Training Loss = 3.362255096435547\n","Accuracy =  0.10692242532968521 F1 weighted =  0.0867568626999855 F1 macro =  0.10839570313692093\n","Epoch: 101, Training Loss = 3.331733465194702\n","Epoch: 102, Training Loss = 3.301377058029175\n","Epoch: 103, Training Loss = 3.2711925506591797\n","Epoch: 104, Training Loss = 3.241183042526245\n","Epoch: 105, Training Loss = 3.2113542556762695\n","Epoch: 106, Training Loss = 3.1817102432250977\n","Epoch: 107, Training Loss = 3.152256727218628\n","Epoch: 108, Training Loss = 3.122997999191284\n","Epoch: 109, Training Loss = 3.0939385890960693\n","Epoch: 110, Training Loss = 3.0650827884674072\n","Accuracy =  0.11990144848823547 F1 weighted =  0.11258414387702942 F1 macro =  0.11731625348329544\n","Epoch: 111, Training Loss = 3.0364365577697754\n","Epoch: 112, Training Loss = 3.0080034732818604\n","Epoch: 113, Training Loss = 2.9797885417938232\n","Epoch: 114, Training Loss = 2.951796531677246\n","Epoch: 115, Training Loss = 2.9240317344665527\n","Epoch: 116, Training Loss = 2.896498918533325\n","Epoch: 117, Training Loss = 2.86920166015625\n","Epoch: 118, Training Loss = 2.8421449661254883\n","Epoch: 119, Training Loss = 2.8153326511383057\n","Epoch: 120, Training Loss = 2.788768768310547\n","Accuracy =  0.13886329531669617 F1 weighted =  0.14864656329154968 F1 macro =  0.12954887747764587\n","Epoch: 121, Training Loss = 2.762458324432373\n","Epoch: 122, Training Loss = 2.7364039421081543\n","Epoch: 123, Training Loss = 2.7106101512908936\n","Epoch: 124, Training Loss = 2.685080051422119\n","Epoch: 125, Training Loss = 2.6598172187805176\n","Epoch: 126, Training Loss = 2.6348252296447754\n","Epoch: 127, Training Loss = 2.6101067066192627\n","Epoch: 128, Training Loss = 2.585665464401245\n","Epoch: 129, Training Loss = 2.5615036487579346\n","Epoch: 130, Training Loss = 2.5376243591308594\n","Accuracy =  0.164826899766922 F1 weighted =  0.19403685629367828 F1 macro =  0.1444884091615677\n","Epoch: 131, Training Loss = 2.514030694961548\n","Epoch: 132, Training Loss = 2.4907236099243164\n","Epoch: 133, Training Loss = 2.467705726623535\n","Epoch: 134, Training Loss = 2.4449799060821533\n","Epoch: 135, Training Loss = 2.422546863555908\n","Epoch: 136, Training Loss = 2.400408983230591\n","Epoch: 137, Training Loss = 2.3785665035247803\n","Epoch: 138, Training Loss = 2.3570215702056885\n","Epoch: 139, Training Loss = 2.335775136947632\n","Epoch: 140, Training Loss = 2.3148274421691895\n","Accuracy =  0.19459624588489532 F1 weighted =  0.2399609088897705 F1 macro =  0.1594477742910385\n","Epoch: 141, Training Loss = 2.2941794395446777\n","Epoch: 142, Training Loss = 2.2738311290740967\n","Epoch: 143, Training Loss = 2.2537834644317627\n","Epoch: 144, Training Loss = 2.2340354919433594\n","Epoch: 145, Training Loss = 2.2145872116088867\n","Epoch: 146, Training Loss = 2.1954386234283447\n","Epoch: 147, Training Loss = 2.176588535308838\n","Epoch: 148, Training Loss = 2.158036231994629\n","Epoch: 149, Training Loss = 2.1397812366485596\n","Epoch: 150, Training Loss = 2.121821165084839\n","Accuracy =  0.22877824306488037 F1 weighted =  0.28615912795066833 F1 macro =  0.1746261864900589\n","Epoch: 151, Training Loss = 2.1041555404663086\n","Epoch: 152, Training Loss = 2.086782932281494\n","Epoch: 153, Training Loss = 2.069700241088867\n","Epoch: 154, Training Loss = 2.0529069900512695\n","Epoch: 155, Training Loss = 2.036400318145752\n","Epoch: 156, Training Loss = 2.0201780796051025\n","Epoch: 157, Training Loss = 2.004237651824951\n","Epoch: 158, Training Loss = 1.9885765314102173\n","Epoch: 159, Training Loss = 1.9731922149658203\n","Epoch: 160, Training Loss = 1.958081841468811\n","Accuracy =  0.26228928565979004 F1 weighted =  0.3261476159095764 F1 macro =  0.18703985214233398\n","Epoch: 161, Training Loss = 1.943241834640503\n","Epoch: 162, Training Loss = 1.9286694526672363\n","Epoch: 163, Training Loss = 1.914361596107483\n","Epoch: 164, Training Loss = 1.9003148078918457\n","Epoch: 165, Training Loss = 1.886525273323059\n","Epoch: 166, Training Loss = 1.8729898929595947\n","Epoch: 167, Training Loss = 1.8597052097320557\n","Epoch: 168, Training Loss = 1.8466671705245972\n","Epoch: 169, Training Loss = 1.8338720798492432\n","Epoch: 170, Training Loss = 1.821315884590149\n","Accuracy =  0.29609543085098267 F1 weighted =  0.3616177439689636 F1 macro =  0.19768676161766052\n","Epoch: 171, Training Loss = 1.8089948892593384\n","Epoch: 172, Training Loss = 1.796905279159546\n","Epoch: 173, Training Loss = 1.7850430011749268\n","Epoch: 174, Training Loss = 1.7734042406082153\n","Epoch: 175, Training Loss = 1.7619848251342773\n","Epoch: 176, Training Loss = 1.7507808208465576\n","Epoch: 177, Training Loss = 1.7397878170013428\n","Epoch: 178, Training Loss = 1.7290022373199463\n","Epoch: 179, Training Loss = 1.7184197902679443\n","Epoch: 180, Training Loss = 1.7080368995666504\n","Accuracy =  0.328289657831192 F1 weighted =  0.39144808053970337 F1 macro =  0.20591285824775696\n","Epoch: 181, Training Loss = 1.6978492736816406\n","Epoch: 182, Training Loss = 1.6878527402877808\n","Epoch: 183, Training Loss = 1.6780433654785156\n","Epoch: 184, Training Loss = 1.6684178113937378\n","Epoch: 185, Training Loss = 1.6589715480804443\n","Epoch: 186, Training Loss = 1.6497012376785278\n","Epoch: 187, Training Loss = 1.640602707862854\n","Epoch: 188, Training Loss = 1.6316722631454468\n","Epoch: 189, Training Loss = 1.6229066848754883\n","Epoch: 190, Training Loss = 1.614301323890686\n","Accuracy =  0.35979342460632324 F1 weighted =  0.41762253642082214 F1 macro =  0.21332235634326935\n","Epoch: 191, Training Loss = 1.6058534383773804\n","Epoch: 192, Training Loss = 1.5975595712661743\n","Epoch: 193, Training Loss = 1.5894157886505127\n","Epoch: 194, Training Loss = 1.5814191102981567\n","Epoch: 195, Training Loss = 1.5735657215118408\n","Epoch: 196, Training Loss = 1.5658527612686157\n","Epoch: 197, Training Loss = 1.5582770109176636\n","Epoch: 198, Training Loss = 1.550835132598877\n","Epoch: 199, Training Loss = 1.543524146080017\n","Epoch: 200, Training Loss = 1.5363409519195557\n","Accuracy =  0.3892175555229187 F1 weighted =  0.43959033489227295 F1 macro =  0.21894404292106628\n","Epoch: 201, Training Loss = 1.5292829275131226\n","Epoch: 202, Training Loss = 1.5223469734191895\n","Epoch: 203, Training Loss = 1.5155303478240967\n","Epoch: 204, Training Loss = 1.5088300704956055\n","Epoch: 205, Training Loss = 1.502243995666504\n","Epoch: 206, Training Loss = 1.4957691431045532\n","Epoch: 207, Training Loss = 1.489403247833252\n","Epoch: 208, Training Loss = 1.4831433296203613\n","Epoch: 209, Training Loss = 1.4769874811172485\n","Epoch: 210, Training Loss = 1.470933437347412\n","Accuracy =  0.4158743917942047 F1 weighted =  0.4575871229171753 F1 macro =  0.22316351532936096\n","Epoch: 211, Training Loss = 1.4649786949157715\n","Epoch: 212, Training Loss = 1.4591208696365356\n","Epoch: 213, Training Loss = 1.4533580541610718\n","Epoch: 214, Training Loss = 1.4476879835128784\n","Epoch: 215, Training Loss = 1.4421087503433228\n","Epoch: 216, Training Loss = 1.4366183280944824\n","Epoch: 217, Training Loss = 1.431214690208435\n","Epoch: 218, Training Loss = 1.425896167755127\n","Epoch: 219, Training Loss = 1.420660376548767\n","Epoch: 220, Training Loss = 1.415506362915039\n","Accuracy =  0.4385751485824585 F1 weighted =  0.47147154808044434 F1 macro =  0.22580598294734955\n","Epoch: 221, Training Loss = 1.4104318618774414\n","Epoch: 222, Training Loss = 1.4054350852966309\n","Epoch: 223, Training Loss = 1.4005146026611328\n","Epoch: 224, Training Loss = 1.395668864250183\n","Epoch: 225, Training Loss = 1.390896201133728\n","Epoch: 226, Training Loss = 1.3861950635910034\n","Epoch: 227, Training Loss = 1.3815640211105347\n","Epoch: 228, Training Loss = 1.3770018815994263\n","Epoch: 229, Training Loss = 1.3725066184997559\n","Epoch: 230, Training Loss = 1.3680776357650757\n","Accuracy =  0.458110511302948 F1 weighted =  0.48243245482444763 F1 macro =  0.22747141122817993\n","Epoch: 231, Training Loss = 1.3637129068374634\n","Epoch: 232, Training Loss = 1.359411597251892\n","Epoch: 233, Training Loss = 1.3551723957061768\n","Epoch: 234, Training Loss = 1.3509937524795532\n","Epoch: 235, Training Loss = 1.3468750715255737\n","Epoch: 236, Training Loss = 1.3428144454956055\n","Epoch: 237, Training Loss = 1.3388113975524902\n","Epoch: 238, Training Loss = 1.3348644971847534\n","Epoch: 239, Training Loss = 1.330972671508789\n","Epoch: 240, Training Loss = 1.327134609222412\n","Accuracy =  0.4751875698566437 F1 weighted =  0.49148720502853394 F1 macro =  0.22888164222240448\n","Epoch: 241, Training Loss = 1.323349952697754\n","Epoch: 242, Training Loss = 1.3196172714233398\n","Epoch: 243, Training Loss = 1.3159356117248535\n","Epoch: 244, Training Loss = 1.312304139137268\n","Epoch: 245, Training Loss = 1.308721661567688\n","Epoch: 246, Training Loss = 1.3051875829696655\n","Epoch: 247, Training Loss = 1.3017009496688843\n","Epoch: 248, Training Loss = 1.2982609272003174\n","Epoch: 249, Training Loss = 1.2948660850524902\n","Epoch: 250, Training Loss = 1.291516900062561\n","Accuracy =  0.4912039339542389 F1 weighted =  0.5000403523445129 F1 macro =  0.23074664175510406\n","Epoch: 251, Training Loss = 1.2882113456726074\n","Epoch: 252, Training Loss = 1.2849493026733398\n","Epoch: 253, Training Loss = 1.2817295789718628\n","Epoch: 254, Training Loss = 1.2785515785217285\n","Epoch: 255, Training Loss = 1.2754147052764893\n","Epoch: 256, Training Loss = 1.2723182439804077\n","Epoch: 257, Training Loss = 1.269261121749878\n","Epoch: 258, Training Loss = 1.2662433385849\n","Epoch: 259, Training Loss = 1.2632635831832886\n","Epoch: 260, Training Loss = 1.2603216171264648\n","Accuracy =  0.5058895349502563 F1 weighted =  0.5074608325958252 F1 macro =  0.23233167827129364\n","Epoch: 261, Training Loss = 1.2574166059494019\n","Epoch: 262, Training Loss = 1.2545477151870728\n","Epoch: 263, Training Loss = 1.251714825630188\n","Epoch: 264, Training Loss = 1.2489168643951416\n","Epoch: 265, Training Loss = 1.2461535930633545\n","Epoch: 266, Training Loss = 1.2434242963790894\n","Epoch: 267, Training Loss = 1.2407286167144775\n","Epoch: 268, Training Loss = 1.2380657196044922\n","Epoch: 269, Training Loss = 1.235435128211975\n","Epoch: 270, Training Loss = 1.232836365699768\n","Accuracy =  0.5191943049430847 F1 weighted =  0.5139760971069336 F1 macro =  0.23372244834899902\n","Epoch: 271, Training Loss = 1.230268955230713\n","Epoch: 272, Training Loss = 1.2277321815490723\n","Epoch: 273, Training Loss = 1.2252259254455566\n","Epoch: 274, Training Loss = 1.2227493524551392\n","Epoch: 275, Training Loss = 1.2203022241592407\n","Epoch: 276, Training Loss = 1.217883825302124\n","Epoch: 277, Training Loss = 1.2154940366744995\n","Epoch: 278, Training Loss = 1.2131321430206299\n","Epoch: 279, Training Loss = 1.210797905921936\n","Epoch: 280, Training Loss = 1.2084907293319702\n","Accuracy =  0.5317223072052002 F1 weighted =  0.5198476314544678 F1 macro =  0.2347131371498108\n","Epoch: 281, Training Loss = 1.2062101364135742\n","Epoch: 282, Training Loss = 1.2039557695388794\n","Epoch: 283, Training Loss = 1.2017276287078857\n","Epoch: 284, Training Loss = 1.199524998664856\n","Epoch: 285, Training Loss = 1.1973471641540527\n","Epoch: 286, Training Loss = 1.1951942443847656\n","Epoch: 287, Training Loss = 1.1930655241012573\n","Epoch: 288, Training Loss = 1.1909610033035278\n","Epoch: 289, Training Loss = 1.1888798475265503\n","Epoch: 290, Training Loss = 1.1868220567703247\n","Accuracy =  0.5432481169700623 F1 weighted =  0.5249409079551697 F1 macro =  0.23538194596767426\n","Epoch: 291, Training Loss = 1.1847871541976929\n","Epoch: 292, Training Loss = 1.1827747821807861\n","Epoch: 293, Training Loss = 1.1807849407196045\n","Epoch: 294, Training Loss = 1.1788166761398315\n","Epoch: 295, Training Loss = 1.1768702268600464\n","Epoch: 296, Training Loss = 1.1749449968338013\n","Epoch: 297, Training Loss = 1.1730406284332275\n","Epoch: 298, Training Loss = 1.1711572408676147\n","Epoch: 299, Training Loss = 1.1692941188812256\n","Epoch: 300, Training Loss = 1.1674509048461914\n","Accuracy =  0.5543674230575562 F1 weighted =  0.5298356413841248 F1 macro =  0.23637787997722626\n","Epoch: 301, Training Loss = 1.1656275987625122\n","Epoch: 302, Training Loss = 1.1638236045837402\n","Epoch: 303, Training Loss = 1.1620389223098755\n","Epoch: 304, Training Loss = 1.1602733135223389\n","Epoch: 305, Training Loss = 1.1585263013839722\n","Epoch: 306, Training Loss = 1.1567978858947754\n","Epoch: 307, Training Loss = 1.1550874710083008\n","Epoch: 308, Training Loss = 1.1533949375152588\n","Epoch: 309, Training Loss = 1.1517201662063599\n","Epoch: 310, Training Loss = 1.1500627994537354\n","Accuracy =  0.5639694333076477 F1 weighted =  0.5336049795150757 F1 macro =  0.23647794127464294\n","Epoch: 311, Training Loss = 1.1484225988388062\n","Epoch: 312, Training Loss = 1.1467992067337036\n","Epoch: 313, Training Loss = 1.1451926231384277\n","Epoch: 314, Training Loss = 1.1436023712158203\n","Epoch: 315, Training Loss = 1.142028570175171\n","Epoch: 316, Training Loss = 1.1404706239700317\n","Epoch: 317, Training Loss = 1.1389285326004028\n","Epoch: 318, Training Loss = 1.1374019384384155\n","Epoch: 319, Training Loss = 1.1358909606933594\n","Epoch: 320, Training Loss = 1.134394884109497\n","Accuracy =  0.5729728937149048 F1 weighted =  0.5370785593986511 F1 macro =  0.23657982051372528\n","Epoch: 321, Training Loss = 1.1329139471054077\n","Epoch: 322, Training Loss = 1.131447672843933\n","Epoch: 323, Training Loss = 1.1299959421157837\n","Epoch: 324, Training Loss = 1.1285587549209595\n","Epoch: 325, Training Loss = 1.1271356344223022\n","Epoch: 326, Training Loss = 1.125726580619812\n","Epoch: 327, Training Loss = 1.1243313550949097\n","Epoch: 328, Training Loss = 1.122949481010437\n","Epoch: 329, Training Loss = 1.1215813159942627\n","Epoch: 330, Training Loss = 1.1202263832092285\n","Accuracy =  0.5813332796096802 F1 weighted =  0.5402456521987915 F1 macro =  0.23659516870975494\n","Epoch: 331, Training Loss = 1.1188844442367554\n","Epoch: 332, Training Loss = 1.1175554990768433\n","Epoch: 333, Training Loss = 1.116239309310913\n","Epoch: 334, Training Loss = 1.1149356365203857\n","Epoch: 335, Training Loss = 1.1136443614959717\n","Epoch: 336, Training Loss = 1.112365484237671\n","Epoch: 337, Training Loss = 1.1110987663269043\n","Epoch: 338, Training Loss = 1.1098439693450928\n","Epoch: 339, Training Loss = 1.1086007356643677\n","Epoch: 340, Training Loss = 1.107369303703308\n","Accuracy =  0.5888862609863281 F1 weighted =  0.5430649518966675 F1 macro =  0.2368229478597641\n","Epoch: 341, Training Loss = 1.106149435043335\n","Epoch: 342, Training Loss = 1.1049408912658691\n","Epoch: 343, Training Loss = 1.1037436723709106\n","Epoch: 344, Training Loss = 1.1025574207305908\n","Epoch: 345, Training Loss = 1.1013818979263306\n","Epoch: 346, Training Loss = 1.100217580795288\n","Epoch: 347, Training Loss = 1.0990636348724365\n","Epoch: 348, Training Loss = 1.097920298576355\n","Epoch: 349, Training Loss = 1.096787452697754\n","Epoch: 350, Training Loss = 1.095664620399475\n","Accuracy =  0.5955929160118103 F1 weighted =  0.5453997254371643 F1 macro =  0.23667673766613007\n","Epoch: 351, Training Loss = 1.0945521593093872\n","Epoch: 352, Training Loss = 1.093449592590332\n","Epoch: 353, Training Loss = 1.0923570394515991\n","Epoch: 354, Training Loss = 1.0912741422653198\n","Epoch: 355, Training Loss = 1.0902010202407837\n","Epoch: 356, Training Loss = 1.0891371965408325\n","Epoch: 357, Training Loss = 1.088083028793335\n","Epoch: 358, Training Loss = 1.0870380401611328\n","Epoch: 359, Training Loss = 1.086002230644226\n","Epoch: 360, Training Loss = 1.0849757194519043\n","Accuracy =  0.6016676425933838 F1 weighted =  0.5472182035446167 F1 macro =  0.23604118824005127\n","Epoch: 361, Training Loss = 1.0839579105377197\n","Epoch: 362, Training Loss = 1.0829490423202515\n","Epoch: 363, Training Loss = 1.0819491147994995\n","Epoch: 364, Training Loss = 1.0809576511383057\n","Epoch: 365, Training Loss = 1.0799747705459595\n","Epoch: 366, Training Loss = 1.079000473022461\n","Epoch: 367, Training Loss = 1.0780342817306519\n","Epoch: 368, Training Loss = 1.0770765542984009\n","Epoch: 369, Training Loss = 1.076127052307129\n","Epoch: 370, Training Loss = 1.0751854181289673\n","Accuracy =  0.6072495579719543 F1 weighted =  0.5490461587905884 F1 macro =  0.23594093322753906\n","Epoch: 371, Training Loss = 1.074251651763916\n","Epoch: 372, Training Loss = 1.0733258724212646\n","Epoch: 373, Training Loss = 1.072407841682434\n","Epoch: 374, Training Loss = 1.0714976787567139\n","Epoch: 375, Training Loss = 1.0705949068069458\n","Epoch: 376, Training Loss = 1.069699764251709\n","Epoch: 377, Training Loss = 1.0688121318817139\n","Epoch: 378, Training Loss = 1.0679316520690918\n","Epoch: 379, Training Loss = 1.0670585632324219\n","Epoch: 380, Training Loss = 1.0661925077438354\n","Accuracy =  0.6120686531066895 F1 weighted =  0.5503053665161133 F1 macro =  0.23528018593788147\n","Epoch: 381, Training Loss = 1.0653337240219116\n","Epoch: 382, Training Loss = 1.0644819736480713\n","Epoch: 383, Training Loss = 1.0636370182037354\n","Epoch: 384, Training Loss = 1.0627989768981934\n","Epoch: 385, Training Loss = 1.0619676113128662\n","Epoch: 386, Training Loss = 1.0611430406570435\n","Epoch: 387, Training Loss = 1.0603251457214355\n","Epoch: 388, Training Loss = 1.0595139265060425\n","Epoch: 389, Training Loss = 1.0587090253829956\n","Epoch: 390, Training Loss = 1.057910442352295\n","Accuracy =  0.6166594624519348 F1 weighted =  0.5514500737190247 F1 macro =  0.2346557378768921\n","Epoch: 391, Training Loss = 1.0571184158325195\n","Epoch: 392, Training Loss = 1.0563325881958008\n","Epoch: 393, Training Loss = 1.0555529594421387\n","Epoch: 394, Training Loss = 1.0547795295715332\n","Epoch: 395, Training Loss = 1.0540120601654053\n","Epoch: 396, Training Loss = 1.0532506704330444\n","Epoch: 397, Training Loss = 1.0524951219558716\n","Epoch: 398, Training Loss = 1.0517456531524658\n","Epoch: 399, Training Loss = 1.0510016679763794\n","Epoch: 400, Training Loss = 1.0502636432647705\n","Accuracy =  0.6208410263061523 F1 weighted =  0.5523797273635864 F1 macro =  0.2338445484638214\n","Epoch: 401, Training Loss = 1.04953134059906\n","Epoch: 402, Training Loss = 1.0488046407699585\n","Epoch: 403, Training Loss = 1.0480833053588867\n","Epoch: 404, Training Loss = 1.0473679304122925\n","Epoch: 405, Training Loss = 1.046657681465149\n","Epoch: 406, Training Loss = 1.0459527969360352\n","Epoch: 407, Training Loss = 1.0452533960342407\n","Epoch: 408, Training Loss = 1.0445592403411865\n","Epoch: 409, Training Loss = 1.0438703298568726\n","Epoch: 410, Training Loss = 1.0431865453720093\n","Accuracy =  0.6246774196624756 F1 weighted =  0.5532097816467285 F1 macro =  0.23312242329120636\n","Epoch: 411, Training Loss = 1.0425080060958862\n","Epoch: 412, Training Loss = 1.0418343544006348\n","Epoch: 413, Training Loss = 1.041165828704834\n","Epoch: 414, Training Loss = 1.0405020713806152\n","Epoch: 415, Training Loss = 1.0398436784744263\n","Epoch: 416, Training Loss = 1.0391898155212402\n","Epoch: 417, Training Loss = 1.0385407209396362\n","Epoch: 418, Training Loss = 1.0378965139389038\n","Epoch: 419, Training Loss = 1.0372570753097534\n","Epoch: 420, Training Loss = 1.0366222858428955\n","Accuracy =  0.6281351447105408 F1 weighted =  0.5538825988769531 F1 macro =  0.23233452439308167\n","Epoch: 421, Training Loss = 1.03599214553833\n","Epoch: 422, Training Loss = 1.0353665351867676\n","Epoch: 423, Training Loss = 1.034745454788208\n","Epoch: 424, Training Loss = 1.0341287851333618\n","Epoch: 425, Training Loss = 1.0335166454315186\n","Epoch: 426, Training Loss = 1.0329090356826782\n","Epoch: 427, Training Loss = 1.0323055982589722\n","Epoch: 428, Training Loss = 1.03170645236969\n","Epoch: 429, Training Loss = 1.0311115980148315\n","Epoch: 430, Training Loss = 1.0305211544036865\n","Accuracy =  0.6312059164047241 F1 weighted =  0.5542631149291992 F1 macro =  0.23146279156208038\n","Epoch: 431, Training Loss = 1.0299345254898071\n","Epoch: 432, Training Loss = 1.0293524265289307\n","Epoch: 433, Training Loss = 1.0287744998931885\n","Epoch: 434, Training Loss = 1.028200387954712\n","Epoch: 435, Training Loss = 1.02763032913208\n","Epoch: 436, Training Loss = 1.027064323425293\n","Epoch: 437, Training Loss = 1.0265023708343506\n","Epoch: 438, Training Loss = 1.0259442329406738\n","Epoch: 439, Training Loss = 1.0253899097442627\n","Epoch: 440, Training Loss = 1.0248396396636963\n","Accuracy =  0.6340678334236145 F1 weighted =  0.55443274974823 F1 macro =  0.23020179569721222\n","Epoch: 441, Training Loss = 1.0242929458618164\n","Epoch: 442, Training Loss = 1.0237503051757812\n","Epoch: 443, Training Loss = 1.023211121559143\n","Epoch: 444, Training Loss = 1.0226757526397705\n","Epoch: 445, Training Loss = 1.022144079208374\n","Epoch: 446, Training Loss = 1.021615982055664\n","Epoch: 447, Training Loss = 1.0210915803909302\n","Epoch: 448, Training Loss = 1.0205706357955933\n","Epoch: 449, Training Loss = 1.0200533866882324\n","Epoch: 450, Training Loss = 1.0195395946502686\n","Accuracy =  0.6368184685707092 F1 weighted =  0.5544333457946777 F1 macro =  0.22884082794189453\n","Epoch: 451, Training Loss = 1.0190292596817017\n","Epoch: 452, Training Loss = 1.0185225009918213\n","Epoch: 453, Training Loss = 1.0180188417434692\n","Epoch: 454, Training Loss = 1.0175188779830933\n","Epoch: 455, Training Loss = 1.0170221328735352\n","Epoch: 456, Training Loss = 1.016528606414795\n","Epoch: 457, Training Loss = 1.0160385370254517\n","Epoch: 458, Training Loss = 1.0155516862869263\n","Epoch: 459, Training Loss = 1.0150680541992188\n","Epoch: 460, Training Loss = 1.0145875215530396\n","Accuracy =  0.6396358609199524 F1 weighted =  0.5544074177742004 F1 macro =  0.22732627391815186\n","Epoch: 461, Training Loss = 1.0141104459762573\n","Epoch: 462, Training Loss = 1.0136362314224243\n","Epoch: 463, Training Loss = 1.0131653547286987\n","Epoch: 464, Training Loss = 1.0126975774765015\n","Epoch: 465, Training Loss = 1.0122326612472534\n","Epoch: 466, Training Loss = 1.0117710828781128\n","Epoch: 467, Training Loss = 1.0113122463226318\n","Epoch: 468, Training Loss = 1.0108565092086792\n","Epoch: 469, Training Loss = 1.0104039907455444\n","Epoch: 470, Training Loss = 1.0099540948867798\n","Accuracy =  0.6426537036895752 F1 weighted =  0.5544869899749756 F1 macro =  0.22598229348659515\n","Epoch: 471, Training Loss = 1.009507179260254\n","Epoch: 472, Training Loss = 1.0090632438659668\n","Epoch: 473, Training Loss = 1.0086219310760498\n","Epoch: 474, Training Loss = 1.0081837177276611\n","Epoch: 475, Training Loss = 1.0077482461929321\n","Epoch: 476, Training Loss = 1.007315754890442\n","Epoch: 477, Training Loss = 1.0068856477737427\n","Epoch: 478, Training Loss = 1.0064586400985718\n","Epoch: 479, Training Loss = 1.0060341358184814\n","Epoch: 480, Training Loss = 1.0056124925613403\n","Accuracy =  0.6454795002937317 F1 weighted =  0.5543932914733887 F1 macro =  0.22438150644302368\n","Epoch: 481, Training Loss = 1.0051935911178589\n","Epoch: 482, Training Loss = 1.0047773122787476\n","Epoch: 483, Training Loss = 1.0043634176254272\n","Epoch: 484, Training Loss = 1.0039525032043457\n","Epoch: 485, Training Loss = 1.0035440921783447\n","Epoch: 486, Training Loss = 1.0031381845474243\n","Epoch: 487, Training Loss = 1.002734661102295\n","Epoch: 488, Training Loss = 1.0023338794708252\n","Epoch: 489, Training Loss = 1.0019357204437256\n","Epoch: 490, Training Loss = 1.001539945602417\n","Accuracy =  0.6482885479927063 F1 weighted =  0.5542837977409363 F1 macro =  0.2229219377040863\n","Epoch: 491, Training Loss = 1.001146674156189\n","Epoch: 492, Training Loss = 1.000755786895752\n","Epoch: 493, Training Loss = 1.000367283821106\n","Epoch: 494, Training Loss = 0.9999812841415405\n","Epoch: 495, Training Loss = 0.9995977282524109\n","Epoch: 496, Training Loss = 0.9992165565490723\n","Epoch: 497, Training Loss = 0.9988376498222351\n","Epoch: 498, Training Loss = 0.9984611868858337\n","Epoch: 499, Training Loss = 0.9980869889259338\n","Epoch: 500, Training Loss = 0.997715175151825\n","Accuracy =  0.6508609652519226 F1 weighted =  0.553854763507843 F1 macro =  0.22107504308223724\n","Epoch: 501, Training Loss = 0.997345507144928\n","Epoch: 502, Training Loss = 0.996978223323822\n","Epoch: 503, Training Loss = 0.9966133236885071\n","Epoch: 504, Training Loss = 0.9962504506111145\n","Epoch: 505, Training Loss = 0.9958899021148682\n","Epoch: 506, Training Loss = 0.995531439781189\n","Epoch: 507, Training Loss = 0.9951751828193665\n","Epoch: 508, Training Loss = 0.9948212504386902\n","Epoch: 509, Training Loss = 0.9944692850112915\n","Epoch: 510, Training Loss = 0.9941196441650391\n","Accuracy =  0.6534305810928345 F1 weighted =  0.5535212159156799 F1 macro =  0.21926744282245636\n","Epoch: 511, Training Loss = 0.993772029876709\n","Epoch: 512, Training Loss = 0.9934265613555908\n","Epoch: 513, Training Loss = 0.9930832386016846\n","Epoch: 514, Training Loss = 0.9927418828010559\n","Epoch: 515, Training Loss = 0.9924024939537048\n","Epoch: 516, Training Loss = 0.9920653700828552\n","Epoch: 517, Training Loss = 0.9917300939559937\n","Epoch: 518, Training Loss = 0.991396963596344\n","Epoch: 519, Training Loss = 0.9910658597946167\n","Epoch: 520, Training Loss = 0.9907366037368774\n","Accuracy =  0.6560336351394653 F1 weighted =  0.5532965660095215 F1 macro =  0.21765346825122833\n","Epoch: 521, Training Loss = 0.9904094934463501\n","Epoch: 522, Training Loss = 0.9900842308998108\n","Epoch: 523, Training Loss = 0.9897609353065491\n","Epoch: 524, Training Loss = 0.9894394874572754\n","Epoch: 525, Training Loss = 0.9891200661659241\n","Epoch: 526, Training Loss = 0.9888025522232056\n","Epoch: 527, Training Loss = 0.9884868264198303\n","Epoch: 528, Training Loss = 0.9881729483604431\n","Epoch: 529, Training Loss = 0.9878610372543335\n","Epoch: 530, Training Loss = 0.9875510334968567\n","Accuracy =  0.6580798625946045 F1 weighted =  0.5529541373252869 F1 macro =  0.21607841551303864\n","Epoch: 531, Training Loss = 0.9872428178787231\n","Epoch: 532, Training Loss = 0.9869362711906433\n","Epoch: 533, Training Loss = 0.9866316318511963\n","Epoch: 534, Training Loss = 0.9863288402557373\n","Epoch: 535, Training Loss = 0.986027717590332\n","Epoch: 536, Training Loss = 0.9857285022735596\n","Epoch: 537, Training Loss = 0.9854310154914856\n","Epoch: 538, Training Loss = 0.9851351976394653\n","Epoch: 539, Training Loss = 0.9848412275314331\n","Epoch: 540, Training Loss = 0.9845488667488098\n","Accuracy =  0.6602820158004761 F1 weighted =  0.5528809428215027 F1 macro =  0.21479380130767822\n","Epoch: 541, Training Loss = 0.984258234500885\n","Epoch: 542, Training Loss = 0.9839693307876587\n","Epoch: 543, Training Loss = 0.9836821556091309\n","Epoch: 544, Training Loss = 0.983396589756012\n","Epoch: 545, Training Loss = 0.9831127524375916\n","Epoch: 546, Training Loss = 0.9828304648399353\n","Epoch: 547, Training Loss = 0.9825498461723328\n","Epoch: 548, Training Loss = 0.9822708368301392\n","Epoch: 549, Training Loss = 0.981993556022644\n","Epoch: 550, Training Loss = 0.9817178249359131\n","Accuracy =  0.6620554327964783 F1 weighted =  0.5529072284698486 F1 macro =  0.21360093355178833\n","Epoch: 551, Training Loss = 0.9814436435699463\n","Epoch: 552, Training Loss = 0.9811711311340332\n","Epoch: 553, Training Loss = 0.9809000492095947\n","Epoch: 554, Training Loss = 0.9806306958198547\n","Epoch: 555, Training Loss = 0.9803628325462341\n","Epoch: 556, Training Loss = 0.9800964593887329\n","Epoch: 557, Training Loss = 0.9798317551612854\n","Epoch: 558, Training Loss = 0.9795683026313782\n","Epoch: 559, Training Loss = 0.979306697845459\n","Epoch: 560, Training Loss = 0.9790464043617249\n","Accuracy =  0.663503110408783 F1 weighted =  0.5528563857078552 F1 macro =  0.21234038472175598\n","Epoch: 561, Training Loss = 0.9787876009941101\n","Epoch: 562, Training Loss = 0.9785304069519043\n","Epoch: 563, Training Loss = 0.9782744646072388\n","Epoch: 564, Training Loss = 0.978020191192627\n","Epoch: 565, Training Loss = 0.977767288684845\n","Epoch: 566, Training Loss = 0.9775158762931824\n","Epoch: 567, Training Loss = 0.9772657155990601\n","Epoch: 568, Training Loss = 0.9770171642303467\n","Epoch: 569, Training Loss = 0.9767699837684631\n","Epoch: 570, Training Loss = 0.9765242338180542\n","Accuracy =  0.6647698283195496 F1 weighted =  0.5529003739356995 F1 macro =  0.21138408780097961\n","Epoch: 571, Training Loss = 0.9762796759605408\n","Epoch: 572, Training Loss = 0.976036787033081\n","Epoch: 573, Training Loss = 0.9757951498031616\n","Epoch: 574, Training Loss = 0.9755548238754272\n","Epoch: 575, Training Loss = 0.9753159284591675\n","Epoch: 576, Training Loss = 0.9750784635543823\n","Epoch: 577, Training Loss = 0.9748421311378479\n","Epoch: 578, Training Loss = 0.9746071696281433\n","Epoch: 579, Training Loss = 0.9743735790252686\n","Epoch: 580, Training Loss = 0.9741414189338684\n","Accuracy =  0.6659892201423645 F1 weighted =  0.5529956221580505 F1 macro =  0.2106684148311615\n","Epoch: 581, Training Loss = 0.9739105105400085\n","Epoch: 582, Training Loss = 0.973680853843689\n","Epoch: 583, Training Loss = 0.9734523892402649\n","Epoch: 584, Training Loss = 0.9732253551483154\n","Epoch: 585, Training Loss = 0.9729995727539062\n","Epoch: 586, Training Loss = 0.9727750420570374\n","Epoch: 587, Training Loss = 0.9725517630577087\n","Epoch: 588, Training Loss = 0.9723296761512756\n","Epoch: 589, Training Loss = 0.9721088409423828\n","Epoch: 590, Training Loss = 0.9718892574310303\n","Accuracy =  0.6672754287719727 F1 weighted =  0.5530738830566406 F1 macro =  0.20978717505931854\n","Epoch: 591, Training Loss = 0.9716710448265076\n","Epoch: 592, Training Loss = 0.9714537858963013\n","Epoch: 593, Training Loss = 0.9712377786636353\n","Epoch: 594, Training Loss = 0.9710232019424438\n","Epoch: 595, Training Loss = 0.9708095788955688\n","Epoch: 596, Training Loss = 0.9705971479415894\n","Epoch: 597, Training Loss = 0.9703860878944397\n","Epoch: 598, Training Loss = 0.970176100730896\n","Epoch: 599, Training Loss = 0.969967246055603\n","Epoch: 600, Training Loss = 0.9697595834732056\n","Accuracy =  0.6684280037879944 F1 weighted =  0.5532367825508118 F1 macro =  0.20932289958000183\n","Epoch: 601, Training Loss = 0.9695529341697693\n","Epoch: 602, Training Loss = 0.9693477153778076\n","Epoch: 603, Training Loss = 0.9691433906555176\n","Epoch: 604, Training Loss = 0.9689401984214783\n","Epoch: 605, Training Loss = 0.9687381982803345\n","Epoch: 606, Training Loss = 0.9685373306274414\n","Epoch: 607, Training Loss = 0.9683374762535095\n","Epoch: 608, Training Loss = 0.9681386351585388\n","Epoch: 609, Training Loss = 0.9679412245750427\n","Epoch: 610, Training Loss = 0.9677445292472839\n","Accuracy =  0.6694469451904297 F1 weighted =  0.5532877445220947 F1 macro =  0.20846912264823914\n","Epoch: 611, Training Loss = 0.967549204826355\n","Epoch: 612, Training Loss = 0.9673546552658081\n","Epoch: 613, Training Loss = 0.9671613574028015\n","Epoch: 614, Training Loss = 0.9669690132141113\n","Epoch: 615, Training Loss = 0.9667777419090271\n","Epoch: 616, Training Loss = 0.9665876030921936\n","Epoch: 617, Training Loss = 0.9663984775543213\n","Epoch: 618, Training Loss = 0.9662102460861206\n","Epoch: 619, Training Loss = 0.9660231471061707\n","Epoch: 620, Training Loss = 0.9658370018005371\n","Accuracy =  0.6703879237174988 F1 weighted =  0.5533381700515747 F1 macro =  0.207840234041214\n","Epoch: 621, Training Loss = 0.9656519889831543\n","Epoch: 622, Training Loss = 0.9654678106307983\n","Epoch: 623, Training Loss = 0.9652847647666931\n","Epoch: 624, Training Loss = 0.9651026129722595\n","Epoch: 625, Training Loss = 0.9649215340614319\n","Epoch: 626, Training Loss = 0.9647412896156311\n","Epoch: 627, Training Loss = 0.9645622968673706\n","Epoch: 628, Training Loss = 0.9643839597702026\n","Epoch: 629, Training Loss = 0.9642068147659302\n","Epoch: 630, Training Loss = 0.9640305042266846\n","Accuracy =  0.6712899804115295 F1 weighted =  0.5534766912460327 F1 macro =  0.20751580595970154\n","Epoch: 631, Training Loss = 0.9638550877571106\n","Epoch: 632, Training Loss = 0.9636806845664978\n","Epoch: 633, Training Loss = 0.9635072350502014\n","Epoch: 634, Training Loss = 0.9633347392082214\n","Epoch: 635, Training Loss = 0.9631630778312683\n","Epoch: 636, Training Loss = 0.9629923105239868\n","Epoch: 637, Training Loss = 0.9628224968910217\n","Epoch: 638, Training Loss = 0.9626535773277283\n","Epoch: 639, Training Loss = 0.9624856114387512\n","Epoch: 640, Training Loss = 0.962318480014801\n","Accuracy =  0.6721446514129639 F1 weighted =  0.5535635352134705 F1 macro =  0.20694057643413544\n","Epoch: 641, Training Loss = 0.9621522426605225\n","Epoch: 642, Training Loss = 0.9619868993759155\n","Epoch: 643, Training Loss = 0.9618224501609802\n","Epoch: 644, Training Loss = 0.9616588950157166\n","Epoch: 645, Training Loss = 0.961496114730835\n","Epoch: 646, Training Loss = 0.9613343477249146\n","Epoch: 647, Training Loss = 0.9611732363700867\n","Epoch: 648, Training Loss = 0.96101313829422\n","Epoch: 649, Training Loss = 0.9608538746833801\n","Epoch: 650, Training Loss = 0.9606953859329224\n","Accuracy =  0.6729631423950195 F1 weighted =  0.5536597371101379 F1 macro =  0.20627620816230774\n","Epoch: 651, Training Loss = 0.9605376720428467\n","Epoch: 652, Training Loss = 0.9603808522224426\n","Epoch: 653, Training Loss = 0.9602248668670654\n","Epoch: 654, Training Loss = 0.9600697159767151\n","Epoch: 655, Training Loss = 0.9599152207374573\n","Epoch: 656, Training Loss = 0.9597616791725159\n","Epoch: 657, Training Loss = 0.9596089720726013\n","Epoch: 658, Training Loss = 0.9594569802284241\n","Epoch: 659, Training Loss = 0.9593057036399841\n","Epoch: 660, Training Loss = 0.959155261516571\n","Accuracy =  0.6737176179885864 F1 weighted =  0.5537596344947815 F1 macro =  0.2057710438966751\n","Epoch: 661, Training Loss = 0.9590057730674744\n","Epoch: 662, Training Loss = 0.9588568806648254\n","Epoch: 663, Training Loss = 0.9587088227272034\n","Epoch: 664, Training Loss = 0.9585615396499634\n","Epoch: 665, Training Loss = 0.9584150314331055\n","Epoch: 666, Training Loss = 0.9582691192626953\n","Epoch: 667, Training Loss = 0.958124041557312\n","Epoch: 668, Training Loss = 0.9579799175262451\n","Epoch: 669, Training Loss = 0.9578362703323364\n","Epoch: 670, Training Loss = 0.9576933979988098\n","Accuracy =  0.6744247674942017 F1 weighted =  0.5539079308509827 F1 macro =  0.20557862520217896\n","Epoch: 671, Training Loss = 0.9575513005256653\n","Epoch: 672, Training Loss = 0.9574099779129028\n","Epoch: 673, Training Loss = 0.9572694301605225\n","Epoch: 674, Training Loss = 0.9571294188499451\n","Epoch: 675, Training Loss = 0.9569901823997498\n","Epoch: 676, Training Loss = 0.9568517804145813\n","Epoch: 677, Training Loss = 0.9567139744758606\n","Epoch: 678, Training Loss = 0.9565768837928772\n","Epoch: 679, Training Loss = 0.9564403891563416\n","Epoch: 680, Training Loss = 0.956304669380188\n","Accuracy =  0.6750511527061462 F1 weighted =  0.5540328621864319 F1 macro =  0.20543892681598663\n","Epoch: 681, Training Loss = 0.9561696648597717\n","Epoch: 682, Training Loss = 0.956035315990448\n","Epoch: 683, Training Loss = 0.955901563167572\n","Epoch: 684, Training Loss = 0.9557686448097229\n","Epoch: 685, Training Loss = 0.9556362628936768\n","Epoch: 686, Training Loss = 0.9555046558380127\n","Epoch: 687, Training Loss = 0.9553735852241516\n","Epoch: 688, Training Loss = 0.9552433490753174\n","Epoch: 689, Training Loss = 0.9551135897636414\n","Epoch: 690, Training Loss = 0.9549845457077026\n","Accuracy =  0.675563395023346 F1 weighted =  0.5540738105773926 F1 macro =  0.20503094792366028\n","Epoch: 691, Training Loss = 0.9548560976982117\n","Epoch: 692, Training Loss = 0.9547283053398132\n","Epoch: 693, Training Loss = 0.9546012282371521\n","Epoch: 694, Training Loss = 0.9544747471809387\n","Epoch: 695, Training Loss = 0.9543488621711731\n","Epoch: 696, Training Loss = 0.9542236328125\n","Epoch: 697, Training Loss = 0.9540988802909851\n","Epoch: 698, Training Loss = 0.9539749622344971\n","Epoch: 699, Training Loss = 0.953851580619812\n","Epoch: 700, Training Loss = 0.9537286162376404\n","Accuracy =  0.6761758923530579 F1 weighted =  0.5542200207710266 F1 macro =  0.20475946366786957\n","Epoch: 701, Training Loss = 0.9536062479019165\n","Epoch: 702, Training Loss = 0.9534847736358643\n","Epoch: 703, Training Loss = 0.9533637762069702\n","Epoch: 704, Training Loss = 0.9532432556152344\n","Epoch: 705, Training Loss = 0.9531233310699463\n","Epoch: 706, Training Loss = 0.9530041813850403\n","Epoch: 707, Training Loss = 0.9528854489326477\n","Epoch: 708, Training Loss = 0.9527673125267029\n","Epoch: 709, Training Loss = 0.9526497721672058\n","Epoch: 710, Training Loss = 0.9525327682495117\n","Accuracy =  0.6766853928565979 F1 weighted =  0.5542944669723511 F1 macro =  0.20446163415908813\n","Epoch: 711, Training Loss = 0.9524163603782654\n","Epoch: 712, Training Loss = 0.952300488948822\n","Epoch: 713, Training Loss = 0.9521850347518921\n","Epoch: 714, Training Loss = 0.9520702362060547\n","Epoch: 715, Training Loss = 0.9519560933113098\n","Epoch: 716, Training Loss = 0.9518424868583679\n","Epoch: 717, Training Loss = 0.9517292380332947\n","Epoch: 718, Training Loss = 0.9516167044639587\n","Epoch: 719, Training Loss = 0.951504647731781\n","Epoch: 720, Training Loss = 0.9513931274414062\n","Accuracy =  0.6771753430366516 F1 weighted =  0.5544359087944031 F1 macro =  0.20435398817062378\n","Epoch: 721, Training Loss = 0.9512819647789001\n","Epoch: 722, Training Loss = 0.9511714577674866\n","Epoch: 723, Training Loss = 0.9510615468025208\n","Epoch: 724, Training Loss = 0.9509519934654236\n","Epoch: 725, Training Loss = 0.950843095779419\n","Epoch: 726, Training Loss = 0.9507347345352173\n","Epoch: 727, Training Loss = 0.950626790523529\n","Epoch: 728, Training Loss = 0.9505193829536438\n","Epoch: 729, Training Loss = 0.9504123330116272\n","Epoch: 730, Training Loss = 0.9503060579299927\n","Accuracy =  0.6777377128601074 F1 weighted =  0.55455082654953 F1 macro =  0.20414188504219055\n","Epoch: 731, Training Loss = 0.9502000212669373\n","Epoch: 732, Training Loss = 0.9500945806503296\n","Epoch: 733, Training Loss = 0.9499896168708801\n","Epoch: 734, Training Loss = 0.9498851299285889\n","Epoch: 735, Training Loss = 0.9497809410095215\n","Epoch: 736, Training Loss = 0.9496775269508362\n","Epoch: 737, Training Loss = 0.9495744109153748\n","Epoch: 738, Training Loss = 0.9494718313217163\n","Epoch: 739, Training Loss = 0.9493696689605713\n","Epoch: 740, Training Loss = 0.9492680430412292\n","Accuracy =  0.6782917380332947 F1 weighted =  0.5546831488609314 F1 macro =  0.2040097713470459\n","Epoch: 741, Training Loss = 0.9491668939590454\n","Epoch: 742, Training Loss = 0.949066162109375\n","Epoch: 743, Training Loss = 0.9489657878875732\n","Epoch: 744, Training Loss = 0.9488660097122192\n","Epoch: 745, Training Loss = 0.9487664103507996\n","Epoch: 746, Training Loss = 0.9486674666404724\n","Epoch: 747, Training Loss = 0.9485690593719482\n","Epoch: 748, Training Loss = 0.9484708309173584\n","Epoch: 749, Training Loss = 0.9483731985092163\n","Epoch: 750, Training Loss = 0.9482759237289429\n","Accuracy =  0.6788067817687988 F1 weighted =  0.5548238754272461 F1 macro =  0.2038252055644989\n","Epoch: 751, Training Loss = 0.9481791257858276\n","Epoch: 752, Training Loss = 0.9480827450752258\n","Epoch: 753, Training Loss = 0.9479867219924927\n","Epoch: 754, Training Loss = 0.9478912949562073\n","Epoch: 755, Training Loss = 0.9477962255477905\n","Epoch: 756, Training Loss = 0.9477015137672424\n","Epoch: 757, Training Loss = 0.947607159614563\n","Epoch: 758, Training Loss = 0.9475133419036865\n","Epoch: 759, Training Loss = 0.9474198222160339\n","Epoch: 760, Training Loss = 0.94732666015625\n","Accuracy =  0.6791825890541077 F1 weighted =  0.554898738861084 F1 macro =  0.20374876260757446\n","Epoch: 761, Training Loss = 0.9472340941429138\n","Epoch: 762, Training Loss = 0.9471416473388672\n","Epoch: 763, Training Loss = 0.9470497965812683\n","Epoch: 764, Training Loss = 0.9469583630561829\n","Epoch: 765, Training Loss = 0.9468672275543213\n","Epoch: 766, Training Loss = 0.9467764496803284\n","Epoch: 767, Training Loss = 0.9466862082481384\n","Epoch: 768, Training Loss = 0.9465961456298828\n","Epoch: 769, Training Loss = 0.9465065598487854\n","Epoch: 770, Training Loss = 0.9464173316955566\n","Accuracy =  0.6795612573623657 F1 weighted =  0.5550017952919006 F1 macro =  0.20371976494789124\n","Epoch: 771, Training Loss = 0.9463284015655518\n","Epoch: 772, Training Loss = 0.9462399482727051\n","Epoch: 773, Training Loss = 0.9461519718170166\n","Epoch: 774, Training Loss = 0.9460641145706177\n","Epoch: 775, Training Loss = 0.9459769129753113\n","Epoch: 776, Training Loss = 0.9458898305892944\n","Epoch: 777, Training Loss = 0.945803165435791\n","Epoch: 778, Training Loss = 0.9457168579101562\n","Epoch: 779, Training Loss = 0.9456308484077454\n","Epoch: 780, Training Loss = 0.9455453157424927\n","Accuracy =  0.6799148321151733 F1 weighted =  0.5550997257232666 F1 macro =  0.2037304937839508\n","Epoch: 781, Training Loss = 0.9454600214958191\n","Epoch: 782, Training Loss = 0.9453749656677246\n","Epoch: 783, Training Loss = 0.9452904462814331\n","Epoch: 784, Training Loss = 0.9452062845230103\n","Epoch: 785, Training Loss = 0.9451224207878113\n","Epoch: 786, Training Loss = 0.9450387358665466\n","Epoch: 787, Training Loss = 0.9449554681777954\n","Epoch: 788, Training Loss = 0.9448726177215576\n","Epoch: 789, Training Loss = 0.9447900056838989\n","Epoch: 790, Training Loss = 0.9447079300880432\n","Accuracy =  0.6802656054496765 F1 weighted =  0.5551924705505371 F1 macro =  0.20363140106201172\n","Epoch: 791, Training Loss = 0.9446258544921875\n","Epoch: 792, Training Loss = 0.9445443153381348\n","Epoch: 793, Training Loss = 0.9444630146026611\n","Epoch: 794, Training Loss = 0.9443820118904114\n","Epoch: 795, Training Loss = 0.944301426410675\n","Epoch: 796, Training Loss = 0.9442209601402283\n","Epoch: 797, Training Loss = 0.9441409707069397\n","Epoch: 798, Training Loss = 0.9440612196922302\n","Epoch: 799, Training Loss = 0.9439818263053894\n","Epoch: 800, Training Loss = 0.9439027309417725\n","Accuracy =  0.6805773973464966 F1 weighted =  0.5552997589111328 F1 macro =  0.2036377340555191\n","Epoch: 801, Training Loss = 0.9438239336013794\n","Epoch: 802, Training Loss = 0.9437453746795654\n","Epoch: 803, Training Loss = 0.9436671733856201\n","Epoch: 804, Training Loss = 0.9435892105102539\n","Epoch: 805, Training Loss = 0.9435115456581116\n","Epoch: 806, Training Loss = 0.9434341192245483\n","Epoch: 807, Training Loss = 0.9433571100234985\n","Epoch: 808, Training Loss = 0.9432803988456726\n","Epoch: 809, Training Loss = 0.943203866481781\n","Epoch: 810, Training Loss = 0.9431276321411133\n","Accuracy =  0.6808724999427795 F1 weighted =  0.5553807616233826 F1 macro =  0.20368273556232452\n","Epoch: 811, Training Loss = 0.9430516362190247\n","Epoch: 812, Training Loss = 0.9429760575294495\n","Epoch: 813, Training Loss = 0.9429005980491638\n","Epoch: 814, Training Loss = 0.9428254961967468\n","Epoch: 815, Training Loss = 0.9427506923675537\n","Epoch: 816, Training Loss = 0.9426760673522949\n","Epoch: 817, Training Loss = 0.9426017999649048\n","Epoch: 818, Training Loss = 0.9425277709960938\n","Epoch: 819, Training Loss = 0.9424540400505066\n","Epoch: 820, Training Loss = 0.9423803687095642\n","Accuracy =  0.6811509132385254 F1 weighted =  0.5554654598236084 F1 macro =  0.20372794568538666\n","Epoch: 821, Training Loss = 0.9423072338104248\n","Epoch: 822, Training Loss = 0.942234218120575\n","Epoch: 823, Training Loss = 0.9421615600585938\n","Epoch: 824, Training Loss = 0.9420889616012573\n","Epoch: 825, Training Loss = 0.9420167803764343\n","Epoch: 826, Training Loss = 0.9419447183609009\n","Epoch: 827, Training Loss = 0.9418730735778809\n","Epoch: 828, Training Loss = 0.9418016076087952\n","Epoch: 829, Training Loss = 0.9417303204536438\n","Epoch: 830, Training Loss = 0.9416593313217163\n","Accuracy =  0.6814571619033813 F1 weighted =  0.5555688142776489 F1 macro =  0.20373116433620453\n","Epoch: 831, Training Loss = 0.9415885210037231\n","Epoch: 832, Training Loss = 0.9415181279182434\n","Epoch: 833, Training Loss = 0.9414477944374084\n","Epoch: 834, Training Loss = 0.9413777589797974\n","Epoch: 835, Training Loss = 0.9413079619407654\n","Epoch: 836, Training Loss = 0.9412384033203125\n","Epoch: 837, Training Loss = 0.941169023513794\n","Epoch: 838, Training Loss = 0.941100001335144\n","Epoch: 839, Training Loss = 0.9410310387611389\n","Epoch: 840, Training Loss = 0.9409623742103577\n","Accuracy =  0.6817439198493958 F1 weighted =  0.55564945936203 F1 macro =  0.20362436771392822\n","Epoch: 841, Training Loss = 0.9408940076828003\n","Epoch: 842, Training Loss = 0.9408257603645325\n","Epoch: 843, Training Loss = 0.9407578110694885\n","Epoch: 844, Training Loss = 0.9406900405883789\n","Epoch: 845, Training Loss = 0.9406225085258484\n","Epoch: 846, Training Loss = 0.9405551552772522\n","Epoch: 847, Training Loss = 0.9404880404472351\n","Epoch: 848, Training Loss = 0.9404211044311523\n","Epoch: 849, Training Loss = 0.9403544664382935\n","Epoch: 850, Training Loss = 0.9402879476547241\n","Accuracy =  0.6820027828216553 F1 weighted =  0.555728018283844 F1 macro =  0.20366457104682922\n","Epoch: 851, Training Loss = 0.9402216672897339\n","Epoch: 852, Training Loss = 0.9401556253433228\n","Epoch: 853, Training Loss = 0.9400898814201355\n","Epoch: 854, Training Loss = 0.9400241374969482\n","Epoch: 855, Training Loss = 0.9399586915969849\n","Epoch: 856, Training Loss = 0.9398934245109558\n","Epoch: 857, Training Loss = 0.9398283362388611\n","Epoch: 858, Training Loss = 0.9397635459899902\n","Epoch: 859, Training Loss = 0.9396988749504089\n","Epoch: 860, Training Loss = 0.9396344423294067\n","Accuracy =  0.6822505593299866 F1 weighted =  0.5558071136474609 F1 macro =  0.20360055565834045\n","Epoch: 861, Training Loss = 0.9395701289176941\n","Epoch: 862, Training Loss = 0.9395059943199158\n","Epoch: 863, Training Loss = 0.9394422173500061\n","Epoch: 864, Training Loss = 0.9393784999847412\n","Epoch: 865, Training Loss = 0.9393149614334106\n","Epoch: 866, Training Loss = 0.9392516016960144\n","Epoch: 867, Training Loss = 0.939188539981842\n","Epoch: 868, Training Loss = 0.9391255378723145\n","Epoch: 869, Training Loss = 0.939062774181366\n","Epoch: 870, Training Loss = 0.9390001893043518\n","Accuracy =  0.6824983358383179 F1 weighted =  0.5558891892433167 F1 macro =  0.20364010334014893\n","Epoch: 871, Training Loss = 0.9389378428459167\n","Epoch: 872, Training Loss = 0.9388756155967712\n","Epoch: 873, Training Loss = 0.9388134479522705\n","Epoch: 874, Training Loss = 0.9387516975402832\n","Epoch: 875, Training Loss = 0.9386898279190063\n","Epoch: 876, Training Loss = 0.9386284351348877\n","Epoch: 877, Training Loss = 0.938567042350769\n","Epoch: 878, Training Loss = 0.9385059475898743\n","Epoch: 879, Training Loss = 0.9384449124336243\n","Epoch: 880, Training Loss = 0.9383840560913086\n","Accuracy =  0.6826960444450378 F1 weighted =  0.5559561252593994 F1 macro =  0.20367224514484406\n","Epoch: 881, Training Loss = 0.938323438167572\n","Epoch: 882, Training Loss = 0.9382628202438354\n","Epoch: 883, Training Loss = 0.9382025599479675\n","Epoch: 884, Training Loss = 0.9381424188613892\n","Epoch: 885, Training Loss = 0.9380823969841003\n","Epoch: 886, Training Loss = 0.9380225539207458\n","Epoch: 887, Training Loss = 0.9379628896713257\n","Epoch: 888, Training Loss = 0.9379032254219055\n","Epoch: 889, Training Loss = 0.9378439784049988\n","Epoch: 890, Training Loss = 0.9377846717834473\n","Accuracy =  0.6828658580780029 F1 weighted =  0.5559922456741333 F1 macro =  0.20347850024700165\n","Epoch: 891, Training Loss = 0.9377256631851196\n","Epoch: 892, Training Loss = 0.9376667737960815\n","Epoch: 893, Training Loss = 0.937608003616333\n","Epoch: 894, Training Loss = 0.937549352645874\n","Epoch: 895, Training Loss = 0.9374908804893494\n","Epoch: 896, Training Loss = 0.9374327063560486\n","Epoch: 897, Training Loss = 0.937374472618103\n","Epoch: 898, Training Loss = 0.9373165369033813\n","Epoch: 899, Training Loss = 0.9372586011886597\n","Epoch: 900, Training Loss = 0.9372009038925171\n","Accuracy =  0.6830384731292725 F1 weighted =  0.5560394525527954 F1 macro =  0.20339249074459076\n","Epoch: 901, Training Loss = 0.9371434450149536\n","Epoch: 902, Training Loss = 0.9370859861373901\n","Epoch: 903, Training Loss = 0.9370286464691162\n","Epoch: 904, Training Loss = 0.9369714856147766\n","Epoch: 905, Training Loss = 0.9369145631790161\n","Epoch: 906, Training Loss = 0.9368577003479004\n","Epoch: 907, Training Loss = 0.936801016330719\n","Epoch: 908, Training Loss = 0.9367443919181824\n","Epoch: 909, Training Loss = 0.9366879463195801\n","Epoch: 910, Training Loss = 0.9366316795349121\n","Accuracy =  0.6831859946250916 F1 weighted =  0.5560798048973083 F1 macro =  0.2033560872077942\n","Epoch: 911, Training Loss = 0.9365755319595337\n","Epoch: 912, Training Loss = 0.9365194439888\n","Epoch: 913, Training Loss = 0.9364635348320007\n","Epoch: 914, Training Loss = 0.9364078044891357\n","Epoch: 915, Training Loss = 0.936352014541626\n","Epoch: 916, Training Loss = 0.9362966418266296\n","Epoch: 917, Training Loss = 0.9362412691116333\n","Epoch: 918, Training Loss = 0.9361860156059265\n","Epoch: 919, Training Loss = 0.9361308813095093\n","Epoch: 920, Training Loss = 0.9360758066177368\n","Accuracy =  0.6833502650260925 F1 weighted =  0.5561355948448181 F1 macro =  0.20337964594364166\n","Epoch: 921, Training Loss = 0.9360209107398987\n","Epoch: 922, Training Loss = 0.9359662532806396\n","Epoch: 923, Training Loss = 0.9359117746353149\n","Epoch: 924, Training Loss = 0.9358571171760559\n","Epoch: 925, Training Loss = 0.9358027577400208\n","Epoch: 926, Training Loss = 0.9357483983039856\n","Epoch: 927, Training Loss = 0.9356943368911743\n","Epoch: 928, Training Loss = 0.935640275478363\n","Epoch: 929, Training Loss = 0.9355863928794861\n","Epoch: 930, Training Loss = 0.9355326294898987\n","Accuracy =  0.6834588646888733 F1 weighted =  0.5561642050743103 F1 macro =  0.20333680510520935\n","Epoch: 931, Training Loss = 0.9354790449142456\n","Epoch: 932, Training Loss = 0.9354254007339478\n","Epoch: 933, Training Loss = 0.9353719353675842\n","Epoch: 934, Training Loss = 0.935318648815155\n","Epoch: 935, Training Loss = 0.9352654814720154\n","Epoch: 936, Training Loss = 0.9352124929428101\n","Epoch: 937, Training Loss = 0.9351593255996704\n","Epoch: 938, Training Loss = 0.9351065158843994\n","Epoch: 939, Training Loss = 0.935053825378418\n","Epoch: 940, Training Loss = 0.9350010752677917\n","Accuracy =  0.6835841536521912 F1 weighted =  0.5562019348144531 F1 macro =  0.20335283875465393\n","Epoch: 941, Training Loss = 0.9349485635757446\n","Epoch: 942, Training Loss = 0.9348962306976318\n","Epoch: 943, Training Loss = 0.9348438382148743\n","Epoch: 944, Training Loss = 0.9347915649414062\n","Epoch: 945, Training Loss = 0.9347396492958069\n","Epoch: 946, Training Loss = 0.9346875548362732\n","Epoch: 947, Training Loss = 0.934635579586029\n","Epoch: 948, Training Loss = 0.9345837235450745\n","Epoch: 949, Training Loss = 0.9345322251319885\n","Epoch: 950, Training Loss = 0.9344804286956787\n","Accuracy =  0.6837149858474731 F1 weighted =  0.5562458634376526 F1 macro =  0.20331446826457977\n","Epoch: 951, Training Loss = 0.9344289302825928\n","Epoch: 952, Training Loss = 0.9343777894973755\n","Epoch: 953, Training Loss = 0.9343264102935791\n","Epoch: 954, Training Loss = 0.9342751502990723\n","Epoch: 955, Training Loss = 0.9342240691184998\n","Epoch: 956, Training Loss = 0.9341732263565063\n","Epoch: 957, Training Loss = 0.9341222047805786\n","Epoch: 958, Training Loss = 0.9340714812278748\n","Epoch: 959, Training Loss = 0.9340207576751709\n","Epoch: 960, Training Loss = 0.9339701533317566\n","Accuracy =  0.683806836605072 F1 weighted =  0.5562756061553955 F1 macro =  0.20332664251327515\n","Epoch: 961, Training Loss = 0.9339196085929871\n","Epoch: 962, Training Loss = 0.9338692426681519\n","Epoch: 963, Training Loss = 0.9338189959526062\n","Epoch: 964, Training Loss = 0.9337686896324158\n","Epoch: 965, Training Loss = 0.9337185621261597\n","Epoch: 966, Training Loss = 0.9336686134338379\n","Epoch: 967, Training Loss = 0.9336186647415161\n","Epoch: 968, Training Loss = 0.9335688352584839\n","Epoch: 969, Training Loss = 0.9335190057754517\n","Epoch: 970, Training Loss = 0.9334694147109985\n","Accuracy =  0.6839126348495483 F1 weighted =  0.5563102960586548 F1 macro =  0.2033408135175705\n","Epoch: 971, Training Loss = 0.9334196448326111\n","Epoch: 972, Training Loss = 0.9333702325820923\n","Epoch: 973, Training Loss = 0.9333208203315735\n","Epoch: 974, Training Loss = 0.9332715272903442\n","Epoch: 975, Training Loss = 0.9332222938537598\n","Epoch: 976, Training Loss = 0.9331731796264648\n","Epoch: 977, Training Loss = 0.9331240653991699\n","Epoch: 978, Training Loss = 0.9330750107765198\n","Epoch: 979, Training Loss = 0.9330261945724487\n","Epoch: 980, Training Loss = 0.9329773783683777\n","Accuracy =  0.6840267777442932 F1 weighted =  0.5563563108444214 F1 macro =  0.20335900783538818\n","Epoch: 981, Training Loss = 0.9329285621643066\n","Epoch: 982, Training Loss = 0.9328799247741699\n","Epoch: 983, Training Loss = 0.9328314661979675\n","Epoch: 984, Training Loss = 0.9327828288078308\n","Epoch: 985, Training Loss = 0.9327345490455627\n","Epoch: 986, Training Loss = 0.9326863288879395\n","Epoch: 987, Training Loss = 0.9326380491256714\n","Epoch: 988, Training Loss = 0.9325897693634033\n","Epoch: 989, Training Loss = 0.9325418472290039\n","Epoch: 990, Training Loss = 0.9324936866760254\n","Accuracy =  0.6841047406196594 F1 weighted =  0.5563867092132568 F1 macro =  0.2033710926771164\n","Epoch: 991, Training Loss = 0.9324458241462708\n","Epoch: 992, Training Loss = 0.9323980212211609\n","Epoch: 993, Training Loss = 0.9323501586914062\n","Epoch: 994, Training Loss = 0.9323025345802307\n","Epoch: 995, Training Loss = 0.9322550296783447\n","Epoch: 996, Training Loss = 0.9322073459625244\n","Epoch: 997, Training Loss = 0.932159960269928\n","Epoch: 998, Training Loss = 0.9321125149726868\n","Epoch: 999, Training Loss = 0.9320652484893799\n","Epoch: 1000, Training Loss = 0.9320181012153625\n","Accuracy =  0.6841715574264526 F1 weighted =  0.5564090013504028 F1 macro =  0.20338019728660583\n","Epoch: 1001, Training Loss = 0.9319708347320557\n","Epoch: 1002, Training Loss = 0.9319238066673279\n","Epoch: 1003, Training Loss = 0.9318765997886658\n","Epoch: 1004, Training Loss = 0.9318297505378723\n","Epoch: 1005, Training Loss = 0.9317829012870789\n","Epoch: 1006, Training Loss = 0.9317360520362854\n","Epoch: 1007, Training Loss = 0.931689441204071\n","Epoch: 1008, Training Loss = 0.9316427707672119\n","Epoch: 1009, Training Loss = 0.9315961003303528\n","Epoch: 1010, Training Loss = 0.931549608707428\n","Accuracy =  0.6842495203018188 F1 weighted =  0.5564374327659607 F1 macro =  0.2033916562795639\n","Epoch: 1011, Training Loss = 0.931503176689148\n","Epoch: 1012, Training Loss = 0.9314568042755127\n","Epoch: 1013, Training Loss = 0.931410551071167\n","Epoch: 1014, Training Loss = 0.9313642382621765\n","Epoch: 1015, Training Loss = 0.9313181042671204\n","Epoch: 1016, Training Loss = 0.9312718510627747\n","Epoch: 1017, Training Loss = 0.9312260746955872\n","Epoch: 1018, Training Loss = 0.9311801195144653\n","Epoch: 1019, Training Loss = 0.931134045124054\n","Epoch: 1020, Training Loss = 0.9310882687568665\n","Accuracy =  0.6843135356903076 F1 weighted =  0.5564502477645874 F1 macro =  0.20328013598918915\n","Epoch: 1021, Training Loss = 0.931042492389679\n","Epoch: 1022, Training Loss = 0.930996835231781\n","Epoch: 1023, Training Loss = 0.9309511780738831\n","Epoch: 1024, Training Loss = 0.9309055209159851\n","Epoch: 1025, Training Loss = 0.9308600425720215\n","Epoch: 1026, Training Loss = 0.9308145046234131\n","Epoch: 1027, Training Loss = 0.9307690858840942\n","Epoch: 1028, Training Loss = 0.9307239055633545\n","Epoch: 1029, Training Loss = 0.9306785464286804\n","Epoch: 1030, Training Loss = 0.9306334257125854\n","Accuracy =  0.6844026446342468 F1 weighted =  0.5564886331558228 F1 macro =  0.20329469442367554\n","Epoch: 1031, Training Loss = 0.9305881857872009\n","Epoch: 1032, Training Loss = 0.9305431842803955\n","Epoch: 1033, Training Loss = 0.9304980635643005\n","Epoch: 1034, Training Loss = 0.9304531216621399\n","Epoch: 1035, Training Loss = 0.930408239364624\n","Epoch: 1036, Training Loss = 0.9303633570671082\n","Epoch: 1037, Training Loss = 0.9303186535835266\n","Epoch: 1038, Training Loss = 0.9302738308906555\n","Epoch: 1039, Training Loss = 0.9302291870117188\n","Epoch: 1040, Training Loss = 0.9301846623420715\n","Accuracy =  0.6844805479049683 F1 weighted =  0.5565226674079895 F1 macro =  0.20330756902694702\n","Epoch: 1041, Training Loss = 0.9301402568817139\n","Epoch: 1042, Training Loss = 0.9300956130027771\n","Epoch: 1043, Training Loss = 0.9300511479377747\n","Epoch: 1044, Training Loss = 0.9300068020820618\n","Epoch: 1045, Training Loss = 0.9299625754356384\n","Epoch: 1046, Training Loss = 0.9299183487892151\n","Epoch: 1047, Training Loss = 0.929874062538147\n","Epoch: 1048, Training Loss = 0.929830014705658\n","Epoch: 1049, Training Loss = 0.9297859072685242\n","Epoch: 1050, Training Loss = 0.9297418594360352\n","Accuracy =  0.6845362782478333 F1 weighted =  0.5565431118011475 F1 macro =  0.20331543684005737\n","Epoch: 1051, Training Loss = 0.9296978116035461\n","Epoch: 1052, Training Loss = 0.9296539425849915\n","Epoch: 1053, Training Loss = 0.929610013961792\n","Epoch: 1054, Training Loss = 0.9295662045478821\n","Epoch: 1055, Training Loss = 0.9295225739479065\n","Epoch: 1056, Training Loss = 0.9294787645339966\n","Epoch: 1057, Training Loss = 0.9294351935386658\n","Epoch: 1058, Training Loss = 0.929391622543335\n","Epoch: 1059, Training Loss = 0.9293481111526489\n","Epoch: 1060, Training Loss = 0.9293046593666077\n","Accuracy =  0.6845808029174805 F1 weighted =  0.556556761264801 F1 macro =  0.20326128602027893\n","Epoch: 1061, Training Loss = 0.9292611479759216\n","Epoch: 1062, Training Loss = 0.9292176961898804\n","Epoch: 1063, Training Loss = 0.9291744232177734\n","Epoch: 1064, Training Loss = 0.9291311502456665\n","Epoch: 1065, Training Loss = 0.9290879368782043\n","Epoch: 1066, Training Loss = 0.929044783115387\n","Epoch: 1067, Training Loss = 0.9290015697479248\n","Epoch: 1068, Training Loss = 0.928958535194397\n","Epoch: 1069, Training Loss = 0.9289155006408691\n","Epoch: 1070, Training Loss = 0.9288725256919861\n","Accuracy =  0.6845919489860535 F1 weighted =  0.5565515756607056 F1 macro =  0.20319993793964386\n","Epoch: 1071, Training Loss = 0.9288296699523926\n","Epoch: 1072, Training Loss = 0.9287867546081543\n","Epoch: 1073, Training Loss = 0.9287440180778503\n","Epoch: 1074, Training Loss = 0.9287011027336121\n","Epoch: 1075, Training Loss = 0.9286585450172424\n","Epoch: 1076, Training Loss = 0.928615927696228\n","Epoch: 1077, Training Loss = 0.9285731315612793\n","Epoch: 1078, Training Loss = 0.9285306930541992\n","Epoch: 1079, Training Loss = 0.9284880757331848\n","Epoch: 1080, Training Loss = 0.9284457564353943\n","Accuracy =  0.6846197843551636 F1 weighted =  0.556561291217804 F1 macro =  0.2032034993171692\n","Epoch: 1081, Training Loss = 0.9284032583236694\n","Epoch: 1082, Training Loss = 0.9283610582351685\n","Epoch: 1083, Training Loss = 0.9283186197280884\n","Epoch: 1084, Training Loss = 0.9282762408256531\n","Epoch: 1085, Training Loss = 0.9282341599464417\n","Epoch: 1086, Training Loss = 0.9281919002532959\n","Epoch: 1087, Training Loss = 0.9281496405601501\n","Epoch: 1088, Training Loss = 0.9281076788902283\n","Epoch: 1089, Training Loss = 0.9280656576156616\n","Epoch: 1090, Training Loss = 0.928023636341095\n","Accuracy =  0.6846504211425781 F1 weighted =  0.556574285030365 F1 macro =  0.20320823788642883\n","Epoch: 1091, Training Loss = 0.9279816746711731\n","Epoch: 1092, Training Loss = 0.9279398322105408\n","Epoch: 1093, Training Loss = 0.9278979301452637\n","Epoch: 1094, Training Loss = 0.9278561472892761\n","Epoch: 1095, Training Loss = 0.9278143644332886\n","Epoch: 1096, Training Loss = 0.9277725219726562\n","Epoch: 1097, Training Loss = 0.9277308583259583\n","Epoch: 1098, Training Loss = 0.927689254283905\n","Epoch: 1099, Training Loss = 0.9276477694511414\n","Epoch: 1100, Training Loss = 0.9276062250137329\n","Accuracy =  0.6846671104431152 F1 weighted =  0.5565786361694336 F1 macro =  0.20320981740951538\n","Epoch: 1101, Training Loss = 0.9275647401809692\n","Epoch: 1102, Training Loss = 0.9275232553482056\n","Epoch: 1103, Training Loss = 0.9274817705154419\n","Epoch: 1104, Training Loss = 0.9274404644966125\n","Epoch: 1105, Training Loss = 0.9273991584777832\n","Epoch: 1106, Training Loss = 0.9273578524589539\n","Epoch: 1107, Training Loss = 0.9273164868354797\n","Epoch: 1108, Training Loss = 0.9272753596305847\n","Epoch: 1109, Training Loss = 0.9272343516349792\n","Epoch: 1110, Training Loss = 0.9271931648254395\n","Accuracy =  0.6846754550933838 F1 weighted =  0.5565789341926575 F1 macro =  0.20320993661880493\n","Epoch: 1111, Training Loss = 0.9271520972251892\n","Epoch: 1112, Training Loss = 0.927111029624939\n","Epoch: 1113, Training Loss = 0.9270700812339783\n","Epoch: 1114, Training Loss = 0.9270291328430176\n","Epoch: 1115, Training Loss = 0.9269883036613464\n","Epoch: 1116, Training Loss = 0.9269474744796753\n","Epoch: 1117, Training Loss = 0.9269065856933594\n","Epoch: 1118, Training Loss = 0.9268658757209778\n","Epoch: 1119, Training Loss = 0.9268250465393066\n","Epoch: 1120, Training Loss = 0.926784336566925\n","Accuracy =  0.6846782565116882 F1 weighted =  0.5565794110298157 F1 macro =  0.20321010053157806\n","Epoch: 1121, Training Loss = 0.9267438054084778\n","Epoch: 1122, Training Loss = 0.9267032146453857\n","Epoch: 1123, Training Loss = 0.9266625642776489\n","Epoch: 1124, Training Loss = 0.9266220331192017\n","Epoch: 1125, Training Loss = 0.9265815615653992\n","Epoch: 1126, Training Loss = 0.926541268825531\n","Epoch: 1127, Training Loss = 0.9265007376670837\n","Epoch: 1128, Training Loss = 0.9264603853225708\n","Epoch: 1129, Training Loss = 0.9264200329780579\n","Epoch: 1130, Training Loss = 0.9263798594474792\n","Accuracy =  0.6846866011619568 F1 weighted =  0.556580662727356 F1 macro =  0.20321056246757507\n","Epoch: 1131, Training Loss = 0.9263396263122559\n","Epoch: 1132, Training Loss = 0.9262993931770325\n","Epoch: 1133, Training Loss = 0.9262592196464539\n","Epoch: 1134, Training Loss = 0.92621910572052\n","Epoch: 1135, Training Loss = 0.9261789917945862\n","Epoch: 1136, Training Loss = 0.9261389970779419\n","Epoch: 1137, Training Loss = 0.9260989427566528\n","Epoch: 1138, Training Loss = 0.9260589480400085\n","Epoch: 1139, Training Loss = 0.926019012928009\n","Epoch: 1140, Training Loss = 0.9259791970252991\n","Accuracy =  0.6846921443939209 F1 weighted =  0.5565834641456604 F1 macro =  0.20321157574653625\n","Epoch: 1141, Training Loss = 0.9259393215179443\n","Epoch: 1142, Training Loss = 0.9258996248245239\n","Epoch: 1143, Training Loss = 0.9258597493171692\n","Epoch: 1144, Training Loss = 0.9258199334144592\n","Epoch: 1145, Training Loss = 0.9257804155349731\n","Epoch: 1146, Training Loss = 0.9257407188415527\n","Epoch: 1147, Training Loss = 0.9257010817527771\n","Epoch: 1148, Training Loss = 0.925661563873291\n","Epoch: 1149, Training Loss = 0.9256219267845154\n","Epoch: 1150, Training Loss = 0.9255824089050293\n","Accuracy =  0.6847144365310669 F1 weighted =  0.5565932393074036 F1 macro =  0.20321515202522278\n","Epoch: 1151, Training Loss = 0.9255430102348328\n","Epoch: 1152, Training Loss = 0.9255035519599915\n","Epoch: 1153, Training Loss = 0.9254642128944397\n","Epoch: 1154, Training Loss = 0.9254248738288879\n","Epoch: 1155, Training Loss = 0.925385594367981\n","Epoch: 1156, Training Loss = 0.9253461360931396\n","Epoch: 1157, Training Loss = 0.9253069758415222\n","Epoch: 1158, Training Loss = 0.9252676963806152\n","Epoch: 1159, Training Loss = 0.9252285361289978\n","Epoch: 1160, Training Loss = 0.9251894354820251\n","Accuracy =  0.6847172379493713 F1 weighted =  0.5565944910049438 F1 macro =  0.2032156139612198\n","Epoch: 1161, Training Loss = 0.9251502156257629\n","Epoch: 1162, Training Loss = 0.9251112341880798\n","Epoch: 1163, Training Loss = 0.9250723123550415\n","Epoch: 1164, Training Loss = 0.9250332713127136\n","Epoch: 1165, Training Loss = 0.9249942302703857\n","Epoch: 1166, Training Loss = 0.9249553084373474\n","Epoch: 1167, Training Loss = 0.9249165654182434\n","Epoch: 1168, Training Loss = 0.9248776435852051\n","Epoch: 1169, Training Loss = 0.9248388409614563\n","Epoch: 1170, Training Loss = 0.9248000383377075\n","Accuracy =  0.6847172379493713 F1 weighted =  0.5565944910049438 F1 macro =  0.2032156139612198\n","Epoch: 1171, Training Loss = 0.9247612953186035\n","Epoch: 1172, Training Loss = 0.9247225522994995\n","Epoch: 1173, Training Loss = 0.9246838688850403\n","Epoch: 1174, Training Loss = 0.9246453046798706\n","Epoch: 1175, Training Loss = 0.9246066212654114\n","Epoch: 1176, Training Loss = 0.9245681166648865\n","Epoch: 1177, Training Loss = 0.9245295524597168\n","Epoch: 1178, Training Loss = 0.9244910478591919\n","Epoch: 1179, Training Loss = 0.9244527220726013\n","Epoch: 1180, Training Loss = 0.9244142174720764\n","Accuracy =  0.684719979763031 F1 weighted =  0.556594967842102 F1 macro =  0.2032157927751541\n","Epoch: 1181, Training Loss = 0.9243758320808411\n","Epoch: 1182, Training Loss = 0.9243373274803162\n","Epoch: 1183, Training Loss = 0.9242991209030151\n","Epoch: 1184, Training Loss = 0.9242607951164246\n","Epoch: 1185, Training Loss = 0.9242225289344788\n","Epoch: 1186, Training Loss = 0.9241843223571777\n","Epoch: 1187, Training Loss = 0.9241461753845215\n","Epoch: 1188, Training Loss = 0.92410808801651\n","Epoch: 1189, Training Loss = 0.9240700006484985\n","Epoch: 1190, Training Loss = 0.9240319132804871\n","Accuracy =  0.6847227811813354 F1 weighted =  0.5565963387489319 F1 macro =  0.2032162845134735\n","Epoch: 1191, Training Loss = 0.923993706703186\n","Epoch: 1192, Training Loss = 0.9239556789398193\n","Epoch: 1193, Training Loss = 0.9239177703857422\n","Epoch: 1194, Training Loss = 0.9238799214363098\n","Epoch: 1195, Training Loss = 0.9238419532775879\n","Epoch: 1196, Training Loss = 0.9238040447235107\n","Epoch: 1197, Training Loss = 0.9237661957740784\n","Epoch: 1198, Training Loss = 0.9237285256385803\n","Epoch: 1199, Training Loss = 0.9236905574798584\n","Epoch: 1200, Training Loss = 0.9236528277397156\n","Accuracy =  0.6847227811813354 F1 weighted =  0.5565953850746155 F1 macro =  0.20321594178676605\n","Epoch: 1201, Training Loss = 0.9236152172088623\n","Epoch: 1202, Training Loss = 0.9235775470733643\n","Epoch: 1203, Training Loss = 0.9235398173332214\n","Epoch: 1204, Training Loss = 0.9235022664070129\n","Epoch: 1205, Training Loss = 0.9234645366668701\n","Epoch: 1206, Training Loss = 0.9234271049499512\n","Epoch: 1207, Training Loss = 0.9233895540237427\n","Epoch: 1208, Training Loss = 0.9233521223068237\n","Epoch: 1209, Training Loss = 0.92331463098526\n","Epoch: 1210, Training Loss = 0.9232773184776306\n","Accuracy =  0.6847227811813354 F1 weighted =  0.5565944910049438 F1 macro =  0.2032156139612198\n","Epoch: 1211, Training Loss = 0.9232398867607117\n","Epoch: 1212, Training Loss = 0.9232025146484375\n","Epoch: 1213, Training Loss = 0.9231652617454529\n","Epoch: 1214, Training Loss = 0.9231280088424683\n","Epoch: 1215, Training Loss = 0.9230907559394836\n","Epoch: 1216, Training Loss = 0.9230534434318542\n","Epoch: 1217, Training Loss = 0.9230162501335144\n","Epoch: 1218, Training Loss = 0.9229791760444641\n","Epoch: 1219, Training Loss = 0.9229419231414795\n","Epoch: 1220, Training Loss = 0.9229047894477844\n","Accuracy =  0.6847255825996399 F1 weighted =  0.5565958619117737 F1 macro =  0.20321610569953918\n","Epoch: 1221, Training Loss = 0.9228678345680237\n","Epoch: 1222, Training Loss = 0.9228307604789734\n","Epoch: 1223, Training Loss = 0.9227938055992126\n","Epoch: 1224, Training Loss = 0.9227569103240967\n","Epoch: 1225, Training Loss = 0.9227198958396912\n","Epoch: 1226, Training Loss = 0.9226829409599304\n","Epoch: 1227, Training Loss = 0.922646164894104\n","Epoch: 1228, Training Loss = 0.922609269618988\n","Epoch: 1229, Training Loss = 0.9225724339485168\n","Epoch: 1230, Training Loss = 0.9225357174873352\n","Accuracy =  0.6847255825996399 F1 weighted =  0.5565958619117737 F1 macro =  0.20321610569953918\n","Epoch: 1231, Training Loss = 0.9224990010261536\n","Epoch: 1232, Training Loss = 0.9224622845649719\n","Epoch: 1233, Training Loss = 0.9224255681037903\n","Epoch: 1234, Training Loss = 0.9223889708518982\n","Epoch: 1235, Training Loss = 0.9223523139953613\n","Epoch: 1236, Training Loss = 0.922315776348114\n","Epoch: 1237, Training Loss = 0.9222791790962219\n","Epoch: 1238, Training Loss = 0.9222426414489746\n","Epoch: 1239, Training Loss = 0.9222061038017273\n","Epoch: 1240, Training Loss = 0.9221696853637695\n","Accuracy =  0.684731125831604 F1 weighted =  0.5565975904464722 F1 macro =  0.20321673154830933\n","Epoch: 1241, Training Loss = 0.9221332669258118\n","Epoch: 1242, Training Loss = 0.9220969676971436\n","Epoch: 1243, Training Loss = 0.9220606088638306\n","Epoch: 1244, Training Loss = 0.922024130821228\n","Epoch: 1245, Training Loss = 0.9219878315925598\n","Epoch: 1246, Training Loss = 0.9219516515731812\n","Epoch: 1247, Training Loss = 0.9219153523445129\n","Epoch: 1248, Training Loss = 0.9218791127204895\n","Epoch: 1249, Training Loss = 0.9218429327011108\n","Epoch: 1250, Training Loss = 0.9218067526817322\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1251, Training Loss = 0.9217706918716431\n","Epoch: 1252, Training Loss = 0.9217345714569092\n","Epoch: 1253, Training Loss = 0.9216985702514648\n","Epoch: 1254, Training Loss = 0.9216625094413757\n","Epoch: 1255, Training Loss = 0.9216264486312866\n","Epoch: 1256, Training Loss = 0.9215905070304871\n","Epoch: 1257, Training Loss = 0.9215545654296875\n","Epoch: 1258, Training Loss = 0.9215185642242432\n","Epoch: 1259, Training Loss = 0.9214826822280884\n","Epoch: 1260, Training Loss = 0.9214468598365784\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1261, Training Loss = 0.9214110374450684\n","Epoch: 1262, Training Loss = 0.9213752746582031\n","Epoch: 1263, Training Loss = 0.9213395714759827\n","Epoch: 1264, Training Loss = 0.9213038682937622\n","Epoch: 1265, Training Loss = 0.9212680459022522\n","Epoch: 1266, Training Loss = 0.9212325811386108\n","Epoch: 1267, Training Loss = 0.9211968779563904\n","Epoch: 1268, Training Loss = 0.9211611151695251\n","Epoch: 1269, Training Loss = 0.921125590801239\n","Epoch: 1270, Training Loss = 0.9210900664329529\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1271, Training Loss = 0.9210546016693115\n","Epoch: 1272, Training Loss = 0.9210190773010254\n","Epoch: 1273, Training Loss = 0.920983612537384\n","Epoch: 1274, Training Loss = 0.9209482073783875\n","Epoch: 1275, Training Loss = 0.9209128618240356\n","Epoch: 1276, Training Loss = 0.9208775758743286\n","Epoch: 1277, Training Loss = 0.920842170715332\n","Epoch: 1278, Training Loss = 0.920806884765625\n","Epoch: 1279, Training Loss = 0.9207715392112732\n","Epoch: 1280, Training Loss = 0.9207363724708557\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1281, Training Loss = 0.9207011461257935\n","Epoch: 1282, Training Loss = 0.920665979385376\n","Epoch: 1283, Training Loss = 0.9206307530403137\n","Epoch: 1284, Training Loss = 0.9205957055091858\n","Epoch: 1285, Training Loss = 0.9205605387687683\n","Epoch: 1286, Training Loss = 0.9205254912376404\n","Epoch: 1287, Training Loss = 0.9204904437065125\n","Epoch: 1288, Training Loss = 0.9204553961753845\n","Epoch: 1289, Training Loss = 0.9204205274581909\n","Epoch: 1290, Training Loss = 0.9203855395317078\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1291, Training Loss = 0.9203504920005798\n","Epoch: 1292, Training Loss = 0.9203155636787415\n","Epoch: 1293, Training Loss = 0.9202807545661926\n","Epoch: 1294, Training Loss = 0.9202460050582886\n","Epoch: 1295, Training Loss = 0.9202110767364502\n","Epoch: 1296, Training Loss = 0.9201763868331909\n","Epoch: 1297, Training Loss = 0.9201416373252869\n","Epoch: 1298, Training Loss = 0.9201069474220276\n","Epoch: 1299, Training Loss = 0.9200721979141235\n","Epoch: 1300, Training Loss = 0.9200374484062195\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1301, Training Loss = 0.9200028777122498\n","Epoch: 1302, Training Loss = 0.91996830701828\n","Epoch: 1303, Training Loss = 0.9199336767196655\n","Epoch: 1304, Training Loss = 0.9198992252349854\n","Epoch: 1305, Training Loss = 0.9198645353317261\n","Epoch: 1306, Training Loss = 0.9198302030563354\n","Epoch: 1307, Training Loss = 0.9197957515716553\n","Epoch: 1308, Training Loss = 0.9197613000869751\n","Epoch: 1309, Training Loss = 0.9197268486022949\n","Epoch: 1310, Training Loss = 0.9196925163269043\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1311, Training Loss = 0.9196581244468689\n","Epoch: 1312, Training Loss = 0.9196237921714783\n","Epoch: 1313, Training Loss = 0.9195895195007324\n","Epoch: 1314, Training Loss = 0.9195553660392761\n","Epoch: 1315, Training Loss = 0.919521152973175\n","Epoch: 1316, Training Loss = 0.9194868206977844\n","Epoch: 1317, Training Loss = 0.9194526672363281\n","Epoch: 1318, Training Loss = 0.919418454170227\n","Epoch: 1319, Training Loss = 0.9193843603134155\n","Epoch: 1320, Training Loss = 0.919350266456604\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1321, Training Loss = 0.919316291809082\n","Epoch: 1322, Training Loss = 0.9192822575569153\n","Epoch: 1323, Training Loss = 0.9192482829093933\n","Epoch: 1324, Training Loss = 0.9192142486572266\n","Epoch: 1325, Training Loss = 0.9191802740097046\n","Epoch: 1326, Training Loss = 0.9191464781761169\n","Epoch: 1327, Training Loss = 0.9191125631332397\n","Epoch: 1328, Training Loss = 0.9190787076950073\n","Epoch: 1329, Training Loss = 0.9190448522567749\n","Epoch: 1330, Training Loss = 0.9190110564231873\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1331, Training Loss = 0.9189772605895996\n","Epoch: 1332, Training Loss = 0.9189435243606567\n","Epoch: 1333, Training Loss = 0.9189098477363586\n","Epoch: 1334, Training Loss = 0.9188761115074158\n","Epoch: 1335, Training Loss = 0.9188424348831177\n","Epoch: 1336, Training Loss = 0.9188088178634644\n","Epoch: 1337, Training Loss = 0.918775200843811\n","Epoch: 1338, Training Loss = 0.9187416434288025\n","Epoch: 1339, Training Loss = 0.918708086013794\n","Epoch: 1340, Training Loss = 0.918674647808075\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1341, Training Loss = 0.9186410903930664\n","Epoch: 1342, Training Loss = 0.918607771396637\n","Epoch: 1343, Training Loss = 0.9185742139816284\n","Epoch: 1344, Training Loss = 0.9185408353805542\n","Epoch: 1345, Training Loss = 0.9185073971748352\n","Epoch: 1346, Training Loss = 0.9184740781784058\n","Epoch: 1347, Training Loss = 0.9184408187866211\n","Epoch: 1348, Training Loss = 0.9184075593948364\n","Epoch: 1349, Training Loss = 0.9183743000030518\n","Epoch: 1350, Training Loss = 0.9183409214019775\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1351, Training Loss = 0.9183078408241272\n","Epoch: 1352, Training Loss = 0.9182746410369873\n","Epoch: 1353, Training Loss = 0.9182414412498474\n","Epoch: 1354, Training Loss = 0.9182083606719971\n","Epoch: 1355, Training Loss = 0.9181752800941467\n","Epoch: 1356, Training Loss = 0.9181421995162964\n","Epoch: 1357, Training Loss = 0.9181090593338013\n","Epoch: 1358, Training Loss = 0.9180760979652405\n","Epoch: 1359, Training Loss = 0.9180430769920349\n","Epoch: 1360, Training Loss = 0.9180101156234741\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1361, Training Loss = 0.9179772138595581\n","Epoch: 1362, Training Loss = 0.9179443120956421\n","Epoch: 1363, Training Loss = 0.9179114699363708\n","Epoch: 1364, Training Loss = 0.9178785085678101\n","Epoch: 1365, Training Loss = 0.9178457260131836\n","Epoch: 1366, Training Loss = 0.9178129434585571\n","Epoch: 1367, Training Loss = 0.9177801609039307\n","Epoch: 1368, Training Loss = 0.9177475571632385\n","Epoch: 1369, Training Loss = 0.9177148342132568\n","Epoch: 1370, Training Loss = 0.9176820516586304\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1371, Training Loss = 0.9176493883132935\n","Epoch: 1372, Training Loss = 0.9176167845726013\n","Epoch: 1373, Training Loss = 0.9175841212272644\n","Epoch: 1374, Training Loss = 0.9175516963005066\n","Epoch: 1375, Training Loss = 0.917519211769104\n","Epoch: 1376, Training Loss = 0.9174865484237671\n","Epoch: 1377, Training Loss = 0.9174541234970093\n","Epoch: 1378, Training Loss = 0.9174216985702515\n","Epoch: 1379, Training Loss = 0.9173893332481384\n","Epoch: 1380, Training Loss = 0.9173567891120911\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1381, Training Loss = 0.917324423789978\n","Epoch: 1382, Training Loss = 0.9172921180725098\n","Epoch: 1383, Training Loss = 0.9172597527503967\n","Epoch: 1384, Training Loss = 0.9172274470329285\n","Epoch: 1385, Training Loss = 0.9171953201293945\n","Epoch: 1386, Training Loss = 0.9171628952026367\n","Epoch: 1387, Training Loss = 0.9171306490898132\n","Epoch: 1388, Training Loss = 0.9170987010002136\n","Epoch: 1389, Training Loss = 0.9170663952827454\n","Epoch: 1390, Training Loss = 0.9170343279838562\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1391, Training Loss = 0.9170022010803223\n","Epoch: 1392, Training Loss = 0.9169700741767883\n","Epoch: 1393, Training Loss = 0.9169380068778992\n","Epoch: 1394, Training Loss = 0.9169061183929443\n","Epoch: 1395, Training Loss = 0.9168739914894104\n","Epoch: 1396, Training Loss = 0.9168421030044556\n","Epoch: 1397, Training Loss = 0.916810154914856\n","Epoch: 1398, Training Loss = 0.9167781472206116\n","Epoch: 1399, Training Loss = 0.9167463183403015\n","Epoch: 1400, Training Loss = 0.9167145490646362\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1401, Training Loss = 0.9166826605796814\n","Epoch: 1402, Training Loss = 0.9166508913040161\n","Epoch: 1403, Training Loss = 0.916619062423706\n","Epoch: 1404, Training Loss = 0.9165871739387512\n","Epoch: 1405, Training Loss = 0.9165557026863098\n","Epoch: 1406, Training Loss = 0.9165239334106445\n","Epoch: 1407, Training Loss = 0.9164924025535583\n","Epoch: 1408, Training Loss = 0.9164605736732483\n","Epoch: 1409, Training Loss = 0.9164290428161621\n","Epoch: 1410, Training Loss = 0.9163975119590759\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1411, Training Loss = 0.916365921497345\n","Epoch: 1412, Training Loss = 0.9163344502449036\n","Epoch: 1413, Training Loss = 0.9163029789924622\n","Epoch: 1414, Training Loss = 0.9162713289260864\n","Epoch: 1415, Training Loss = 0.9162400364875793\n","Epoch: 1416, Training Loss = 0.9162085056304932\n","Epoch: 1417, Training Loss = 0.9161770939826965\n","Epoch: 1418, Training Loss = 0.9161457419395447\n","Epoch: 1419, Training Loss = 0.9161144495010376\n","Epoch: 1420, Training Loss = 0.9160830974578857\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1421, Training Loss = 0.9160518646240234\n","Epoch: 1422, Training Loss = 0.9160206913948059\n","Epoch: 1423, Training Loss = 0.915989339351654\n","Epoch: 1424, Training Loss = 0.9159581065177917\n","Epoch: 1425, Training Loss = 0.915926992893219\n","Epoch: 1426, Training Loss = 0.9158958196640015\n","Epoch: 1427, Training Loss = 0.9158645868301392\n","Epoch: 1428, Training Loss = 0.915833592414856\n","Epoch: 1429, Training Loss = 0.9158025979995728\n","Epoch: 1430, Training Loss = 0.915771484375\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1431, Training Loss = 0.9157404899597168\n","Epoch: 1432, Training Loss = 0.9157094955444336\n","Epoch: 1433, Training Loss = 0.9156785607337952\n","Epoch: 1434, Training Loss = 0.915647566318512\n","Epoch: 1435, Training Loss = 0.9156166911125183\n","Epoch: 1436, Training Loss = 0.9155857563018799\n","Epoch: 1437, Training Loss = 0.915554940700531\n","Epoch: 1438, Training Loss = 0.9155241250991821\n","Epoch: 1439, Training Loss = 0.9154933094978333\n","Epoch: 1440, Training Loss = 0.9154625535011292\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1441, Training Loss = 0.915431797504425\n","Epoch: 1442, Training Loss = 0.9154011011123657\n","Epoch: 1443, Training Loss = 0.9153703451156616\n","Epoch: 1444, Training Loss = 0.9153396487236023\n","Epoch: 1445, Training Loss = 0.9153090715408325\n","Epoch: 1446, Training Loss = 0.915278434753418\n","Epoch: 1447, Training Loss = 0.915247917175293\n","Epoch: 1448, Training Loss = 0.9152172803878784\n","Epoch: 1449, Training Loss = 0.9151867032051086\n","Epoch: 1450, Training Loss = 0.9151561856269836\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1451, Training Loss = 0.9151257872581482\n","Epoch: 1452, Training Loss = 0.9150953888893127\n","Epoch: 1453, Training Loss = 0.9150648713111877\n","Epoch: 1454, Training Loss = 0.9150344133377075\n","Epoch: 1455, Training Loss = 0.9150040745735168\n","Epoch: 1456, Training Loss = 0.9149736762046814\n","Epoch: 1457, Training Loss = 0.9149434566497803\n","Epoch: 1458, Training Loss = 0.9149131774902344\n","Epoch: 1459, Training Loss = 0.9148828387260437\n","Epoch: 1460, Training Loss = 0.914852499961853\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1461, Training Loss = 0.9148224592208862\n","Epoch: 1462, Training Loss = 0.9147922396659851\n","Epoch: 1463, Training Loss = 0.914762020111084\n","Epoch: 1464, Training Loss = 0.9147318601608276\n","Epoch: 1465, Training Loss = 0.9147018790245056\n","Epoch: 1466, Training Loss = 0.9146717190742493\n","Epoch: 1467, Training Loss = 0.9146417379379272\n","Epoch: 1468, Training Loss = 0.91461181640625\n","Epoch: 1469, Training Loss = 0.9145816564559937\n","Epoch: 1470, Training Loss = 0.9145517349243164\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1471, Training Loss = 0.9145218729972839\n","Epoch: 1472, Training Loss = 0.9144918918609619\n","Epoch: 1473, Training Loss = 0.9144619703292847\n","Epoch: 1474, Training Loss = 0.9144321084022522\n","Epoch: 1475, Training Loss = 0.9144023060798645\n","Epoch: 1476, Training Loss = 0.914372444152832\n","Epoch: 1477, Training Loss = 0.9143426418304443\n","Epoch: 1478, Training Loss = 0.9143129587173462\n","Epoch: 1479, Training Loss = 0.9142831563949585\n","Epoch: 1480, Training Loss = 0.9142534732818604\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1481, Training Loss = 0.9142237901687622\n","Epoch: 1482, Training Loss = 0.9141941666603088\n","Epoch: 1483, Training Loss = 0.9141645431518555\n","Epoch: 1484, Training Loss = 0.9141349196434021\n","Epoch: 1485, Training Loss = 0.9141052961349487\n","Epoch: 1486, Training Loss = 0.9140756726264954\n","Epoch: 1487, Training Loss = 0.9140462875366211\n","Epoch: 1488, Training Loss = 0.9140167236328125\n","Epoch: 1489, Training Loss = 0.9139872193336487\n","Epoch: 1490, Training Loss = 0.9139578342437744\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1491, Training Loss = 0.9139285087585449\n","Epoch: 1492, Training Loss = 0.9138990044593811\n","Epoch: 1493, Training Loss = 0.9138696193695068\n","Epoch: 1494, Training Loss = 0.9138403534889221\n","Epoch: 1495, Training Loss = 0.9138110280036926\n","Epoch: 1496, Training Loss = 0.9137817025184631\n","Epoch: 1497, Training Loss = 0.9137524366378784\n","Epoch: 1498, Training Loss = 0.9137232303619385\n","Epoch: 1499, Training Loss = 0.9136940836906433\n","Epoch: 1500, Training Loss = 0.9136648178100586\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1501, Training Loss = 0.9136356711387634\n","Epoch: 1502, Training Loss = 0.9136064648628235\n","Epoch: 1503, Training Loss = 0.9135774374008179\n","Epoch: 1504, Training Loss = 0.9135484099388123\n","Epoch: 1505, Training Loss = 0.9135193228721619\n","Epoch: 1506, Training Loss = 0.913490355014801\n","Epoch: 1507, Training Loss = 0.9134613275527954\n","Epoch: 1508, Training Loss = 0.9134323000907898\n","Epoch: 1509, Training Loss = 0.913403332233429\n","Epoch: 1510, Training Loss = 0.9133744835853577\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1511, Training Loss = 0.9133455157279968\n","Epoch: 1512, Training Loss = 0.9133167862892151\n","Epoch: 1513, Training Loss = 0.913287878036499\n","Epoch: 1514, Training Loss = 0.9132590889930725\n","Epoch: 1515, Training Loss = 0.9132302403450012\n","Epoch: 1516, Training Loss = 0.9132015109062195\n","Epoch: 1517, Training Loss = 0.913172721862793\n","Epoch: 1518, Training Loss = 0.913144052028656\n","Epoch: 1519, Training Loss = 0.913115382194519\n","Epoch: 1520, Training Loss = 0.9130867719650269\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1521, Training Loss = 0.9130581021308899\n","Epoch: 1522, Training Loss = 0.9130294322967529\n","Epoch: 1523, Training Loss = 0.9130008816719055\n","Epoch: 1524, Training Loss = 0.9129722714424133\n","Epoch: 1525, Training Loss = 0.9129438400268555\n","Epoch: 1526, Training Loss = 0.9129153490066528\n","Epoch: 1527, Training Loss = 0.9128868579864502\n","Epoch: 1528, Training Loss = 0.9128584265708923\n","Epoch: 1529, Training Loss = 0.9128300547599792\n","Epoch: 1530, Training Loss = 0.9128016233444214\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1531, Training Loss = 0.9127732515335083\n","Epoch: 1532, Training Loss = 0.9127448797225952\n","Epoch: 1533, Training Loss = 0.9127166271209717\n","Epoch: 1534, Training Loss = 0.9126882553100586\n","Epoch: 1535, Training Loss = 0.9126601219177246\n","Epoch: 1536, Training Loss = 0.9126317501068115\n","Epoch: 1537, Training Loss = 0.9126036167144775\n","Epoch: 1538, Training Loss = 0.9125754833221436\n","Epoch: 1539, Training Loss = 0.91254723072052\n","Epoch: 1540, Training Loss = 0.912519097328186\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1541, Training Loss = 0.912490963935852\n","Epoch: 1542, Training Loss = 0.9124627709388733\n","Epoch: 1543, Training Loss = 0.9124347567558289\n","Epoch: 1544, Training Loss = 0.912406861782074\n","Epoch: 1545, Training Loss = 0.9123787879943848\n","Epoch: 1546, Training Loss = 0.9123507142066956\n","Epoch: 1547, Training Loss = 0.9123228192329407\n","Epoch: 1548, Training Loss = 0.912294864654541\n","Epoch: 1549, Training Loss = 0.9122669696807861\n","Epoch: 1550, Training Loss = 0.912239134311676\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1551, Training Loss = 0.9122111797332764\n","Epoch: 1552, Training Loss = 0.912183403968811\n","Epoch: 1553, Training Loss = 0.9121556878089905\n","Epoch: 1554, Training Loss = 0.9121279120445251\n","Epoch: 1555, Training Loss = 0.9121001958847046\n","Epoch: 1556, Training Loss = 0.9120724201202393\n","Epoch: 1557, Training Loss = 0.9120447635650635\n","Epoch: 1558, Training Loss = 0.9120170474052429\n","Epoch: 1559, Training Loss = 0.9119894504547119\n","Epoch: 1560, Training Loss = 0.9119617938995361\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1561, Training Loss = 0.9119341969490051\n","Epoch: 1562, Training Loss = 0.9119066596031189\n","Epoch: 1563, Training Loss = 0.9118790626525879\n","Epoch: 1564, Training Loss = 0.9118514657020569\n","Epoch: 1565, Training Loss = 0.9118240475654602\n","Epoch: 1566, Training Loss = 0.911796510219574\n","Epoch: 1567, Training Loss = 0.9117691516876221\n","Epoch: 1568, Training Loss = 0.9117417335510254\n","Epoch: 1569, Training Loss = 0.9117143154144287\n","Epoch: 1570, Training Loss = 0.9116870164871216\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1571, Training Loss = 0.9116596579551697\n","Epoch: 1572, Training Loss = 0.9116322994232178\n","Epoch: 1573, Training Loss = 0.9116050601005554\n","Epoch: 1574, Training Loss = 0.9115777611732483\n","Epoch: 1575, Training Loss = 0.9115506410598755\n","Epoch: 1576, Training Loss = 0.9115233421325684\n","Epoch: 1577, Training Loss = 0.9114962816238403\n","Epoch: 1578, Training Loss = 0.9114691019058228\n","Epoch: 1579, Training Loss = 0.9114419221878052\n","Epoch: 1580, Training Loss = 0.9114148020744324\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1581, Training Loss = 0.9113876819610596\n","Epoch: 1582, Training Loss = 0.9113606810569763\n","Epoch: 1583, Training Loss = 0.9113335609436035\n","Epoch: 1584, Training Loss = 0.9113065004348755\n","Epoch: 1585, Training Loss = 0.9112797379493713\n","Epoch: 1586, Training Loss = 0.9112527370452881\n","Epoch: 1587, Training Loss = 0.9112257957458496\n","Epoch: 1588, Training Loss = 0.9111989140510559\n","Epoch: 1589, Training Loss = 0.9111720323562622\n","Epoch: 1590, Training Loss = 0.9111452698707581\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1591, Training Loss = 0.9111183881759644\n","Epoch: 1592, Training Loss = 0.911091685295105\n","Epoch: 1593, Training Loss = 0.911064863204956\n","Epoch: 1594, Training Loss = 0.9110381007194519\n","Epoch: 1595, Training Loss = 0.9110113382339478\n","Epoch: 1596, Training Loss = 0.9109846949577332\n","Epoch: 1597, Training Loss = 0.910957932472229\n","Epoch: 1598, Training Loss = 0.9109312891960144\n","Epoch: 1599, Training Loss = 0.9109046459197998\n","Epoch: 1600, Training Loss = 0.9108781218528748\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1601, Training Loss = 0.9108515381813049\n","Epoch: 1602, Training Loss = 0.9108249545097351\n","Epoch: 1603, Training Loss = 0.9107985496520996\n","Epoch: 1604, Training Loss = 0.910771906375885\n","Epoch: 1605, Training Loss = 0.9107456207275391\n","Epoch: 1606, Training Loss = 0.9107190370559692\n","Epoch: 1607, Training Loss = 0.9106926918029785\n","Epoch: 1608, Training Loss = 0.910666286945343\n","Epoch: 1609, Training Loss = 0.9106399416923523\n","Epoch: 1610, Training Loss = 0.9106135368347168\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1611, Training Loss = 0.9105872511863708\n","Epoch: 1612, Training Loss = 0.9105609655380249\n","Epoch: 1613, Training Loss = 0.910534679889679\n","Epoch: 1614, Training Loss = 0.9105084538459778\n","Epoch: 1615, Training Loss = 0.9104822278022766\n","Epoch: 1616, Training Loss = 0.9104559421539307\n","Epoch: 1617, Training Loss = 0.9104298949241638\n","Epoch: 1618, Training Loss = 0.9104036688804626\n","Epoch: 1619, Training Loss = 0.9103776216506958\n","Epoch: 1620, Training Loss = 0.9103515148162842\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1621, Training Loss = 0.9103254079818726\n","Epoch: 1622, Training Loss = 0.9102994203567505\n","Epoch: 1623, Training Loss = 0.9102733731269836\n","Epoch: 1624, Training Loss = 0.9102473258972168\n","Epoch: 1625, Training Loss = 0.9102214574813843\n","Epoch: 1626, Training Loss = 0.910195529460907\n","Epoch: 1627, Training Loss = 0.9101696610450745\n","Epoch: 1628, Training Loss = 0.9101437330245972\n","Epoch: 1629, Training Loss = 0.9101178646087646\n","Epoch: 1630, Training Loss = 0.9100920557975769\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1631, Training Loss = 0.9100662469863892\n","Epoch: 1632, Training Loss = 0.9100404977798462\n","Epoch: 1633, Training Loss = 0.9100146293640137\n","Epoch: 1634, Training Loss = 0.9099889993667603\n","Epoch: 1635, Training Loss = 0.9099632501602173\n","Epoch: 1636, Training Loss = 0.9099375605583191\n","Epoch: 1637, Training Loss = 0.9099119901657104\n","Epoch: 1638, Training Loss = 0.9098863005638123\n","Epoch: 1639, Training Loss = 0.9098606109619141\n","Epoch: 1640, Training Loss = 0.9098351001739502\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1641, Training Loss = 0.9098095297813416\n","Epoch: 1642, Training Loss = 0.9097839593887329\n","Epoch: 1643, Training Loss = 0.9097583889961243\n","Epoch: 1644, Training Loss = 0.90973299741745\n","Epoch: 1645, Training Loss = 0.9097076058387756\n","Epoch: 1646, Training Loss = 0.9096822142601013\n","Epoch: 1647, Training Loss = 0.9096567630767822\n","Epoch: 1648, Training Loss = 0.9096313714981079\n","Epoch: 1649, Training Loss = 0.9096060991287231\n","Epoch: 1650, Training Loss = 0.9095807075500488\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1651, Training Loss = 0.9095553755760193\n","Epoch: 1652, Training Loss = 0.9095302224159241\n","Epoch: 1653, Training Loss = 0.9095048904418945\n","Epoch: 1654, Training Loss = 0.9094796776771545\n","Epoch: 1655, Training Loss = 0.9094545245170593\n","Epoch: 1656, Training Loss = 0.9094292521476746\n","Epoch: 1657, Training Loss = 0.9094039797782898\n","Epoch: 1658, Training Loss = 0.9093790054321289\n","Epoch: 1659, Training Loss = 0.9093537926673889\n","Epoch: 1660, Training Loss = 0.909328818321228\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1661, Training Loss = 0.9093037843704224\n","Epoch: 1662, Training Loss = 0.9092786908149719\n","Epoch: 1663, Training Loss = 0.9092536568641663\n","Epoch: 1664, Training Loss = 0.9092286825180054\n","Epoch: 1665, Training Loss = 0.9092035889625549\n","Epoch: 1666, Training Loss = 0.9091787338256836\n","Epoch: 1667, Training Loss = 0.909153938293457\n","Epoch: 1668, Training Loss = 0.9091290831565857\n","Epoch: 1669, Training Loss = 0.9091041088104248\n","Epoch: 1670, Training Loss = 0.909079372882843\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1671, Training Loss = 0.9090545773506165\n","Epoch: 1672, Training Loss = 0.9090297222137451\n","Epoch: 1673, Training Loss = 0.9090049266815186\n","Epoch: 1674, Training Loss = 0.9089802503585815\n","Epoch: 1675, Training Loss = 0.9089555740356445\n","Epoch: 1676, Training Loss = 0.9089308381080627\n","Epoch: 1677, Training Loss = 0.9089061617851257\n","Epoch: 1678, Training Loss = 0.9088816046714783\n","Epoch: 1679, Training Loss = 0.9088569283485413\n","Epoch: 1680, Training Loss = 0.9088323712348938\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1681, Training Loss = 0.9088076949119568\n","Epoch: 1682, Training Loss = 0.9087833166122437\n","Epoch: 1683, Training Loss = 0.9087587594985962\n","Epoch: 1684, Training Loss = 0.9087343811988831\n","Epoch: 1685, Training Loss = 0.9087098836898804\n","Epoch: 1686, Training Loss = 0.9086855053901672\n","Epoch: 1687, Training Loss = 0.9086610078811646\n","Epoch: 1688, Training Loss = 0.9086365699768066\n","Epoch: 1689, Training Loss = 0.9086121916770935\n","Epoch: 1690, Training Loss = 0.9085878729820251\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1691, Training Loss = 0.9085636138916016\n","Epoch: 1692, Training Loss = 0.9085392951965332\n","Epoch: 1693, Training Loss = 0.9085150957107544\n","Epoch: 1694, Training Loss = 0.908490777015686\n","Epoch: 1695, Training Loss = 0.9084665179252625\n","Epoch: 1696, Training Loss = 0.9084424376487732\n","Epoch: 1697, Training Loss = 0.9084182381629944\n","Epoch: 1698, Training Loss = 0.9083940982818604\n","Epoch: 1699, Training Loss = 0.9083699584007263\n","Epoch: 1700, Training Loss = 0.9083458781242371\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1701, Training Loss = 0.9083218574523926\n","Epoch: 1702, Training Loss = 0.9082977771759033\n","Epoch: 1703, Training Loss = 0.9082739353179932\n","Epoch: 1704, Training Loss = 0.9082499146461487\n","Epoch: 1705, Training Loss = 0.9082258939743042\n","Epoch: 1706, Training Loss = 0.9082019329071045\n","Epoch: 1707, Training Loss = 0.9081780314445496\n","Epoch: 1708, Training Loss = 0.9081541299819946\n","Epoch: 1709, Training Loss = 0.9081302881240845\n","Epoch: 1710, Training Loss = 0.9081064462661743\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1711, Training Loss = 0.9080826044082642\n","Epoch: 1712, Training Loss = 0.9080589413642883\n","Epoch: 1713, Training Loss = 0.9080350399017334\n","Epoch: 1714, Training Loss = 0.908011257648468\n","Epoch: 1715, Training Loss = 0.9079875946044922\n","Epoch: 1716, Training Loss = 0.9079638123512268\n","Epoch: 1717, Training Loss = 0.907940149307251\n","Epoch: 1718, Training Loss = 0.9079166650772095\n","Epoch: 1719, Training Loss = 0.9078930020332336\n","Epoch: 1720, Training Loss = 0.9078693389892578\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1721, Training Loss = 0.9078457355499268\n","Epoch: 1722, Training Loss = 0.9078221917152405\n","Epoch: 1723, Training Loss = 0.907798707485199\n","Epoch: 1724, Training Loss = 0.9077752232551575\n","Epoch: 1725, Training Loss = 0.9077516794204712\n","Epoch: 1726, Training Loss = 0.9077281951904297\n","Epoch: 1727, Training Loss = 0.9077048301696777\n","Epoch: 1728, Training Loss = 0.9076814651489258\n","Epoch: 1729, Training Loss = 0.9076581001281738\n","Epoch: 1730, Training Loss = 0.9076347947120667\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1731, Training Loss = 0.9076114296913147\n","Epoch: 1732, Training Loss = 0.9075880646705627\n","Epoch: 1733, Training Loss = 0.9075646996498108\n","Epoch: 1734, Training Loss = 0.9075415730476379\n","Epoch: 1735, Training Loss = 0.9075182676315308\n","Epoch: 1736, Training Loss = 0.9074950814247131\n","Epoch: 1737, Training Loss = 0.9074719548225403\n","Epoch: 1738, Training Loss = 0.9074487686157227\n","Epoch: 1739, Training Loss = 0.9074255228042603\n","Epoch: 1740, Training Loss = 0.9074025750160217\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1741, Training Loss = 0.9073793888092041\n","Epoch: 1742, Training Loss = 0.9073563814163208\n","Epoch: 1743, Training Loss = 0.9073333144187927\n","Epoch: 1744, Training Loss = 0.9073103666305542\n","Epoch: 1745, Training Loss = 0.9072874188423157\n","Epoch: 1746, Training Loss = 0.9072642922401428\n","Epoch: 1747, Training Loss = 0.9072412848472595\n","Epoch: 1748, Training Loss = 0.9072183966636658\n","Epoch: 1749, Training Loss = 0.9071955680847168\n","Epoch: 1750, Training Loss = 0.9071727395057678\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1751, Training Loss = 0.9071497917175293\n","Epoch: 1752, Training Loss = 0.9071270823478699\n","Epoch: 1753, Training Loss = 0.9071042537689209\n","Epoch: 1754, Training Loss = 0.9070813655853271\n","Epoch: 1755, Training Loss = 0.9070587158203125\n","Epoch: 1756, Training Loss = 0.9070360064506531\n","Epoch: 1757, Training Loss = 0.9070131778717041\n","Epoch: 1758, Training Loss = 0.906990647315979\n","Epoch: 1759, Training Loss = 0.9069679975509644\n","Epoch: 1760, Training Loss = 0.9069454073905945\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1761, Training Loss = 0.9069227576255798\n","Epoch: 1762, Training Loss = 0.9069001078605652\n","Epoch: 1763, Training Loss = 0.9068776369094849\n","Epoch: 1764, Training Loss = 0.906855046749115\n","Epoch: 1765, Training Loss = 0.9068325757980347\n","Epoch: 1766, Training Loss = 0.9068101048469543\n","Epoch: 1767, Training Loss = 0.9067876935005188\n","Epoch: 1768, Training Loss = 0.9067652821540833\n","Epoch: 1769, Training Loss = 0.9067428112030029\n","Epoch: 1770, Training Loss = 0.9067204594612122\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1771, Training Loss = 0.9066981077194214\n","Epoch: 1772, Training Loss = 0.9066757559776306\n","Epoch: 1773, Training Loss = 0.9066534042358398\n","Epoch: 1774, Training Loss = 0.9066311120986938\n","Epoch: 1775, Training Loss = 0.9066088199615479\n","Epoch: 1776, Training Loss = 0.9065866470336914\n","Epoch: 1777, Training Loss = 0.9065642952919006\n","Epoch: 1778, Training Loss = 0.906542181968689\n","Epoch: 1779, Training Loss = 0.9065200686454773\n","Epoch: 1780, Training Loss = 0.9064978957176208\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1781, Training Loss = 0.9064757227897644\n","Epoch: 1782, Training Loss = 0.9064536690711975\n","Epoch: 1783, Training Loss = 0.9064315557479858\n","Epoch: 1784, Training Loss = 0.9064096212387085\n","Epoch: 1785, Training Loss = 0.906387448310852\n","Epoch: 1786, Training Loss = 0.9063654541969299\n","Epoch: 1787, Training Loss = 0.906343400478363\n","Epoch: 1788, Training Loss = 0.9063215255737305\n","Epoch: 1789, Training Loss = 0.9062995910644531\n","Epoch: 1790, Training Loss = 0.9062777161598206\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1791, Training Loss = 0.9062557220458984\n","Epoch: 1792, Training Loss = 0.9062339067459106\n","Epoch: 1793, Training Loss = 0.9062122106552124\n","Epoch: 1794, Training Loss = 0.9061902761459351\n","Epoch: 1795, Training Loss = 0.9061684608459473\n","Epoch: 1796, Training Loss = 0.906146764755249\n","Epoch: 1797, Training Loss = 0.9061249494552612\n","Epoch: 1798, Training Loss = 0.9061031937599182\n","Epoch: 1799, Training Loss = 0.9060815572738647\n","Epoch: 1800, Training Loss = 0.9060598611831665\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1801, Training Loss = 0.9060381650924683\n","Epoch: 1802, Training Loss = 0.9060165882110596\n","Epoch: 1803, Training Loss = 0.9059949517250061\n","Epoch: 1804, Training Loss = 0.905973494052887\n","Epoch: 1805, Training Loss = 0.9059517979621887\n","Epoch: 1806, Training Loss = 0.9059302806854248\n","Epoch: 1807, Training Loss = 0.9059088826179504\n","Epoch: 1808, Training Loss = 0.9058873057365417\n","Epoch: 1809, Training Loss = 0.9058658480644226\n","Epoch: 1810, Training Loss = 0.9058443903923035\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1811, Training Loss = 0.9058229923248291\n","Epoch: 1812, Training Loss = 0.9058015942573547\n","Epoch: 1813, Training Loss = 0.9057801365852356\n","Epoch: 1814, Training Loss = 0.9057589769363403\n","Epoch: 1815, Training Loss = 0.9057376384735107\n","Epoch: 1816, Training Loss = 0.9057163000106812\n","Epoch: 1817, Training Loss = 0.9056950807571411\n","Epoch: 1818, Training Loss = 0.9056737422943115\n","Epoch: 1819, Training Loss = 0.9056525230407715\n","Epoch: 1820, Training Loss = 0.905631422996521\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1821, Training Loss = 0.905610203742981\n","Epoch: 1822, Training Loss = 0.9055889844894409\n","Epoch: 1823, Training Loss = 0.9055679440498352\n","Epoch: 1824, Training Loss = 0.9055467844009399\n","Epoch: 1825, Training Loss = 0.905525803565979\n","Epoch: 1826, Training Loss = 0.9055046439170837\n","Epoch: 1827, Training Loss = 0.9054835438728333\n","Epoch: 1828, Training Loss = 0.9054625034332275\n","Epoch: 1829, Training Loss = 0.9054416418075562\n","Epoch: 1830, Training Loss = 0.9054205417633057\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1831, Training Loss = 0.9053996801376343\n","Epoch: 1832, Training Loss = 0.9053786993026733\n","Epoch: 1833, Training Loss = 0.905357837677002\n","Epoch: 1834, Training Loss = 0.9053369760513306\n","Epoch: 1835, Training Loss = 0.9053162336349487\n","Epoch: 1836, Training Loss = 0.9052953124046326\n","Epoch: 1837, Training Loss = 0.905274510383606\n","Epoch: 1838, Training Loss = 0.9052537083625793\n","Epoch: 1839, Training Loss = 0.905232846736908\n","Epoch: 1840, Training Loss = 0.9052121043205261\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1841, Training Loss = 0.9051914215087891\n","Epoch: 1842, Training Loss = 0.9051707983016968\n","Epoch: 1843, Training Loss = 0.9051500558853149\n","Epoch: 1844, Training Loss = 0.9051294326782227\n","Epoch: 1845, Training Loss = 0.9051088690757751\n","Epoch: 1846, Training Loss = 0.9050882458686829\n","Epoch: 1847, Training Loss = 0.9050676822662354\n","Epoch: 1848, Training Loss = 0.9050471186637878\n","Epoch: 1849, Training Loss = 0.9050266146659851\n","Epoch: 1850, Training Loss = 0.9050059914588928\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1851, Training Loss = 0.9049856066703796\n","Epoch: 1852, Training Loss = 0.9049650430679321\n","Epoch: 1853, Training Loss = 0.9049447178840637\n","Epoch: 1854, Training Loss = 0.9049242734909058\n","Epoch: 1855, Training Loss = 0.9049039483070374\n","Epoch: 1856, Training Loss = 0.9048835039138794\n","Epoch: 1857, Training Loss = 0.9048631191253662\n","Epoch: 1858, Training Loss = 0.9048427939414978\n","Epoch: 1859, Training Loss = 0.904822587966919\n","Epoch: 1860, Training Loss = 0.9048022031784058\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1861, Training Loss = 0.9047818779945374\n","Epoch: 1862, Training Loss = 0.9047618508338928\n","Epoch: 1863, Training Loss = 0.9047415852546692\n","Epoch: 1864, Training Loss = 0.9047214388847351\n","Epoch: 1865, Training Loss = 0.9047012329101562\n","Epoch: 1866, Training Loss = 0.9046811461448669\n","Epoch: 1867, Training Loss = 0.9046609401702881\n","Epoch: 1868, Training Loss = 0.9046408534049988\n","Epoch: 1869, Training Loss = 0.9046207070350647\n","Epoch: 1870, Training Loss = 0.9046007394790649\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1871, Training Loss = 0.9045807123184204\n","Epoch: 1872, Training Loss = 0.9045607447624207\n","Epoch: 1873, Training Loss = 0.9045407176017761\n","Epoch: 1874, Training Loss = 0.9045208692550659\n","Epoch: 1875, Training Loss = 0.9045009016990662\n","Epoch: 1876, Training Loss = 0.9044809341430664\n","Epoch: 1877, Training Loss = 0.904461145401001\n","Epoch: 1878, Training Loss = 0.9044412970542908\n","Epoch: 1879, Training Loss = 0.904421329498291\n","Epoch: 1880, Training Loss = 0.9044014811515808\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1881, Training Loss = 0.9043816924095154\n","Epoch: 1882, Training Loss = 0.9043620228767395\n","Epoch: 1883, Training Loss = 0.9043422341346741\n","Epoch: 1884, Training Loss = 0.9043224453926086\n","Epoch: 1885, Training Loss = 0.9043028354644775\n","Epoch: 1886, Training Loss = 0.9042829871177673\n","Epoch: 1887, Training Loss = 0.9042633771896362\n","Epoch: 1888, Training Loss = 0.9042438268661499\n","Epoch: 1889, Training Loss = 0.9042242169380188\n","Epoch: 1890, Training Loss = 0.9042046070098877\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1891, Training Loss = 0.9041849970817566\n","Epoch: 1892, Training Loss = 0.9041654467582703\n","Epoch: 1893, Training Loss = 0.9041459560394287\n","Epoch: 1894, Training Loss = 0.9041264057159424\n","Epoch: 1895, Training Loss = 0.9041069149971008\n","Epoch: 1896, Training Loss = 0.9040874242782593\n","Epoch: 1897, Training Loss = 0.9040680527687073\n","Epoch: 1898, Training Loss = 0.9040486216545105\n","Epoch: 1899, Training Loss = 0.9040292501449585\n","Epoch: 1900, Training Loss = 0.9040098190307617\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1901, Training Loss = 0.9039904475212097\n","Epoch: 1902, Training Loss = 0.9039711356163025\n","Epoch: 1903, Training Loss = 0.90395188331604\n","Epoch: 1904, Training Loss = 0.9039326310157776\n","Epoch: 1905, Training Loss = 0.9039132595062256\n","Epoch: 1906, Training Loss = 0.9038940668106079\n","Epoch: 1907, Training Loss = 0.9038748741149902\n","Epoch: 1908, Training Loss = 0.9038556814193726\n","Epoch: 1909, Training Loss = 0.9038365483283997\n","Epoch: 1910, Training Loss = 0.9038172960281372\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1911, Training Loss = 0.9037981629371643\n","Epoch: 1912, Training Loss = 0.903779149055481\n","Epoch: 1913, Training Loss = 0.9037600159645081\n","Epoch: 1914, Training Loss = 0.9037410020828247\n","Epoch: 1915, Training Loss = 0.9037219882011414\n","Epoch: 1916, Training Loss = 0.9037029147148132\n","Epoch: 1917, Training Loss = 0.9036839604377747\n","Epoch: 1918, Training Loss = 0.9036650061607361\n","Epoch: 1919, Training Loss = 0.9036460518836975\n","Epoch: 1920, Training Loss = 0.9036270976066589\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1921, Training Loss = 0.9036081433296204\n","Epoch: 1922, Training Loss = 0.9035893678665161\n","Epoch: 1923, Training Loss = 0.9035704135894775\n","Epoch: 1924, Training Loss = 0.9035518169403076\n","Epoch: 1925, Training Loss = 0.903532862663269\n","Epoch: 1926, Training Loss = 0.9035140872001648\n","Epoch: 1927, Training Loss = 0.9034953117370605\n","Epoch: 1928, Training Loss = 0.9034765362739563\n","Epoch: 1929, Training Loss = 0.9034577012062073\n","Epoch: 1930, Training Loss = 0.9034391641616821\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1931, Training Loss = 0.9034204483032227\n","Epoch: 1932, Training Loss = 0.903401792049408\n","Epoch: 1933, Training Loss = 0.9033830165863037\n","Epoch: 1934, Training Loss = 0.9033645391464233\n","Epoch: 1935, Training Loss = 0.9033460021018982\n","Epoch: 1936, Training Loss = 0.9033273458480835\n","Epoch: 1937, Training Loss = 0.9033088088035583\n","Epoch: 1938, Training Loss = 0.9032902717590332\n","Epoch: 1939, Training Loss = 0.9032717943191528\n","Epoch: 1940, Training Loss = 0.9032532572746277\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1941, Training Loss = 0.9032347798347473\n","Epoch: 1942, Training Loss = 0.9032163619995117\n","Epoch: 1943, Training Loss = 0.9031979441642761\n","Epoch: 1944, Training Loss = 0.9031795263290405\n","Epoch: 1945, Training Loss = 0.9031611680984497\n","Epoch: 1946, Training Loss = 0.9031427502632141\n","Epoch: 1947, Training Loss = 0.9031244516372681\n","Epoch: 1948, Training Loss = 0.9031060934066772\n","Epoch: 1949, Training Loss = 0.9030879139900208\n","Epoch: 1950, Training Loss = 0.9030696153640747\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1951, Training Loss = 0.9030513167381287\n","Epoch: 1952, Training Loss = 0.9030330777168274\n","Epoch: 1953, Training Loss = 0.9030148983001709\n","Epoch: 1954, Training Loss = 0.9029967188835144\n","Epoch: 1955, Training Loss = 0.9029785990715027\n","Epoch: 1956, Training Loss = 0.9029604196548462\n","Epoch: 1957, Training Loss = 0.9029423594474792\n","Epoch: 1958, Training Loss = 0.9029242396354675\n","Epoch: 1959, Training Loss = 0.902906060218811\n","Epoch: 1960, Training Loss = 0.9028881788253784\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1961, Training Loss = 0.9028700590133667\n","Epoch: 1962, Training Loss = 0.9028519988059998\n","Epoch: 1963, Training Loss = 0.9028341174125671\n","Epoch: 1964, Training Loss = 0.9028161764144897\n","Epoch: 1965, Training Loss = 0.9027982354164124\n","Epoch: 1966, Training Loss = 0.902780294418335\n","Epoch: 1967, Training Loss = 0.9027624130249023\n","Epoch: 1968, Training Loss = 0.9027444124221802\n","Epoch: 1969, Training Loss = 0.9027266502380371\n","Epoch: 1970, Training Loss = 0.9027087688446045\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1971, Training Loss = 0.9026908874511719\n","Epoch: 1972, Training Loss = 0.9026732444763184\n","Epoch: 1973, Training Loss = 0.9026554226875305\n","Epoch: 1974, Training Loss = 0.9026376605033875\n","Epoch: 1975, Training Loss = 0.9026199579238892\n","Epoch: 1976, Training Loss = 0.9026021361351013\n","Epoch: 1977, Training Loss = 0.9025844931602478\n","Epoch: 1978, Training Loss = 0.9025668501853943\n","Epoch: 1979, Training Loss = 0.9025493264198303\n","Epoch: 1980, Training Loss = 0.902531623840332\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1981, Training Loss = 0.9025140404701233\n","Epoch: 1982, Training Loss = 0.9024964570999146\n","Epoch: 1983, Training Loss = 0.9024789333343506\n","Epoch: 1984, Training Loss = 0.9024612903594971\n","Epoch: 1985, Training Loss = 0.9024438858032227\n","Epoch: 1986, Training Loss = 0.9024263620376587\n","Epoch: 1987, Training Loss = 0.9024088382720947\n","Epoch: 1988, Training Loss = 0.9023914337158203\n","Epoch: 1989, Training Loss = 0.9023739695549011\n","Epoch: 1990, Training Loss = 0.9023565649986267\n","Accuracy =  0.6847339272499084 F1 weighted =  0.556598961353302 F1 macro =  0.20321723818778992\n","Epoch: 1991, Training Loss = 0.9023391008377075\n","Epoch: 1992, Training Loss = 0.9023218750953674\n","Epoch: 1993, Training Loss = 0.902304470539093\n","Epoch: 1994, Training Loss = 0.9022871255874634\n","Epoch: 1995, Training Loss = 0.9022697806358337\n","Epoch: 1996, Training Loss = 0.9022525548934937\n","Epoch: 1997, Training Loss = 0.9022353291511536\n","Epoch: 1998, Training Loss = 0.9022181034088135\n","Epoch: 1999, Training Loss = 0.9022008776664734\n"]}],"source":["from torchmetrics import F1Score, Accuracy\n","\n","model = Model(2, 4, 2, qp_graph.etypes)\n","query_feats = qp_graph.nodes['query'].data['embed']\n","product_feats = qp_graph.nodes['product'].data['embed']\n","node_features = {'query': query_feats, 'product': product_feats}\n","\n","acc_list = []\n","f1_w = []\n","f1_m = []\n","\n","\n","opt = torch.optim.Adam(model.parameters(), lr=0.001)\n","for epoch in range(2000):\n","    model.train()\n","    logits = model(qp_graph, node_features, dec_graph)\n","    loss = F.cross_entropy(logits[train_mask], edge_label[train_mask])\n","    opt.zero_grad()\n","    loss.backward()\n","    opt.step()\n","    print(f\"Epoch: {epoch}, Training Loss = {loss.item()}\")\n","\n","    if epoch % 10 == 0:\n","      model.eval()\n","      with torch.no_grad():\n","          logits = model(qp_graph, node_features, dec_graph)\n","          logits = logits[val_mask]\n","          labels = edge_label[val_mask]\n","          _, indices = torch.max(logits, dim=1)\n","          correct = torch.sum(indices == labels)\n","          f1 = F1Score(num_classes=4, average = 'weighted')\n","          f1_weighted = f1(indices, labels)\n","          f1 = F1Score(num_classes=4, average = 'macro')\n","          f1_macro = f1(indices, labels)\n","          accuracy = Accuracy()\n","          acc = accuracy(indices, labels)\n","          acc_list.append(acc.item())\n","          f1_w.append(f1_weighted.item())\n","          f1_m.append(f1_macro.item())\n","          print(\"Accuracy = \", acc.item(), \"F1 weighted = \", f1_weighted.item(), \"F1 macro = \", f1_macro.item())"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.rcParams[\"figure.figsize\"] = (12,8)\n","plt.plot(list(range(200)), acc_list, label=\"Accuracy\")\n","plt.plot(list(range(200)), f1_w, label=\"F1 Weighted\")\n","plt.plot(list(range(200)), f1_m, label=\"F1 Macro\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"GNN Training Detail (2D)\")\n","plt.xlabel(\"epoches (*10)\")\n","plt.xticks(np.arange(0, 200, 10))\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"h2ifVd8FXVfA","executionInfo":{"status":"ok","timestamp":1651959353962,"user_tz":300,"elapsed":1030,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"742e99e6-c9ef-4fa3-c313-e62afb329750"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"31-heteograph-approach-2D.ipynb","provenance":[],"authorship_tag":"ABX9TyPx3/gyS1OZIleoDIeyZ0Nq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}