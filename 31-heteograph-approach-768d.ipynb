{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111517,"status":"ok","timestamp":1651959495030,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"HLUA9V2uyAyL","outputId":"9d956fd3-bb38-4da5-f002-81e23a7f64ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Othercomputers/Vivian's MacBook Pro 2021/DS5720/FinalProject\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","cur_path = \"./drive/Othercomputers/Vivian's MacBook Pro 2021/DS5720/FinalProject\"\n","os.chdir(cur_path)\n","!pwd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26353,"status":"ok","timestamp":1651959521376,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"eZt_o-qjx0ns","outputId":"13afd265-fac3-42b1-dfaf-5f9435a383a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dgl\n","  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n","Installing collected packages: dgl\n","Successfully installed dgl-0.6.1\n","\u001b[33mWARNING: Skipping umap as it is not installed.\u001b[0m\n","Collecting umap-learn\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n","Collecting pynndescent>=0.5\n","  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 23.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.64.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n","Building wheels for collected packages: umap-learn, pynndescent\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=213deecf33de83c82d6a91896310a4775bb30345374af010fb9731c2b66aa1f7\n","  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=b506bb9e51fa3323b9567613ab5820bd666e2f94f6ae273b42c115e87878327c\n","  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n","Successfully built umap-learn pynndescent\n","Installing collected packages: pynndescent, umap-learn\n","Successfully installed pynndescent-0.5.6 umap-learn-0.5.3\n","Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Using backend: pytorch\n"]}],"source":["! pip install dgl\n","! pip uninstall umap\n","! pip install umap-learn\n","import dgl\n","import torch\n","import pandas as pd \n","import umap.umap_ as umap"]},{"cell_type":"markdown","metadata":{"id":"BBiHzbsPr-CI"},"source":["# 1. Data Import"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"KA7FwfwGmx8-","executionInfo":{"status":"ok","timestamp":1651960036902,"user_tz":300,"elapsed":42211,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["task = pd.read_csv(\"./data/task2/train-v0.2.csv\")\n","mega_table = pd.read_csv(\"./data/product_catalogue-v0.2.csv\")\n","merged_df = pd.merge(task, mega_table, how = 'left', left_on = ['product_id', 'query_locale'], right_on = ['product_id', 'product_locale'])\n","query_embed = pd.read_csv(\"./data/us50k_query_embedding.csv\")\n","product_title_embed = pd.read_csv(\"./data/us50k_product_title_embedding.csv\")"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"gIk7nG3X6qFj","executionInfo":{"status":"ok","timestamp":1651960038798,"user_tz":300,"elapsed":1900,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["merged_df = merged_df[merged_df['product_locale'] == 'us']\n","merged_df = merged_df.fillna('')"]},{"cell_type":"markdown","metadata":{"id":"5i0_7sPXzTK4"},"source":["## 1.1 Get nodes"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1651960039106,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"D5HE_xW87Igb","outputId":"12e8ca3a-ddc9-4071-9551-3398c5772390"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      query_id                      Query  \\\n","0            0              revent 80 cfm   \n","1            1  # 2 pencils not sharpened   \n","2            2           # do not disturb   \n","3            3                 # mom life   \n","4            4  # sharp not hashtag shirt   \n","...        ...                        ...   \n","2616      2616           ac milan leather   \n","2617      2617               ac powerbank   \n","2618      2618            ac recharge kit   \n","2619      2619              ac split unit   \n","2620      2620                   ac units   \n","\n","                                               combined  \n","0     [0.3772154, 0.28850505, 0.9209312, -0.11552514...  \n","1     [0.2370911, 0.19300619, 0.19530456, -0.4864252...  \n","2     [0.39659384, 0.44133782, 0.66782707, -0.936925...  \n","3     [0.98151696, 0.5753808, 0.9085639, 0.32715052,...  \n","4     [0.7096678, 0.5629531, 0.21123986, -0.5959373,...  \n","...                                                 ...  \n","2616  [0.6984452, 0.16217867, 0.6510631, 0.31046593,...  \n","2617  [0.6807513, -0.3814727, 0.21798177, 0.721333, ...  \n","2618  [0.617627, -0.061278045, 0.39211014, 0.9004252...  \n","2619  [0.7279886, -0.46039385, 0.085269734, 0.591594...  \n","2620  [0.6555154, -0.23562235, -0.12681063, 0.620930...  \n","\n","[2621 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-2f9f95f8-4a98-48d6-a228-bb779aec74d2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>Query</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[0.3772154, 0.28850505, 0.9209312, -0.11552514...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td># 2 pencils not sharpened</td>\n","      <td>[0.2370911, 0.19300619, 0.19530456, -0.4864252...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td># do not disturb</td>\n","      <td>[0.39659384, 0.44133782, 0.66782707, -0.936925...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td># mom life</td>\n","      <td>[0.98151696, 0.5753808, 0.9085639, 0.32715052,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td># sharp not hashtag shirt</td>\n","      <td>[0.7096678, 0.5629531, 0.21123986, -0.5959373,...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2616</th>\n","      <td>2616</td>\n","      <td>ac milan leather</td>\n","      <td>[0.6984452, 0.16217867, 0.6510631, 0.31046593,...</td>\n","    </tr>\n","    <tr>\n","      <th>2617</th>\n","      <td>2617</td>\n","      <td>ac powerbank</td>\n","      <td>[0.6807513, -0.3814727, 0.21798177, 0.721333, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2618</th>\n","      <td>2618</td>\n","      <td>ac recharge kit</td>\n","      <td>[0.617627, -0.061278045, 0.39211014, 0.9004252...</td>\n","    </tr>\n","    <tr>\n","      <th>2619</th>\n","      <td>2619</td>\n","      <td>ac split unit</td>\n","      <td>[0.7279886, -0.46039385, 0.085269734, 0.591594...</td>\n","    </tr>\n","    <tr>\n","      <th>2620</th>\n","      <td>2620</td>\n","      <td>ac units</td>\n","      <td>[0.6555154, -0.23562235, -0.12681063, 0.620930...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2621 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f9f95f8-4a98-48d6-a228-bb779aec74d2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2f9f95f8-4a98-48d6-a228-bb779aec74d2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2f9f95f8-4a98-48d6-a228-bb779aec74d2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}],"source":["# query_embed = pd.read_csv(\"./data/query_2d_embedding.csv\")\n","query_embed = pd.merge(query_embed, pd.DataFrame(merged_df['query'].unique(), columns=['Query']), on = 'Query').drop(columns=['Unnamed: 0'])\n","query_embed.insert(0, 'query_id', range(0, 0 + len(query_embed)))\n","query_embed['combined']=query_embed.drop(columns=['query_id', 'Query']).values.tolist()\n","query_embed = query_embed[['query_id', 'Query', 'combined']]\n","query_embed"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"YCroXLcK1mh4","colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"status":"error","timestamp":1651959991428,"user_tz":300,"elapsed":3823,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"012799bc-49c0-47c0-efe3-c8aef307740f"},"outputs":[{"output_type":"error","ename":"ParserError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-19802e601526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproduct_title_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/product_2d_embedding.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mproduct_title_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_bullet_point'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_brand'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_color_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mproduct_title_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Product'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Product'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'product_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_title_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."]}],"source":["product_title_embed = pd.read_csv(\"./data/product_2d_embedding.csv\")\n","product_title_embed = product_title_embed.drop_duplicates()\n","merged_df['product'] = merged_df['product_title'] +  merged_df['product_description'] +  merged_df['product_bullet_point'] +  merged_df['product_brand'] +  merged_df['product_color_name']\n","product_title_embed = pd.merge(product_title_embed, pd.DataFrame(merged_df['product'].unique(), columns=['Product']), on = 'Product').drop(columns=['Unnamed: 0'])\n","product_title_embed.insert(0, 'product_id', range(0, 0 + len(product_title_embed)))\n","product_title_embed['combined']=product_title_embed.drop(columns=['product_id', 'Product']).values.tolist()\n","product_title_embed = product_title_embed[['product_id', 'Product', 'combined']]\n","product_title_embed"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3119,"status":"ok","timestamp":1651960251879,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"ltouHFYRQ8pu","outputId":"d9c6c3a2-b6ee-41e9-c51f-bdfb865c854c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       product_id                                            Product  \\\n","0               0  Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...   \n","1               1  Broan Very Quiet Ceiling Bathroom Exhaust Fan,...   \n","2               2  Delta BreezSignature VFB25ACH 80 CFM Exhaust B...   \n","3               3  Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...   \n","4               4  Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...   \n","...           ...                                                ...   \n","45195       45195  Cooper & Hunter 9,000 BTU, 115V, 19 SEER Ductl...   \n","45196       45196  DELLA 12,000 BTU Mini Split Air Conditioner Du...   \n","45197       45197  Emerson Quiet Kool 5,000 BTU 115V Window Air C...   \n","45198       45198  JHS 10,000 BTU Portable Air Conditioner 3-in-1...   \n","45199       45199  JHS 8,000 BTU Small Portable Air Conditioner 3...   \n","\n","                                                combined  \n","0      [0.5584528, -0.115527354, 0.989929, 0.5647745,...  \n","1      [0.42908123, -0.01130617, 0.78302675, 0.889836...  \n","2      [0.55030024, -0.13049354, 1.067971, 0.76725423...  \n","3      [0.6489395, -0.2732966, 0.9358898, 0.7858058, ...  \n","4      [0.4358175, 0.096745856, 0.88996965, 0.4098112...  \n","...                                                  ...  \n","45195  [0.5811683, -0.07111953, 0.8577781, 0.7198514,...  \n","45196  [0.41857454, -0.14850773, 0.40461016, 0.960956...  \n","45197  [0.4760484, 0.12030364, 0.99494934, 0.6027467,...  \n","45198  [0.36931574, -0.062436827, 0.7381011, 0.826377...  \n","45199  [0.3502267, -0.07390693, 0.7353081, 0.8260111,...  \n","\n","[45200 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-9266cb53-7475-475b-a7c6-fd1e89eb9de9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>Product</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>[0.5584528, -0.115527354, 0.989929, 0.5647745,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>[0.42908123, -0.01130617, 0.78302675, 0.889836...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>[0.55030024, -0.13049354, 1.067971, 0.76725423...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>[0.6489395, -0.2732966, 0.9358898, 0.7858058, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>[0.4358175, 0.096745856, 0.88996965, 0.4098112...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>45195</th>\n","      <td>45195</td>\n","      <td>Cooper &amp; Hunter 9,000 BTU, 115V, 19 SEER Ductl...</td>\n","      <td>[0.5811683, -0.07111953, 0.8577781, 0.7198514,...</td>\n","    </tr>\n","    <tr>\n","      <th>45196</th>\n","      <td>45196</td>\n","      <td>DELLA 12,000 BTU Mini Split Air Conditioner Du...</td>\n","      <td>[0.41857454, -0.14850773, 0.40461016, 0.960956...</td>\n","    </tr>\n","    <tr>\n","      <th>45197</th>\n","      <td>45197</td>\n","      <td>Emerson Quiet Kool 5,000 BTU 115V Window Air C...</td>\n","      <td>[0.4760484, 0.12030364, 0.99494934, 0.6027467,...</td>\n","    </tr>\n","    <tr>\n","      <th>45198</th>\n","      <td>45198</td>\n","      <td>JHS 10,000 BTU Portable Air Conditioner 3-in-1...</td>\n","      <td>[0.36931574, -0.062436827, 0.7381011, 0.826377...</td>\n","    </tr>\n","    <tr>\n","      <th>45199</th>\n","      <td>45199</td>\n","      <td>JHS 8,000 BTU Small Portable Air Conditioner 3...</td>\n","      <td>[0.3502267, -0.07390693, 0.7353081, 0.8260111,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>45200 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9266cb53-7475-475b-a7c6-fd1e89eb9de9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9266cb53-7475-475b-a7c6-fd1e89eb9de9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9266cb53-7475-475b-a7c6-fd1e89eb9de9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":29}],"source":["product_title_embed = pd.merge(product_title_embed, pd.DataFrame(merged_df['product_title'].unique(), columns=['Product']), on = 'Product').drop(columns=['Unnamed: 0'])\n","product_title_embed.insert(0, 'product_id', range(0, 0 + len(product_title_embed)))\n","product_title_embed['combined']=product_title_embed.drop(columns=['product_id', 'Product']).values.tolist()\n","product_title_embed = product_title_embed[['product_id', 'Product', 'combined']]\n","product_title_embed"]},{"cell_type":"markdown","metadata":{"id":"X2Nc3vOS4sTY"},"source":["## 1.2 Get edges"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"GQHv1R--2mDf","executionInfo":{"status":"ok","timestamp":1651960259379,"user_tz":300,"elapsed":1042,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["cleaned_df = merged_df[merged_df['product_locale'] == 'us'][['query', 'product_title', 'esci_label']][:50000]\n","temp_merged = pd.merge(cleaned_df, query_embed, left_on = ['query'], right_on = ['Query'], how = 'left')\n","total_index = pd.merge(temp_merged, product_title_embed, left_on = ['product_title'], right_on = ['Product'], how = 'left', suffixes = ('_query', '_product') )\n","total_index = total_index.dropna()\n","# total_index\n","query_idx = total_index[['query_id', 'query', 'combined_query', 'esci_label']]\n","product_idx = total_index[['product_id', 'product_title', 'combined_product', 'esci_label']]\n"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"PyOobiRHBOld","executionInfo":{"status":"ok","timestamp":1651960261073,"user_tz":300,"elapsed":3,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["i_edge_q = query_idx[query_idx['esci_label'] == 'irrelevant']\n","i_edge_p = product_idx[product_idx['esci_label'] == 'irrelevant']\n","i_edge_idx = [i_edge_q['query_id'].tolist(), i_edge_p['product_id'].tolist()]\n","\n","e_edge_q = query_idx[query_idx['esci_label'] == 'exact']\n","e_edge_p = product_idx[product_idx['esci_label'] == 'exact']\n","e_edge_idx = [e_edge_q['query_id'].tolist(), e_edge_p['product_id'].tolist()]\n","\n","c_edge_q = query_idx[query_idx['esci_label'] == 'complement']\n","c_edge_p = product_idx[product_idx['esci_label'] == 'complement']\n","c_edge_idx = [c_edge_q['query_id'].tolist(), c_edge_p['product_id'].tolist()]\n","\n","\n","s_edge_q = query_idx[query_idx['esci_label'] == 'substitute']\n","s_edge_p = product_idx[product_idx['esci_label'] == 'substitute']\n","s_edge_idx = [s_edge_q['query_id'].tolist(), s_edge_p['product_id'].tolist()]\n"]},{"cell_type":"markdown","metadata":{"id":"vKlnJGYY4uOK"},"source":["# 2. Create Graph"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"ClMfrGUGCCbE","executionInfo":{"status":"ok","timestamp":1651960266039,"user_tz":300,"elapsed":824,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["graph_data = {\n","   ('query', 'irrelevant', 'product'): (torch.tensor(i_edge_idx[0], dtype=torch.int32), torch.tensor(i_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'exact', 'product'): (torch.tensor(e_edge_idx[0], dtype=torch.int32), torch.tensor(e_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'complement', 'product'): (torch.tensor(c_edge_idx[0], dtype=torch.int32), torch.tensor(c_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'substitute', 'product'): (torch.tensor(s_edge_idx[0], dtype=torch.int32), torch.tensor(s_edge_idx[1], dtype=torch.int32))\n","}\n","qp_graph = dgl.heterograph(graph_data)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651960266809,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"9nKvaNwv4w42","outputId":"632c50df-e8f8-4b25-dd10-6f5a31b591db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Graph(num_nodes={'product': 45200, 'query': 2621},\n","      num_edges={('query', 'complement', 'product'): 1149, ('query', 'exact', 'product'): 29903, ('query', 'irrelevant', 'product'): 5851, ('query', 'substitute', 'product'): 13094},\n","      metagraph=[('query', 'product', 'complement'), ('query', 'product', 'exact'), ('query', 'product', 'irrelevant'), ('query', 'product', 'substitute')])"]},"metadata":{},"execution_count":33}],"source":["qp_graph"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"m6TOHP4lRhQX","executionInfo":{"status":"ok","timestamp":1651960269818,"user_tz":300,"elapsed":1396,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["qp_graph.nodes['query'].data['embed'] = torch.tensor(query_embed['combined'].tolist())\n","qp_graph.nodes['product'].data['embed'] = torch.tensor(product_title_embed['combined'].tolist())"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1651959700277,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"eiK-aQkgK0-T","outputId":"374d660e-509d-45c2-9f83-a5de02719bb5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3707"]},"metadata":{},"execution_count":12}],"source":["import gc\n","\n","del task\n","del mega_table\n","del merged_df\n","del cleaned_df\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"a4yINMxKUMc-"},"source":["# 3. Train a model"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"lO5glZJjVhtP","executionInfo":{"status":"ok","timestamp":1651960271613,"user_tz":300,"elapsed":267,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["import dgl.nn as dglnn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class RGCN(nn.Module):\n","    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n","        super().__init__()\n","\n","        self.conv1 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(in_feats, hid_feats)\n","            for rel in rel_names}, aggregate='sum')\n","        self.conv2 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(hid_feats, out_feats)\n","            for rel in rel_names}, aggregate='sum')\n","\n","    def forward(self, graph, inputs):\n","        # inputs are features of nodes\n","        h = self.conv1(graph, inputs)\n","        h = {k: F.relu(v) for k, v in h.items()}\n","        h = self.conv2(graph, h)\n","        return h\n","\n","class HeteroMLPPredictor(nn.Module):\n","    def __init__(self, in_dims, n_classes):\n","        super().__init__()\n","        self.W = nn.Linear(in_dims * 2, n_classes)\n","\n","    def apply_edges(self, edges):\n","        x = torch.cat([edges.src['embed'], edges.dst['embed']], 1)\n","        y = self.W(x)\n","        return {'score': y}\n","\n","    def forward(self, graph, h):\n","        # h contains the node representations for each edge type computed from\n","        # the GNN for heterogeneous graphs defined in the node classification\n","        # section (Section 5.1).\n","        with graph.local_scope():\n","            graph.ndata['h'] = h   # assigns 'h' of all node types in one shot\n","            graph.apply_edges(self.apply_edges)\n","            return graph.edata['score']\n","\n","class Model(nn.Module):\n","    def __init__(self, in_features, hidden_features, out_features, rel_names):\n","        super().__init__()\n","        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n","        self.pred = HeteroMLPPredictor(out_features, len(rel_names))\n","    def forward(self, g, x, dec_graph):\n","        h = self.sage(g, x)\n","        return self.pred(dec_graph, h)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1734,"status":"ok","timestamp":1651960275088,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"y1zgKw8NUOMp","outputId":"cde1bebb-7d0c-4c5a-b2ee-26609c6c57af"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]}],"source":["dec_graph = qp_graph['query', :, 'product']\n","edge_label = torch.tensor(dec_graph.edata[dgl.ETYPE], dtype=torch.long)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"x4m9gDuGbWmG","executionInfo":{"status":"ok","timestamp":1651960276693,"user_tz":300,"elapsed":315,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["dec_graph.edata['train_mask'] = torch.zeros(dec_graph.num_edges('complement+exact+irrelevant+substitute'), dtype=torch.bool).bernoulli(0.7)\n","dec_graph.edata['val_mask'] = torch.tensor([not x for x in dec_graph.edata['train_mask'] ], dtype=torch.bool)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"4Jj9pateWQ8x","executionInfo":{"status":"ok","timestamp":1651960277207,"user_tz":300,"elapsed":260,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["train_mask = dec_graph.edata['train_mask']\n","val_mask = dec_graph.edata['val_mask']"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3574,"status":"ok","timestamp":1651959715416,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"SLKfCjd7rRiq","outputId":"7bc51a1f-4e77-4a43-9081-539615655219"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 33.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Collecting pyDeprecate==0.3.*\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n","Installing collected packages: pyDeprecate, torchmetrics\n","Successfully installed pyDeprecate-0.3.2 torchmetrics-0.8.2\n"]}],"source":["! pip install torchmetrics"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7383186,"status":"ok","timestamp":1651967664431,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"7nkUVsnuV_bD","outputId":"9a34f5bb-ab79-4634-f5c6-9b950a244b3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Training Loss = 1.559446930885315\n","Accuracy =  0.3249207139015198 F1 weighted =  0.29264530539512634 F1 macro =  0.19230948388576508\n","Epoch: 1, Training Loss = 1.2670763731002808\n","Epoch: 2, Training Loss = 1.0849097967147827\n","Epoch: 3, Training Loss = 1.0332164764404297\n","Epoch: 4, Training Loss = 1.0482177734375\n","Epoch: 5, Training Loss = 1.062922477722168\n","Epoch: 6, Training Loss = 1.060956358909607\n","Epoch: 7, Training Loss = 1.0496364831924438\n","Epoch: 8, Training Loss = 1.041958212852478\n","Epoch: 9, Training Loss = 1.0422724485397339\n","Epoch: 10, Training Loss = 1.0408084392547607\n","Accuracy =  0.5983747243881226 F1 weighted =  0.4697168171405792 F1 macro =  0.2052973210811615\n","Epoch: 11, Training Loss = 1.0296709537506104\n","Epoch: 12, Training Loss = 1.012649655342102\n","Epoch: 13, Training Loss = 0.9983761310577393\n","Epoch: 14, Training Loss = 0.9926044344902039\n","Epoch: 15, Training Loss = 0.9951434135437012\n","Epoch: 16, Training Loss = 1.0014314651489258\n","Epoch: 17, Training Loss = 1.0062599182128906\n","Epoch: 18, Training Loss = 1.0065349340438843\n","Epoch: 19, Training Loss = 1.0020592212677002\n","Epoch: 20, Training Loss = 0.9948670864105225\n","Accuracy =  0.606501042842865 F1 weighted =  0.47245535254478455 F1 macro =  0.2197181135416031\n","Epoch: 21, Training Loss = 0.9877223372459412\n","Epoch: 22, Training Loss = 0.9824406504631042\n","Epoch: 23, Training Loss = 0.9790477156639099\n","Epoch: 24, Training Loss = 0.9764679074287415\n","Epoch: 25, Training Loss = 0.9739618897438049\n","Epoch: 26, Training Loss = 0.9716871380805969\n","Epoch: 27, Training Loss = 0.9700363874435425\n","Epoch: 28, Training Loss = 0.9688397645950317\n","Epoch: 29, Training Loss = 0.9673691987991333\n","Epoch: 30, Training Loss = 0.9650219082832336\n","Accuracy =  0.6052457690238953 F1 weighted =  0.4567144215106964 F1 macro =  0.18910126388072968\n","Epoch: 31, Training Loss = 0.9618993401527405\n","Epoch: 32, Training Loss = 0.958758533000946\n","Epoch: 33, Training Loss = 0.9564260840415955\n","Epoch: 34, Training Loss = 0.955178439617157\n","Epoch: 35, Training Loss = 0.954586386680603\n","Epoch: 36, Training Loss = 0.9539316892623901\n","Epoch: 37, Training Loss = 0.9527943134307861\n","Epoch: 38, Training Loss = 0.951283872127533\n","Epoch: 39, Training Loss = 0.9497925639152527\n","Epoch: 40, Training Loss = 0.9485908150672913\n","Accuracy =  0.6074920892715454 F1 weighted =  0.46482935547828674 F1 macro =  0.2018076330423355\n","Epoch: 41, Training Loss = 0.9476409554481506\n","Epoch: 42, Training Loss = 0.9467224478721619\n","Epoch: 43, Training Loss = 0.9456881880760193\n","Epoch: 44, Training Loss = 0.9445932507514954\n","Epoch: 45, Training Loss = 0.9436038136482239\n","Epoch: 46, Training Loss = 0.942797064781189\n","Epoch: 47, Training Loss = 0.9420698285102844\n","Epoch: 48, Training Loss = 0.941260576248169\n","Epoch: 49, Training Loss = 0.9403420686721802\n","Epoch: 50, Training Loss = 0.939454972743988\n","Accuracy =  0.6087473630905151 F1 weighted =  0.47756052017211914 F1 macro =  0.2214587777853012\n","Epoch: 51, Training Loss = 0.9387459754943848\n","Epoch: 52, Training Loss = 0.9382045269012451\n","Epoch: 53, Training Loss = 0.9376735687255859\n","Epoch: 54, Training Loss = 0.9370048642158508\n","Epoch: 55, Training Loss = 0.9361847043037415\n","Epoch: 56, Training Loss = 0.9353212118148804\n","Epoch: 57, Training Loss = 0.9345263242721558\n","Epoch: 58, Training Loss = 0.933824896812439\n","Epoch: 59, Training Loss = 0.933168888092041\n","Epoch: 60, Training Loss = 0.9325166940689087\n","Accuracy =  0.6100687384605408 F1 weighted =  0.48151716589927673 F1 macro =  0.22286178171634674\n","Epoch: 61, Training Loss = 0.9318743944168091\n","Epoch: 62, Training Loss = 0.9312632083892822\n","Epoch: 63, Training Loss = 0.9306716322898865\n","Epoch: 64, Training Loss = 0.9300614595413208\n","Epoch: 65, Training Loss = 0.9294155836105347\n","Epoch: 66, Training Loss = 0.9287657737731934\n","Epoch: 67, Training Loss = 0.928165078163147\n","Epoch: 68, Training Loss = 0.9276338219642639\n","Epoch: 69, Training Loss = 0.9271423816680908\n","Epoch: 70, Training Loss = 0.9266435503959656\n","Accuracy =  0.6128435730934143 F1 weighted =  0.49487578868865967 F1 macro =  0.2446098029613495\n","Epoch: 71, Training Loss = 0.9261150360107422\n","Epoch: 72, Training Loss = 0.9255682229995728\n","Epoch: 73, Training Loss = 0.9250227808952332\n","Epoch: 74, Training Loss = 0.924485445022583\n","Epoch: 75, Training Loss = 0.9239526987075806\n","Epoch: 76, Training Loss = 0.9234263300895691\n","Epoch: 77, Training Loss = 0.9229145646095276\n","Epoch: 78, Training Loss = 0.922420084476471\n","Epoch: 79, Training Loss = 0.921932578086853\n","Epoch: 80, Training Loss = 0.9214382767677307\n","Accuracy =  0.6142309904098511 F1 weighted =  0.4981410503387451 F1 macro =  0.24739938974380493\n","Epoch: 81, Training Loss = 0.9209353923797607\n","Epoch: 82, Training Loss = 0.9204355478286743\n","Epoch: 83, Training Loss = 0.9199507832527161\n","Epoch: 84, Training Loss = 0.9194821119308472\n","Epoch: 85, Training Loss = 0.9190219640731812\n","Epoch: 86, Training Loss = 0.9185642004013062\n","Epoch: 87, Training Loss = 0.918109118938446\n","Epoch: 88, Training Loss = 0.917658269405365\n","Epoch: 89, Training Loss = 0.9172110557556152\n","Epoch: 90, Training Loss = 0.916765034198761\n","Accuracy =  0.6157505512237549 F1 weighted =  0.5058941841125488 F1 macro =  0.25956279039382935\n","Epoch: 91, Training Loss = 0.9163207411766052\n","Epoch: 92, Training Loss = 0.9158814549446106\n","Epoch: 93, Training Loss = 0.9154492020606995\n","Epoch: 94, Training Loss = 0.915021538734436\n","Epoch: 95, Training Loss = 0.9145953059196472\n","Epoch: 96, Training Loss = 0.9141698479652405\n","Epoch: 97, Training Loss = 0.9137477278709412\n","Epoch: 98, Training Loss = 0.9133309125900269\n","Epoch: 99, Training Loss = 0.9129185080528259\n","Epoch: 100, Training Loss = 0.9125090837478638\n","Accuracy =  0.6166093945503235 F1 weighted =  0.5101445317268372 F1 macro =  0.26542237401008606\n","Epoch: 101, Training Loss = 0.9121022820472717\n","Epoch: 102, Training Loss = 0.9116990566253662\n","Epoch: 103, Training Loss = 0.9112995862960815\n","Epoch: 104, Training Loss = 0.9109032154083252\n","Epoch: 105, Training Loss = 0.910509467124939\n","Epoch: 106, Training Loss = 0.910118579864502\n","Epoch: 107, Training Loss = 0.9097314476966858\n","Epoch: 108, Training Loss = 0.9093475937843323\n","Epoch: 109, Training Loss = 0.9089659452438354\n","Epoch: 110, Training Loss = 0.9085864424705505\n","Accuracy =  0.6174682974815369 F1 weighted =  0.5134239792823792 F1 macro =  0.270211398601532\n","Epoch: 111, Training Loss = 0.9082095623016357\n","Epoch: 112, Training Loss = 0.9078361392021179\n","Epoch: 113, Training Loss = 0.907465398311615\n","Epoch: 114, Training Loss = 0.907097339630127\n","Epoch: 115, Training Loss = 0.9067317247390747\n","Epoch: 116, Training Loss = 0.9063685536384583\n","Epoch: 117, Training Loss = 0.9060078263282776\n","Epoch: 118, Training Loss = 0.9056494832038879\n","Epoch: 119, Training Loss = 0.9052935242652893\n","Epoch: 120, Training Loss = 0.9049399495124817\n","Accuracy =  0.6179307699203491 F1 weighted =  0.5165711641311646 F1 macro =  0.2743995785713196\n","Epoch: 121, Training Loss = 0.9045891165733337\n","Epoch: 122, Training Loss = 0.9042407274246216\n","Epoch: 123, Training Loss = 0.9038944244384766\n","Epoch: 124, Training Loss = 0.9035503268241882\n","Epoch: 125, Training Loss = 0.9032083749771118\n","Epoch: 126, Training Loss = 0.9028688669204712\n","Epoch: 127, Training Loss = 0.9025315642356873\n","Epoch: 128, Training Loss = 0.9021962285041809\n","Epoch: 129, Training Loss = 0.9018633365631104\n","Epoch: 130, Training Loss = 0.9015323519706726\n","Accuracy =  0.6197145581245422 F1 weighted =  0.5210293531417847 F1 macro =  0.27981552481651306\n","Epoch: 131, Training Loss = 0.9012033343315125\n","Epoch: 132, Training Loss = 0.9008764624595642\n","Epoch: 133, Training Loss = 0.9005513787269592\n","Epoch: 134, Training Loss = 0.9002283811569214\n","Epoch: 135, Training Loss = 0.8999072909355164\n","Epoch: 136, Training Loss = 0.8995881676673889\n","Epoch: 137, Training Loss = 0.8992709517478943\n","Epoch: 138, Training Loss = 0.8989555835723877\n","Epoch: 139, Training Loss = 0.8986421227455139\n","Epoch: 140, Training Loss = 0.8983304500579834\n","Accuracy =  0.6203091740608215 F1 weighted =  0.5243304371833801 F1 macro =  0.2845081686973572\n","Epoch: 141, Training Loss = 0.8980206847190857\n","Epoch: 142, Training Loss = 0.8977124691009521\n","Epoch: 143, Training Loss = 0.8974062204360962\n","Epoch: 144, Training Loss = 0.897101640701294\n","Epoch: 145, Training Loss = 0.896798849105835\n","Epoch: 146, Training Loss = 0.8964975476264954\n","Epoch: 147, Training Loss = 0.8961981534957886\n","Epoch: 148, Training Loss = 0.8959002494812012\n","Epoch: 149, Training Loss = 0.8956039547920227\n","Epoch: 150, Training Loss = 0.8953093886375427\n","Accuracy =  0.6224894523620605 F1 weighted =  0.5294413566589355 F1 macro =  0.29076528549194336\n","Epoch: 151, Training Loss = 0.8950163722038269\n","Epoch: 152, Training Loss = 0.8947249054908752\n","Epoch: 153, Training Loss = 0.8944349884986877\n","Epoch: 154, Training Loss = 0.8941465616226196\n","Epoch: 155, Training Loss = 0.8938598036766052\n","Epoch: 156, Training Loss = 0.8935743570327759\n","Epoch: 157, Training Loss = 0.8932905197143555\n","Epoch: 158, Training Loss = 0.8930080533027649\n","Epoch: 159, Training Loss = 0.8927270174026489\n","Epoch: 160, Training Loss = 0.8924474716186523\n","Accuracy =  0.6228858232498169 F1 weighted =  0.5321580767631531 F1 macro =  0.29460129141807556\n","Epoch: 161, Training Loss = 0.8921694159507751\n","Epoch: 162, Training Loss = 0.8918927311897278\n","Epoch: 163, Training Loss = 0.8916173577308655\n","Epoch: 164, Training Loss = 0.8913431763648987\n","Epoch: 165, Training Loss = 0.8910706043243408\n","Epoch: 166, Training Loss = 0.890799343585968\n","Epoch: 167, Training Loss = 0.8905293345451355\n","Epoch: 168, Training Loss = 0.8902606964111328\n","Epoch: 169, Training Loss = 0.8899933099746704\n","Epoch: 170, Training Loss = 0.8897272348403931\n","Accuracy =  0.6238768696784973 F1 weighted =  0.5352928638458252 F1 macro =  0.29831933975219727\n","Epoch: 171, Training Loss = 0.8894622921943665\n","Epoch: 172, Training Loss = 0.8891987204551697\n","Epoch: 173, Training Loss = 0.8889364004135132\n","Epoch: 174, Training Loss = 0.8886752128601074\n","Epoch: 175, Training Loss = 0.8884152173995972\n","Epoch: 176, Training Loss = 0.8881564736366272\n","Epoch: 177, Training Loss = 0.8878989815711975\n","Epoch: 178, Training Loss = 0.8876426219940186\n","Epoch: 179, Training Loss = 0.8873873353004456\n","Epoch: 180, Training Loss = 0.8871333003044128\n","Accuracy =  0.6243393421173096 F1 weighted =  0.5375695824623108 F1 macro =  0.30114516615867615\n","Epoch: 181, Training Loss = 0.8868803381919861\n","Epoch: 182, Training Loss = 0.8866285681724548\n","Epoch: 183, Training Loss = 0.8863778710365295\n","Epoch: 184, Training Loss = 0.886128306388855\n","Epoch: 185, Training Loss = 0.8858796954154968\n","Epoch: 186, Training Loss = 0.8856322765350342\n","Epoch: 187, Training Loss = 0.8853859901428223\n","Epoch: 188, Training Loss = 0.8851406574249268\n","Epoch: 189, Training Loss = 0.8848963975906372\n","Epoch: 190, Training Loss = 0.8846532702445984\n","Accuracy =  0.6255285143852234 F1 weighted =  0.5410462021827698 F1 macro =  0.3054962158203125\n","Epoch: 191, Training Loss = 0.884411096572876\n","Epoch: 192, Training Loss = 0.8841699361801147\n","Epoch: 193, Training Loss = 0.8839297890663147\n","Epoch: 194, Training Loss = 0.8836906552314758\n","Epoch: 195, Training Loss = 0.8834524750709534\n","Epoch: 196, Training Loss = 0.8832154273986816\n","Epoch: 197, Training Loss = 0.8829792141914368\n","Epoch: 198, Training Loss = 0.8827440142631531\n","Epoch: 199, Training Loss = 0.882509708404541\n","Epoch: 200, Training Loss = 0.8822763562202454\n","Accuracy =  0.6259909868240356 F1 weighted =  0.5431451201438904 F1 macro =  0.3079858720302582\n","Epoch: 201, Training Loss = 0.8820440173149109\n","Epoch: 202, Training Loss = 0.8818125128746033\n","Epoch: 203, Training Loss = 0.8815821409225464\n","Epoch: 204, Training Loss = 0.8813524842262268\n","Epoch: 205, Training Loss = 0.8811237215995789\n","Epoch: 206, Training Loss = 0.8808959126472473\n","Epoch: 207, Training Loss = 0.8806689381599426\n","Epoch: 208, Training Loss = 0.8804430365562439\n","Epoch: 209, Training Loss = 0.8802177906036377\n","Epoch: 210, Training Loss = 0.8799935579299927\n","Accuracy =  0.6264534592628479 F1 weighted =  0.5448336601257324 F1 macro =  0.31021660566329956\n","Epoch: 211, Training Loss = 0.8797701001167297\n","Epoch: 212, Training Loss = 0.8795474767684937\n","Epoch: 213, Training Loss = 0.8793256878852844\n","Epoch: 214, Training Loss = 0.8791048526763916\n","Epoch: 215, Training Loss = 0.8788848519325256\n","Epoch: 216, Training Loss = 0.878665566444397\n","Epoch: 217, Training Loss = 0.8784471750259399\n","Epoch: 218, Training Loss = 0.878229558467865\n","Epoch: 219, Training Loss = 0.8780127167701721\n","Epoch: 220, Training Loss = 0.8777967691421509\n","Accuracy =  0.6266517043113708 F1 weighted =  0.5461497902870178 F1 macro =  0.31193816661834717\n","Epoch: 221, Training Loss = 0.8775815367698669\n","Epoch: 222, Training Loss = 0.8773671388626099\n","Epoch: 223, Training Loss = 0.8771535158157349\n","Epoch: 224, Training Loss = 0.8769405484199524\n","Epoch: 225, Training Loss = 0.8767284750938416\n","Epoch: 226, Training Loss = 0.876517117023468\n","Epoch: 227, Training Loss = 0.8763065338134766\n","Epoch: 228, Training Loss = 0.8760966658592224\n","Epoch: 229, Training Loss = 0.8758876919746399\n","Epoch: 230, Training Loss = 0.8756793737411499\n","Accuracy =  0.6271802186965942 F1 weighted =  0.5480851531028748 F1 macro =  0.31391575932502747\n","Epoch: 231, Training Loss = 0.8754716515541077\n","Epoch: 232, Training Loss = 0.8752646446228027\n","Epoch: 233, Training Loss = 0.8750584721565247\n","Epoch: 234, Training Loss = 0.8748530745506287\n","Epoch: 235, Training Loss = 0.8746483325958252\n","Epoch: 236, Training Loss = 0.874444305896759\n","Epoch: 237, Training Loss = 0.8742409348487854\n","Epoch: 238, Training Loss = 0.8740383386611938\n","Epoch: 239, Training Loss = 0.8738363981246948\n","Epoch: 240, Training Loss = 0.8736351728439331\n","Accuracy =  0.6281712651252747 F1 weighted =  0.5504117012023926 F1 macro =  0.3163410425186157\n","Epoch: 241, Training Loss = 0.8734346032142639\n","Epoch: 242, Training Loss = 0.8732346296310425\n","Epoch: 243, Training Loss = 0.8730354905128479\n","Epoch: 244, Training Loss = 0.8728367686271667\n","Epoch: 245, Training Loss = 0.8726389408111572\n","Epoch: 246, Training Loss = 0.8724416494369507\n","Epoch: 247, Training Loss = 0.8722450137138367\n","Epoch: 248, Training Loss = 0.8720490336418152\n","Epoch: 249, Training Loss = 0.8718538284301758\n","Epoch: 250, Training Loss = 0.8716590404510498\n","Accuracy =  0.6281712651252747 F1 weighted =  0.5514225959777832 F1 macro =  0.3175836503505707\n","Epoch: 251, Training Loss = 0.8714650273323059\n","Epoch: 252, Training Loss = 0.8712716102600098\n","Epoch: 253, Training Loss = 0.8710787892341614\n","Epoch: 254, Training Loss = 0.8708866834640503\n","Epoch: 255, Training Loss = 0.8706951141357422\n","Epoch: 256, Training Loss = 0.8705042600631714\n","Epoch: 257, Training Loss = 0.8703139424324036\n","Epoch: 258, Training Loss = 0.8701241612434387\n","Epoch: 259, Training Loss = 0.8699350357055664\n","Epoch: 260, Training Loss = 0.8697465658187866\n","Accuracy =  0.6292943954467773 F1 weighted =  0.5542557239532471 F1 macro =  0.3208962678909302\n","Epoch: 261, Training Loss = 0.869558572769165\n","Epoch: 262, Training Loss = 0.869371235370636\n","Epoch: 263, Training Loss = 0.8691844344139099\n","Epoch: 264, Training Loss = 0.8689983487129211\n","Epoch: 265, Training Loss = 0.8688126802444458\n","Epoch: 266, Training Loss = 0.8686277270317078\n","Epoch: 267, Training Loss = 0.8684431910514832\n","Epoch: 268, Training Loss = 0.8682593703269958\n","Epoch: 269, Training Loss = 0.8680760264396667\n","Epoch: 270, Training Loss = 0.8678933382034302\n","Accuracy =  0.6299550533294678 F1 weighted =  0.556012749671936 F1 macro =  0.3224363625049591\n","Epoch: 271, Training Loss = 0.867711067199707\n","Epoch: 272, Training Loss = 0.8675294518470764\n","Epoch: 273, Training Loss = 0.8673483729362488\n","Epoch: 274, Training Loss = 0.8671677708625793\n","Epoch: 275, Training Loss = 0.8669877648353577\n","Epoch: 276, Training Loss = 0.8668081760406494\n","Epoch: 277, Training Loss = 0.866629421710968\n","Epoch: 278, Training Loss = 0.8664509057998657\n","Epoch: 279, Training Loss = 0.8662731647491455\n","Epoch: 280, Training Loss = 0.8660957217216492\n","Accuracy =  0.6310782432556152 F1 weighted =  0.5582998991012573 F1 macro =  0.3250265419483185\n","Epoch: 281, Training Loss = 0.8659188747406006\n","Epoch: 282, Training Loss = 0.8657425045967102\n","Epoch: 283, Training Loss = 0.8655667901039124\n","Epoch: 284, Training Loss = 0.8653914928436279\n","Epoch: 285, Training Loss = 0.8652167320251465\n","Epoch: 286, Training Loss = 0.8650424480438232\n","Epoch: 287, Training Loss = 0.864868700504303\n","Epoch: 288, Training Loss = 0.8646954298019409\n","Epoch: 289, Training Loss = 0.8645227551460266\n","Epoch: 290, Training Loss = 0.864350438117981\n","Accuracy =  0.632267415523529 F1 weighted =  0.5605226159095764 F1 macro =  0.32721146941185\n","Epoch: 291, Training Loss = 0.8641787171363831\n","Epoch: 292, Training Loss = 0.8640074133872986\n","Epoch: 293, Training Loss = 0.8638365864753723\n","Epoch: 294, Training Loss = 0.863666296005249\n","Epoch: 295, Training Loss = 0.8634964823722839\n","Epoch: 296, Training Loss = 0.863327145576477\n","Epoch: 297, Training Loss = 0.8631582856178284\n","Epoch: 298, Training Loss = 0.8629898428916931\n","Epoch: 299, Training Loss = 0.8628219962120056\n","Epoch: 300, Training Loss = 0.8626545071601868\n","Accuracy =  0.6326638460159302 F1 weighted =  0.5618575811386108 F1 macro =  0.32899463176727295\n","Epoch: 301, Training Loss = 0.8624874353408813\n","Epoch: 302, Training Loss = 0.8623210191726685\n","Epoch: 303, Training Loss = 0.8621549606323242\n","Epoch: 304, Training Loss = 0.8619893789291382\n","Epoch: 305, Training Loss = 0.8618242144584656\n","Epoch: 306, Training Loss = 0.8616594672203064\n","Epoch: 307, Training Loss = 0.8614951968193054\n","Epoch: 308, Training Loss = 0.8613313436508179\n","Epoch: 309, Training Loss = 0.8611680269241333\n","Epoch: 310, Training Loss = 0.8610051870346069\n","Accuracy =  0.6335227489471436 F1 weighted =  0.5636776089668274 F1 macro =  0.3307441473007202\n","Epoch: 311, Training Loss = 0.8608425855636597\n","Epoch: 312, Training Loss = 0.8606806397438049\n","Epoch: 313, Training Loss = 0.8605189919471741\n","Epoch: 314, Training Loss = 0.8603578209877014\n","Epoch: 315, Training Loss = 0.8601971864700317\n","Epoch: 316, Training Loss = 0.8600367307662964\n","Epoch: 317, Training Loss = 0.8598769307136536\n","Epoch: 318, Training Loss = 0.8597174882888794\n","Epoch: 319, Training Loss = 0.8595583438873291\n","Epoch: 320, Training Loss = 0.8593997359275818\n","Accuracy =  0.6340512633323669 F1 weighted =  0.5652954578399658 F1 macro =  0.3326387405395508\n","Epoch: 321, Training Loss = 0.8592416048049927\n","Epoch: 322, Training Loss = 0.8590838313102722\n","Epoch: 323, Training Loss = 0.8589263558387756\n","Epoch: 324, Training Loss = 0.8587695360183716\n","Epoch: 325, Training Loss = 0.8586129546165466\n","Epoch: 326, Training Loss = 0.8584567904472351\n","Epoch: 327, Training Loss = 0.8583009839057922\n","Epoch: 328, Training Loss = 0.8581455945968628\n","Epoch: 329, Training Loss = 0.8579906821250916\n","Epoch: 330, Training Loss = 0.8578361868858337\n","Accuracy =  0.634315550327301 F1 weighted =  0.5662626028060913 F1 macro =  0.3335920572280884\n","Epoch: 331, Training Loss = 0.8576820492744446\n","Epoch: 332, Training Loss = 0.8575283288955688\n","Epoch: 333, Training Loss = 0.857374906539917\n","Epoch: 334, Training Loss = 0.8572219610214233\n","Epoch: 335, Training Loss = 0.8570693135261536\n","Epoch: 336, Training Loss = 0.856917142868042\n","Epoch: 337, Training Loss = 0.8567653894424438\n","Epoch: 338, Training Loss = 0.8566139340400696\n","Epoch: 339, Training Loss = 0.8564630150794983\n","Epoch: 340, Training Loss = 0.8563122749328613\n","Accuracy =  0.6347119212150574 F1 weighted =  0.5675958395004272 F1 macro =  0.33541661500930786\n","Epoch: 341, Training Loss = 0.8561619520187378\n","Epoch: 342, Training Loss = 0.8560120463371277\n","Epoch: 343, Training Loss = 0.855862557888031\n","Epoch: 344, Training Loss = 0.8557133078575134\n","Epoch: 345, Training Loss = 0.855564534664154\n","Epoch: 346, Training Loss = 0.8554160594940186\n","Epoch: 347, Training Loss = 0.8552679419517517\n","Epoch: 348, Training Loss = 0.8551203608512878\n","Epoch: 349, Training Loss = 0.8549729585647583\n","Epoch: 350, Training Loss = 0.8548259735107422\n","Accuracy =  0.6356368660926819 F1 weighted =  0.569368839263916 F1 macro =  0.33764034509658813\n","Epoch: 351, Training Loss = 0.8546793460845947\n","Epoch: 352, Training Loss = 0.8545330166816711\n","Epoch: 353, Training Loss = 0.8543872237205505\n","Epoch: 354, Training Loss = 0.8542415499687195\n","Epoch: 355, Training Loss = 0.8540964126586914\n","Epoch: 356, Training Loss = 0.8539515137672424\n","Epoch: 357, Training Loss = 0.8538070917129517\n","Epoch: 358, Training Loss = 0.8536628484725952\n","Epoch: 359, Training Loss = 0.8535190224647522\n","Epoch: 360, Training Loss = 0.8533756136894226\n","Accuracy =  0.635901153087616 F1 weighted =  0.5702971816062927 F1 macro =  0.3385569453239441\n","Epoch: 361, Training Loss = 0.8532324433326721\n","Epoch: 362, Training Loss = 0.8530896902084351\n","Epoch: 363, Training Loss = 0.8529472947120667\n","Epoch: 364, Training Loss = 0.8528050184249878\n","Epoch: 365, Training Loss = 0.8526632785797119\n","Epoch: 366, Training Loss = 0.8525218963623047\n","Epoch: 367, Training Loss = 0.8523806929588318\n","Epoch: 368, Training Loss = 0.8522399663925171\n","Epoch: 369, Training Loss = 0.8520995378494263\n","Epoch: 370, Training Loss = 0.8519594669342041\n","Accuracy =  0.6362975835800171 F1 weighted =  0.5714305639266968 F1 macro =  0.33973127603530884\n","Epoch: 371, Training Loss = 0.8518195748329163\n","Epoch: 372, Training Loss = 0.8516800999641418\n","Epoch: 373, Training Loss = 0.8515409231185913\n","Epoch: 374, Training Loss = 0.8514021039009094\n","Epoch: 375, Training Loss = 0.8512635827064514\n","Epoch: 376, Training Loss = 0.8511254787445068\n","Epoch: 377, Training Loss = 0.8509874939918518\n","Epoch: 378, Training Loss = 0.8508499264717102\n","Epoch: 379, Training Loss = 0.850712776184082\n","Epoch: 380, Training Loss = 0.8505757451057434\n","Accuracy =  0.6367600560188293 F1 weighted =  0.5724339485168457 F1 macro =  0.34113311767578125\n","Epoch: 381, Training Loss = 0.850439190864563\n","Epoch: 382, Training Loss = 0.8503028750419617\n","Epoch: 383, Training Loss = 0.850166916847229\n","Epoch: 384, Training Loss = 0.8500311374664307\n","Epoch: 385, Training Loss = 0.8498957753181458\n","Epoch: 386, Training Loss = 0.8497606515884399\n","Epoch: 387, Training Loss = 0.8496259450912476\n","Epoch: 388, Training Loss = 0.8494914174079895\n","Epoch: 389, Training Loss = 0.8493573069572449\n","Epoch: 390, Training Loss = 0.8492233753204346\n","Accuracy =  0.6368260979652405 F1 weighted =  0.5729627013206482 F1 macro =  0.3417024314403534\n","Epoch: 391, Training Loss = 0.8490898013114929\n","Epoch: 392, Training Loss = 0.8489565253257751\n","Epoch: 393, Training Loss = 0.8488235473632812\n","Epoch: 394, Training Loss = 0.8486907482147217\n","Epoch: 395, Training Loss = 0.8485584259033203\n","Epoch: 396, Training Loss = 0.8484262824058533\n","Epoch: 397, Training Loss = 0.8482943773269653\n","Epoch: 398, Training Loss = 0.8481628894805908\n","Epoch: 399, Training Loss = 0.8480316996574402\n","Epoch: 400, Training Loss = 0.8479008078575134\n","Accuracy =  0.6370242834091187 F1 weighted =  0.573775053024292 F1 macro =  0.34252065420150757\n","Epoch: 401, Training Loss = 0.847770094871521\n","Epoch: 402, Training Loss = 0.8476396203041077\n","Epoch: 403, Training Loss = 0.847509503364563\n","Epoch: 404, Training Loss = 0.847379744052887\n","Epoch: 405, Training Loss = 0.8472501635551453\n","Epoch: 406, Training Loss = 0.847121000289917\n","Epoch: 407, Training Loss = 0.8469918966293335\n","Epoch: 408, Training Loss = 0.8468632698059082\n","Epoch: 409, Training Loss = 0.8467348217964172\n","Epoch: 410, Training Loss = 0.8466066718101501\n","Accuracy =  0.6372885704040527 F1 weighted =  0.5747635364532471 F1 macro =  0.34398552775382996\n","Epoch: 411, Training Loss = 0.8464787006378174\n","Epoch: 412, Training Loss = 0.846351146697998\n","Epoch: 413, Training Loss = 0.846223771572113\n","Epoch: 414, Training Loss = 0.8460967540740967\n","Epoch: 415, Training Loss = 0.8459699153900146\n","Epoch: 416, Training Loss = 0.8458433747291565\n","Epoch: 417, Training Loss = 0.8457171320915222\n","Epoch: 418, Training Loss = 0.8455910682678223\n","Epoch: 419, Training Loss = 0.8454654216766357\n","Epoch: 420, Training Loss = 0.8453398942947388\n","Accuracy =  0.6375528573989868 F1 weighted =  0.5754801034927368 F1 macro =  0.34476757049560547\n","Epoch: 421, Training Loss = 0.8452146649360657\n","Epoch: 422, Training Loss = 0.8450896143913269\n","Epoch: 423, Training Loss = 0.8449649810791016\n","Epoch: 424, Training Loss = 0.8448405265808105\n","Epoch: 425, Training Loss = 0.8447163701057434\n","Epoch: 426, Training Loss = 0.8445923924446106\n","Epoch: 427, Training Loss = 0.8444687724113464\n","Epoch: 428, Training Loss = 0.8443453311920166\n","Epoch: 429, Training Loss = 0.8442221879959106\n","Epoch: 430, Training Loss = 0.844099223613739\n","Accuracy =  0.637751042842865 F1 weighted =  0.5764333605766296 F1 macro =  0.34591051936149597\n","Epoch: 431, Training Loss = 0.843976616859436\n","Epoch: 432, Training Loss = 0.8438541293144226\n","Epoch: 433, Training Loss = 0.8437319993972778\n","Epoch: 434, Training Loss = 0.8436102271080017\n","Epoch: 435, Training Loss = 0.8434884548187256\n","Epoch: 436, Training Loss = 0.8433670997619629\n","Epoch: 437, Training Loss = 0.8432458639144897\n","Epoch: 438, Training Loss = 0.8431249856948853\n","Epoch: 439, Training Loss = 0.8430041670799255\n","Epoch: 440, Training Loss = 0.8428837656974792\n","Accuracy =  0.6382135152816772 F1 weighted =  0.5776814222335815 F1 macro =  0.3477172553539276\n","Epoch: 441, Training Loss = 0.8427635431289673\n","Epoch: 442, Training Loss = 0.8426437377929688\n","Epoch: 443, Training Loss = 0.8425239324569702\n","Epoch: 444, Training Loss = 0.8424043655395508\n","Epoch: 445, Training Loss = 0.8422850966453552\n","Epoch: 446, Training Loss = 0.8421661257743835\n","Epoch: 447, Training Loss = 0.8420474529266357\n","Epoch: 448, Training Loss = 0.8419288396835327\n","Epoch: 449, Training Loss = 0.8418105244636536\n","Epoch: 450, Training Loss = 0.8416925072669983\n","Accuracy =  0.6384778022766113 F1 weighted =  0.5786664485931396 F1 macro =  0.35050082206726074\n","Epoch: 451, Training Loss = 0.8415746092796326\n","Epoch: 452, Training Loss = 0.8414570093154907\n","Epoch: 453, Training Loss = 0.841339647769928\n","Epoch: 454, Training Loss = 0.8412225246429443\n","Epoch: 455, Training Loss = 0.841105580329895\n","Epoch: 456, Training Loss = 0.84098881483078\n","Epoch: 457, Training Loss = 0.8408724665641785\n","Epoch: 458, Training Loss = 0.8407561779022217\n","Epoch: 459, Training Loss = 0.840640127658844\n","Epoch: 460, Training Loss = 0.8405243158340454\n","Accuracy =  0.6387420892715454 F1 weighted =  0.5793337225914001 F1 macro =  0.35106730461120605\n","Epoch: 461, Training Loss = 0.8404088020324707\n","Epoch: 462, Training Loss = 0.8402934074401855\n","Epoch: 463, Training Loss = 0.8401783108711243\n","Epoch: 464, Training Loss = 0.8400632739067078\n","Epoch: 465, Training Loss = 0.8399486541748047\n","Epoch: 466, Training Loss = 0.8398342132568359\n","Epoch: 467, Training Loss = 0.8397199511528015\n","Epoch: 468, Training Loss = 0.839605987071991\n","Epoch: 469, Training Loss = 0.8394920825958252\n","Epoch: 470, Training Loss = 0.8393785357475281\n","Accuracy =  0.6393367052078247 F1 weighted =  0.5802764892578125 F1 macro =  0.352108895778656\n","Epoch: 471, Training Loss = 0.8392651081085205\n","Epoch: 472, Training Loss = 0.8391518592834473\n","Epoch: 473, Training Loss = 0.8390389680862427\n","Epoch: 474, Training Loss = 0.8389262557029724\n","Epoch: 475, Training Loss = 0.8388136029243469\n","Epoch: 476, Training Loss = 0.8387013077735901\n","Epoch: 477, Training Loss = 0.8385891318321228\n","Epoch: 478, Training Loss = 0.8384773135185242\n","Epoch: 479, Training Loss = 0.8383655548095703\n","Epoch: 480, Training Loss = 0.8382540941238403\n","Accuracy =  0.6396670341491699 F1 weighted =  0.5811697840690613 F1 macro =  0.35324254631996155\n","Epoch: 481, Training Loss = 0.8381428122520447\n","Epoch: 482, Training Loss = 0.8380318284034729\n","Epoch: 483, Training Loss = 0.8379208445549011\n","Epoch: 484, Training Loss = 0.8378101587295532\n","Epoch: 485, Training Loss = 0.8376996517181396\n","Epoch: 486, Training Loss = 0.8375893831253052\n","Epoch: 487, Training Loss = 0.837479293346405\n","Epoch: 488, Training Loss = 0.837369441986084\n","Epoch: 489, Training Loss = 0.837259829044342\n","Epoch: 490, Training Loss = 0.8371502757072449\n","Accuracy =  0.6395348906517029 F1 weighted =  0.5815706253051758 F1 macro =  0.35498443245887756\n","Epoch: 491, Training Loss = 0.8370410203933716\n","Epoch: 492, Training Loss = 0.8369319438934326\n","Epoch: 493, Training Loss = 0.8368231654167175\n","Epoch: 494, Training Loss = 0.8367144465446472\n","Epoch: 495, Training Loss = 0.8366060256958008\n","Epoch: 496, Training Loss = 0.8364976644515991\n","Epoch: 497, Training Loss = 0.8363895416259766\n","Epoch: 498, Training Loss = 0.8362817168235779\n","Epoch: 499, Training Loss = 0.8361740708351135\n","Epoch: 500, Training Loss = 0.8360665440559387\n","Accuracy =  0.6393367052078247 F1 weighted =  0.5817432999610901 F1 macro =  0.35546156764030457\n","Epoch: 501, Training Loss = 0.8359591960906982\n","Epoch: 502, Training Loss = 0.8358520269393921\n","Epoch: 503, Training Loss = 0.835745096206665\n","Epoch: 504, Training Loss = 0.8356383442878723\n","Epoch: 505, Training Loss = 0.8355317711830139\n","Epoch: 506, Training Loss = 0.8354253768920898\n","Epoch: 507, Training Loss = 0.8353192210197449\n","Epoch: 508, Training Loss = 0.8352131247520447\n","Epoch: 509, Training Loss = 0.8351073861122131\n","Epoch: 510, Training Loss = 0.8350018262863159\n","Accuracy =  0.639468789100647 F1 weighted =  0.582434356212616 F1 macro =  0.35628587007522583\n","Epoch: 511, Training Loss = 0.8348963856697083\n","Epoch: 512, Training Loss = 0.8347911238670349\n","Epoch: 513, Training Loss = 0.8346859812736511\n","Epoch: 514, Training Loss = 0.8345811367034912\n","Epoch: 515, Training Loss = 0.8344764709472656\n","Epoch: 516, Training Loss = 0.8343719244003296\n","Epoch: 517, Training Loss = 0.8342675566673279\n","Epoch: 518, Training Loss = 0.8341633677482605\n","Epoch: 519, Training Loss = 0.8340594172477722\n","Epoch: 520, Training Loss = 0.8339555263519287\n","Accuracy =  0.6393367052078247 F1 weighted =  0.582928478717804 F1 macro =  0.3579672873020172\n","Epoch: 521, Training Loss = 0.8338519334793091\n","Epoch: 522, Training Loss = 0.8337485194206238\n","Epoch: 523, Training Loss = 0.833645224571228\n","Epoch: 524, Training Loss = 0.8335421681404114\n","Epoch: 525, Training Loss = 0.8334391713142395\n","Epoch: 526, Training Loss = 0.8333364129066467\n","Epoch: 527, Training Loss = 0.8332338929176331\n","Epoch: 528, Training Loss = 0.8331315517425537\n","Epoch: 529, Training Loss = 0.8330292701721191\n","Epoch: 530, Training Loss = 0.8329272270202637\n","Accuracy =  0.6398652195930481 F1 weighted =  0.5838452577590942 F1 macro =  0.3588605523109436\n","Epoch: 531, Training Loss = 0.8328253626823425\n","Epoch: 532, Training Loss = 0.8327236175537109\n","Epoch: 533, Training Loss = 0.8326221108436584\n","Epoch: 534, Training Loss = 0.8325207829475403\n","Epoch: 535, Training Loss = 0.8324195742607117\n","Epoch: 536, Training Loss = 0.8323184847831726\n","Epoch: 537, Training Loss = 0.8322176337242126\n","Epoch: 538, Training Loss = 0.8321169018745422\n","Epoch: 539, Training Loss = 0.8320164680480957\n","Epoch: 540, Training Loss = 0.8319160342216492\n","Accuracy =  0.6408562660217285 F1 weighted =  0.5853838324546814 F1 macro =  0.36057722568511963\n","Epoch: 541, Training Loss = 0.8318158388137817\n","Epoch: 542, Training Loss = 0.8317158222198486\n","Epoch: 543, Training Loss = 0.8316159844398499\n","Epoch: 544, Training Loss = 0.831516444683075\n","Epoch: 545, Training Loss = 0.8314167857170105\n","Epoch: 546, Training Loss = 0.8313174843788147\n","Epoch: 547, Training Loss = 0.8312181830406189\n","Epoch: 548, Training Loss = 0.831119179725647\n","Epoch: 549, Training Loss = 0.8310203552246094\n","Epoch: 550, Training Loss = 0.8309215903282166\n","Accuracy =  0.6407241225242615 F1 weighted =  0.585689902305603 F1 macro =  0.36244577169418335\n","Epoch: 551, Training Loss = 0.8308229446411133\n","Epoch: 552, Training Loss = 0.8307245969772339\n","Epoch: 553, Training Loss = 0.830626368522644\n","Epoch: 554, Training Loss = 0.8305283784866333\n","Epoch: 555, Training Loss = 0.8304303884506226\n","Epoch: 556, Training Loss = 0.8303326964378357\n","Epoch: 557, Training Loss = 0.8302350044250488\n","Epoch: 558, Training Loss = 0.8301376700401306\n","Epoch: 559, Training Loss = 0.8300403356552124\n","Epoch: 560, Training Loss = 0.8299431800842285\n","Accuracy =  0.6410544514656067 F1 weighted =  0.5865439772605896 F1 macro =  0.3659321069717407\n","Epoch: 561, Training Loss = 0.829846203327179\n","Epoch: 562, Training Loss = 0.829749345779419\n","Epoch: 563, Training Loss = 0.829652726650238\n","Epoch: 564, Training Loss = 0.8295561671257019\n","Epoch: 565, Training Loss = 0.8294599056243896\n","Epoch: 566, Training Loss = 0.8293636441230774\n","Epoch: 567, Training Loss = 0.8292676210403442\n","Epoch: 568, Training Loss = 0.8291716575622559\n","Epoch: 569, Training Loss = 0.8290759921073914\n","Epoch: 570, Training Loss = 0.8289803266525269\n","Accuracy =  0.6411865949630737 F1 weighted =  0.5871025919914246 F1 macro =  0.36796849966049194\n","Epoch: 571, Training Loss = 0.8288849592208862\n","Epoch: 572, Training Loss = 0.8287895917892456\n","Epoch: 573, Training Loss = 0.8286944627761841\n","Epoch: 574, Training Loss = 0.8285994529724121\n","Epoch: 575, Training Loss = 0.8285045623779297\n","Epoch: 576, Training Loss = 0.8284098505973816\n","Epoch: 577, Training Loss = 0.828315258026123\n","Epoch: 578, Training Loss = 0.8282209634780884\n","Epoch: 579, Training Loss = 0.8281267285346985\n","Epoch: 580, Training Loss = 0.8280325531959534\n","Accuracy =  0.641450822353363 F1 weighted =  0.5879439115524292 F1 macro =  0.3699410855770111\n","Epoch: 581, Training Loss = 0.8279386162757874\n","Epoch: 582, Training Loss = 0.8278447389602661\n","Epoch: 583, Training Loss = 0.827751100063324\n","Epoch: 584, Training Loss = 0.8276574611663818\n","Epoch: 585, Training Loss = 0.8275640606880188\n","Epoch: 586, Training Loss = 0.8274708390235901\n","Epoch: 587, Training Loss = 0.8273777961730957\n","Epoch: 588, Training Loss = 0.8272848129272461\n","Epoch: 589, Training Loss = 0.827191948890686\n","Epoch: 590, Training Loss = 0.8270992636680603\n","Accuracy =  0.6417151093482971 F1 weighted =  0.5885483026504517 F1 macro =  0.3704538643360138\n","Epoch: 591, Training Loss = 0.8270067572593689\n","Epoch: 592, Training Loss = 0.8269143104553223\n","Epoch: 593, Training Loss = 0.82682204246521\n","Epoch: 594, Training Loss = 0.826729953289032\n","Epoch: 595, Training Loss = 0.8266379237174988\n","Epoch: 596, Training Loss = 0.8265460729598999\n","Epoch: 597, Training Loss = 0.8264544010162354\n","Epoch: 598, Training Loss = 0.8263627886772156\n","Epoch: 599, Training Loss = 0.8262714147567749\n","Epoch: 600, Training Loss = 0.826180100440979\n","Accuracy =  0.6420454382896423 F1 weighted =  0.589253306388855 F1 macro =  0.371149480342865\n","Epoch: 601, Training Loss = 0.8260889053344727\n","Epoch: 602, Training Loss = 0.8259978890419006\n","Epoch: 603, Training Loss = 0.8259071111679077\n","Epoch: 604, Training Loss = 0.8258163332939148\n","Epoch: 605, Training Loss = 0.8257256746292114\n","Epoch: 606, Training Loss = 0.8256351351737976\n","Epoch: 607, Training Loss = 0.8255448937416077\n","Epoch: 608, Training Loss = 0.8254546523094177\n","Epoch: 609, Training Loss = 0.8253645896911621\n","Epoch: 610, Training Loss = 0.825274646282196\n","Accuracy =  0.6425079107284546 F1 weighted =  0.5901217460632324 F1 macro =  0.37307506799697876\n","Epoch: 611, Training Loss = 0.8251848816871643\n","Epoch: 612, Training Loss = 0.8250950574874878\n","Epoch: 613, Training Loss = 0.8250055909156799\n","Epoch: 614, Training Loss = 0.8249161243438721\n","Epoch: 615, Training Loss = 0.8248268365859985\n","Epoch: 616, Training Loss = 0.8247376680374146\n","Epoch: 617, Training Loss = 0.8246486783027649\n","Epoch: 618, Training Loss = 0.8245596885681152\n","Epoch: 619, Training Loss = 0.8244710564613342\n","Epoch: 620, Training Loss = 0.8243823647499084\n","Accuracy =  0.6429703831672668 F1 weighted =  0.5910241603851318 F1 macro =  0.37397462129592896\n","Epoch: 621, Training Loss = 0.824293851852417\n","Epoch: 622, Training Loss = 0.8242053985595703\n","Epoch: 623, Training Loss = 0.8241172432899475\n","Epoch: 624, Training Loss = 0.8240289688110352\n","Epoch: 625, Training Loss = 0.8239411115646362\n","Epoch: 626, Training Loss = 0.8238531947135925\n","Epoch: 627, Training Loss = 0.8237653970718384\n","Epoch: 628, Training Loss = 0.8236778378486633\n","Epoch: 629, Training Loss = 0.8235902786254883\n","Epoch: 630, Training Loss = 0.8235028982162476\n","Accuracy =  0.6431025266647339 F1 weighted =  0.5916166305541992 F1 macro =  0.37708544731140137\n","Epoch: 631, Training Loss = 0.8234156370162964\n","Epoch: 632, Training Loss = 0.8233286142349243\n","Epoch: 633, Training Loss = 0.8232415318489075\n","Epoch: 634, Training Loss = 0.823154628276825\n","Epoch: 635, Training Loss = 0.823067843914032\n","Epoch: 636, Training Loss = 0.8229813575744629\n","Epoch: 637, Training Loss = 0.8228946924209595\n","Epoch: 638, Training Loss = 0.8228083252906799\n","Epoch: 639, Training Loss = 0.8227220773696899\n","Epoch: 640, Training Loss = 0.8226360082626343\n","Accuracy =  0.6438292860984802 F1 weighted =  0.5927362442016602 F1 macro =  0.3782016336917877\n","Epoch: 641, Training Loss = 0.8225498199462891\n","Epoch: 642, Training Loss = 0.8224640488624573\n","Epoch: 643, Training Loss = 0.8223782181739807\n","Epoch: 644, Training Loss = 0.8222925662994385\n","Epoch: 645, Training Loss = 0.8222071528434753\n","Epoch: 646, Training Loss = 0.8221215605735779\n","Epoch: 647, Training Loss = 0.8220362663269043\n","Epoch: 648, Training Loss = 0.8219510912895203\n","Epoch: 649, Training Loss = 0.8218660950660706\n","Epoch: 650, Training Loss = 0.8217809796333313\n","Accuracy =  0.6441596150398254 F1 weighted =  0.5932978391647339 F1 macro =  0.37860792875289917\n","Epoch: 651, Training Loss = 0.8216962218284607\n","Epoch: 652, Training Loss = 0.8216115236282349\n","Epoch: 653, Training Loss = 0.8215268850326538\n","Epoch: 654, Training Loss = 0.8214424252510071\n","Epoch: 655, Training Loss = 0.8213580250740051\n","Epoch: 656, Training Loss = 0.8212738037109375\n","Epoch: 657, Training Loss = 0.8211896419525146\n","Epoch: 658, Training Loss = 0.8211057186126709\n","Epoch: 659, Training Loss = 0.8210216760635376\n","Epoch: 660, Training Loss = 0.820937991142273\n","Accuracy =  0.6441596150398254 F1 weighted =  0.5936453342437744 F1 macro =  0.3801761269569397\n","Epoch: 661, Training Loss = 0.8208541870117188\n","Epoch: 662, Training Loss = 0.820770800113678\n","Epoch: 663, Training Loss = 0.8206871747970581\n","Epoch: 664, Training Loss = 0.8206040263175964\n","Epoch: 665, Training Loss = 0.8205206990242004\n","Epoch: 666, Training Loss = 0.8204376101493835\n","Epoch: 667, Training Loss = 0.8203545808792114\n","Epoch: 668, Training Loss = 0.8202716708183289\n","Epoch: 669, Training Loss = 0.8201888203620911\n","Epoch: 670, Training Loss = 0.8201062083244324\n","Accuracy =  0.6440935730934143 F1 weighted =  0.5939030647277832 F1 macro =  0.3814791738986969\n","Epoch: 671, Training Loss = 0.8200236558914185\n","Epoch: 672, Training Loss = 0.8199412822723389\n","Epoch: 673, Training Loss = 0.8198587894439697\n","Epoch: 674, Training Loss = 0.8197766542434692\n","Epoch: 675, Training Loss = 0.819694459438324\n","Epoch: 676, Training Loss = 0.819612443447113\n","Epoch: 677, Training Loss = 0.8195306062698364\n","Epoch: 678, Training Loss = 0.8194487690925598\n","Epoch: 679, Training Loss = 0.8193671107292175\n","Epoch: 680, Training Loss = 0.81928551197052\n","Accuracy =  0.6441596150398254 F1 weighted =  0.5943921804428101 F1 macro =  0.3831944465637207\n","Epoch: 681, Training Loss = 0.8192040920257568\n","Epoch: 682, Training Loss = 0.8191226720809937\n","Epoch: 683, Training Loss = 0.8190414905548096\n","Epoch: 684, Training Loss = 0.8189603090286255\n","Epoch: 685, Training Loss = 0.8188793063163757\n","Epoch: 686, Training Loss = 0.8187984228134155\n","Epoch: 687, Training Loss = 0.8187175393104553\n","Epoch: 688, Training Loss = 0.8186367154121399\n","Epoch: 689, Training Loss = 0.8185561299324036\n","Epoch: 690, Training Loss = 0.8184756636619568\n","Accuracy =  0.6446881890296936 F1 weighted =  0.5951627492904663 F1 macro =  0.3840404152870178\n","Epoch: 691, Training Loss = 0.8183952569961548\n","Epoch: 692, Training Loss = 0.8183150291442871\n","Epoch: 693, Training Loss = 0.8182348012924194\n","Epoch: 694, Training Loss = 0.8181546330451965\n","Epoch: 695, Training Loss = 0.8180747032165527\n","Epoch: 696, Training Loss = 0.8179947733879089\n","Epoch: 697, Training Loss = 0.8179150819778442\n","Epoch: 698, Training Loss = 0.8178353309631348\n","Epoch: 699, Training Loss = 0.8177557587623596\n","Epoch: 700, Training Loss = 0.8176763653755188\n","Accuracy =  0.6450185179710388 F1 weighted =  0.5957196950912476 F1 macro =  0.384843111038208\n","Epoch: 701, Training Loss = 0.8175969123840332\n","Epoch: 702, Training Loss = 0.8175176382064819\n","Epoch: 703, Training Loss = 0.8174384832382202\n","Epoch: 704, Training Loss = 0.817359447479248\n","Epoch: 705, Training Loss = 0.8172803521156311\n","Epoch: 706, Training Loss = 0.8172016143798828\n","Epoch: 707, Training Loss = 0.817122757434845\n","Epoch: 708, Training Loss = 0.8170441389083862\n","Epoch: 709, Training Loss = 0.8169655799865723\n","Epoch: 710, Training Loss = 0.8168870210647583\n","Accuracy =  0.6458773612976074 F1 weighted =  0.5970719456672668 F1 macro =  0.3872825503349304\n","Epoch: 711, Training Loss = 0.8168087005615234\n","Epoch: 712, Training Loss = 0.8167304396629333\n","Epoch: 713, Training Loss = 0.8166521787643433\n","Epoch: 714, Training Loss = 0.8165742754936218\n","Epoch: 715, Training Loss = 0.8164962530136108\n","Epoch: 716, Training Loss = 0.8164183497428894\n","Epoch: 717, Training Loss = 0.8163405060768127\n","Epoch: 718, Training Loss = 0.81626296043396\n","Epoch: 719, Training Loss = 0.8161852955818176\n","Epoch: 720, Training Loss = 0.8161078691482544\n","Accuracy =  0.6466701626777649 F1 weighted =  0.5984355807304382 F1 macro =  0.38855311274528503\n","Epoch: 721, Training Loss = 0.8160304427146912\n","Epoch: 722, Training Loss = 0.8159531950950623\n","Epoch: 723, Training Loss = 0.8158759474754333\n","Epoch: 724, Training Loss = 0.815798819065094\n","Epoch: 725, Training Loss = 0.8157218098640442\n","Epoch: 726, Training Loss = 0.8156449198722839\n","Epoch: 727, Training Loss = 0.8155680894851685\n","Epoch: 728, Training Loss = 0.815491259098053\n","Epoch: 729, Training Loss = 0.8154147863388062\n","Epoch: 730, Training Loss = 0.8153381943702698\n","Accuracy =  0.6462737917900085 F1 weighted =  0.5983394384384155 F1 macro =  0.3897021412849426\n","Epoch: 731, Training Loss = 0.8152617812156677\n","Epoch: 732, Training Loss = 0.8151853680610657\n","Epoch: 733, Training Loss = 0.815109133720398\n","Epoch: 734, Training Loss = 0.8150330185890198\n","Epoch: 735, Training Loss = 0.8149569630622864\n","Epoch: 736, Training Loss = 0.8148809671401978\n","Epoch: 737, Training Loss = 0.8148052096366882\n","Epoch: 738, Training Loss = 0.8147293329238892\n","Epoch: 739, Training Loss = 0.8146536946296692\n","Epoch: 740, Training Loss = 0.8145779967308044\n","Accuracy =  0.6462076902389526 F1 weighted =  0.5984735488891602 F1 macro =  0.38981980085372925\n","Epoch: 741, Training Loss = 0.814502477645874\n","Epoch: 742, Training Loss = 0.8144270777702332\n","Epoch: 743, Training Loss = 0.8143518567085266\n","Epoch: 744, Training Loss = 0.8142766356468201\n","Epoch: 745, Training Loss = 0.8142014145851135\n","Epoch: 746, Training Loss = 0.8141263723373413\n","Epoch: 747, Training Loss = 0.8140513896942139\n","Epoch: 748, Training Loss = 0.8139765858650208\n","Epoch: 749, Training Loss = 0.8139017224311829\n","Epoch: 750, Training Loss = 0.8138270378112793\n","Accuracy =  0.6467362642288208 F1 weighted =  0.599374532699585 F1 macro =  0.3908573389053345\n","Epoch: 751, Training Loss = 0.8137524127960205\n","Epoch: 752, Training Loss = 0.813677966594696\n","Epoch: 753, Training Loss = 0.8136034607887268\n","Epoch: 754, Training Loss = 0.8135291934013367\n","Epoch: 755, Training Loss = 0.8134549260139465\n","Epoch: 756, Training Loss = 0.813380777835846\n","Epoch: 757, Training Loss = 0.8133067488670349\n","Epoch: 758, Training Loss = 0.8132327198982239\n","Epoch: 759, Training Loss = 0.8131588101387024\n","Epoch: 760, Training Loss = 0.8130849599838257\n","Accuracy =  0.6468023061752319 F1 weighted =  0.5995903611183167 F1 macro =  0.3908913731575012\n","Epoch: 761, Training Loss = 0.8130112290382385\n","Epoch: 762, Training Loss = 0.8129376173019409\n","Epoch: 763, Training Loss = 0.8128640651702881\n","Epoch: 764, Training Loss = 0.8127906918525696\n","Epoch: 765, Training Loss = 0.8127173185348511\n","Epoch: 766, Training Loss = 0.8126440048217773\n","Epoch: 767, Training Loss = 0.8125706911087036\n","Epoch: 768, Training Loss = 0.8124976754188538\n","Epoch: 769, Training Loss = 0.8124247193336487\n","Epoch: 770, Training Loss = 0.8123517036437988\n","Accuracy =  0.6473308801651001 F1 weighted =  0.6005256772041321 F1 macro =  0.3919147849082947\n","Epoch: 771, Training Loss = 0.8122788667678833\n","Epoch: 772, Training Loss = 0.8122061491012573\n","Epoch: 773, Training Loss = 0.8121333718299866\n","Epoch: 774, Training Loss = 0.8120607137680054\n","Epoch: 775, Training Loss = 0.8119882941246033\n","Epoch: 776, Training Loss = 0.8119157552719116\n","Epoch: 777, Training Loss = 0.8118435144424438\n","Epoch: 778, Training Loss = 0.8117712736129761\n","Epoch: 779, Training Loss = 0.8116990923881531\n","Epoch: 780, Training Loss = 0.8116269707679749\n","Accuracy =  0.6471987366676331 F1 weighted =  0.6007112264633179 F1 macro =  0.39228469133377075\n","Epoch: 781, Training Loss = 0.8115549087524414\n","Epoch: 782, Training Loss = 0.8114829659461975\n","Epoch: 783, Training Loss = 0.8114112019538879\n","Epoch: 784, Training Loss = 0.8113393187522888\n","Epoch: 785, Training Loss = 0.8112676739692688\n","Epoch: 786, Training Loss = 0.8111960291862488\n","Epoch: 787, Training Loss = 0.8111245632171631\n","Epoch: 788, Training Loss = 0.8110530972480774\n","Epoch: 789, Training Loss = 0.8109817504882812\n","Epoch: 790, Training Loss = 0.8109105229377747\n","Accuracy =  0.6472647786140442 F1 weighted =  0.601193368434906 F1 macro =  0.3940313756465912\n","Epoch: 791, Training Loss = 0.8108392357826233\n","Epoch: 792, Training Loss = 0.810768187046051\n","Epoch: 793, Training Loss = 0.8106971979141235\n","Epoch: 794, Training Loss = 0.8106261491775513\n","Epoch: 795, Training Loss = 0.8105552792549133\n","Epoch: 796, Training Loss = 0.8104845285415649\n","Epoch: 797, Training Loss = 0.8104138374328613\n","Epoch: 798, Training Loss = 0.8103431463241577\n","Epoch: 799, Training Loss = 0.8102725744247437\n","Epoch: 800, Training Loss = 0.8102020621299744\n","Accuracy =  0.6471987366676331 F1 weighted =  0.6013803482055664 F1 macro =  0.39433008432388306\n","Epoch: 801, Training Loss = 0.8101317286491394\n","Epoch: 802, Training Loss = 0.8100613951683044\n","Epoch: 803, Training Loss = 0.809991180896759\n","Epoch: 804, Training Loss = 0.8099210262298584\n","Epoch: 805, Training Loss = 0.8098510503768921\n","Epoch: 806, Training Loss = 0.809781014919281\n","Epoch: 807, Training Loss = 0.8097110986709595\n","Epoch: 808, Training Loss = 0.8096412420272827\n","Epoch: 809, Training Loss = 0.809571385383606\n","Epoch: 810, Training Loss = 0.8095018267631531\n","Accuracy =  0.6471987366676331 F1 weighted =  0.6016062498092651 F1 macro =  0.3957934081554413\n","Epoch: 811, Training Loss = 0.8094321489334106\n","Epoch: 812, Training Loss = 0.8093625903129578\n","Epoch: 813, Training Loss = 0.8092930912971497\n","Epoch: 814, Training Loss = 0.8092237114906311\n","Epoch: 815, Training Loss = 0.8091544508934021\n","Epoch: 816, Training Loss = 0.8090852499008179\n","Epoch: 817, Training Loss = 0.8090159893035889\n","Epoch: 818, Training Loss = 0.8089470267295837\n","Epoch: 819, Training Loss = 0.8088780045509338\n","Epoch: 820, Training Loss = 0.8088090419769287\n","Accuracy =  0.6475290656089783 F1 weighted =  0.6021669507026672 F1 macro =  0.3963760733604431\n","Epoch: 821, Training Loss = 0.8087402582168579\n","Epoch: 822, Training Loss = 0.8086714744567871\n","Epoch: 823, Training Loss = 0.8086026906967163\n","Epoch: 824, Training Loss = 0.8085341453552246\n","Epoch: 825, Training Loss = 0.8084656000137329\n","Epoch: 826, Training Loss = 0.8083971738815308\n","Epoch: 827, Training Loss = 0.8083288073539734\n","Epoch: 828, Training Loss = 0.808260440826416\n","Epoch: 829, Training Loss = 0.8081921935081482\n","Epoch: 830, Training Loss = 0.8081239461898804\n","Accuracy =  0.6477933526039124 F1 weighted =  0.6027337908744812 F1 macro =  0.3969467580318451\n","Epoch: 831, Training Loss = 0.8080559968948364\n","Epoch: 832, Training Loss = 0.8079878687858582\n","Epoch: 833, Training Loss = 0.8079199194908142\n","Epoch: 834, Training Loss = 0.8078520894050598\n","Epoch: 835, Training Loss = 0.8077842593193054\n","Epoch: 836, Training Loss = 0.8077165484428406\n","Epoch: 837, Training Loss = 0.8076488971710205\n","Epoch: 838, Training Loss = 0.8075813055038452\n","Epoch: 839, Training Loss = 0.8075138330459595\n","Epoch: 840, Training Loss = 0.8074463605880737\n","Accuracy =  0.6479915380477905 F1 weighted =  0.60335773229599 F1 macro =  0.39887675642967224\n","Epoch: 841, Training Loss = 0.807378888130188\n","Epoch: 842, Training Loss = 0.8073117733001709\n","Epoch: 843, Training Loss = 0.8072445392608643\n","Epoch: 844, Training Loss = 0.8071773052215576\n","Epoch: 845, Training Loss = 0.8071103096008301\n","Epoch: 846, Training Loss = 0.8070432543754578\n","Epoch: 847, Training Loss = 0.8069762587547302\n","Epoch: 848, Training Loss = 0.806909441947937\n","Epoch: 849, Training Loss = 0.8068426847457886\n","Epoch: 850, Training Loss = 0.8067759275436401\n","Accuracy =  0.6483879685401917 F1 weighted =  0.6041046977043152 F1 macro =  0.400752454996109\n","Epoch: 851, Training Loss = 0.8067092895507812\n","Epoch: 852, Training Loss = 0.8066426515579224\n","Epoch: 853, Training Loss = 0.8065761923789978\n","Epoch: 854, Training Loss = 0.806509792804718\n","Epoch: 855, Training Loss = 0.8064433336257935\n","Epoch: 856, Training Loss = 0.8063770532608032\n","Epoch: 857, Training Loss = 0.8063108325004578\n","Epoch: 858, Training Loss = 0.8062446713447571\n","Epoch: 859, Training Loss = 0.806178629398346\n","Epoch: 860, Training Loss = 0.8061126470565796\n","Accuracy =  0.6484540104866028 F1 weighted =  0.6042492985725403 F1 macro =  0.4008747935295105\n","Epoch: 861, Training Loss = 0.8060466647148132\n","Epoch: 862, Training Loss = 0.8059808015823364\n","Epoch: 863, Training Loss = 0.8059149980545044\n","Epoch: 864, Training Loss = 0.8058491945266724\n","Epoch: 865, Training Loss = 0.8057835102081299\n","Epoch: 866, Training Loss = 0.8057180047035217\n","Epoch: 867, Training Loss = 0.8056524395942688\n","Epoch: 868, Training Loss = 0.8055869340896606\n","Epoch: 869, Training Loss = 0.805521547794342\n","Epoch: 870, Training Loss = 0.805456280708313\n","Accuracy =  0.6490486264228821 F1 weighted =  0.6050319671630859 F1 macro =  0.4028615653514862\n","Epoch: 871, Training Loss = 0.8053909540176392\n","Epoch: 872, Training Loss = 0.8053258061408997\n","Epoch: 873, Training Loss = 0.8052606582641602\n","Epoch: 874, Training Loss = 0.8051956295967102\n","Epoch: 875, Training Loss = 0.8051305413246155\n","Epoch: 876, Training Loss = 0.8050656914710999\n","Epoch: 877, Training Loss = 0.8050007224082947\n","Epoch: 878, Training Loss = 0.8049361109733582\n","Epoch: 879, Training Loss = 0.8048713207244873\n","Epoch: 880, Training Loss = 0.804806649684906\n","Accuracy =  0.6491807699203491 F1 weighted =  0.6054933071136475 F1 macro =  0.40563473105430603\n","Epoch: 881, Training Loss = 0.8047420978546143\n","Epoch: 882, Training Loss = 0.8046774864196777\n","Epoch: 883, Training Loss = 0.8046130537986755\n","Epoch: 884, Training Loss = 0.8045486211776733\n","Epoch: 885, Training Loss = 0.8044843673706055\n","Epoch: 886, Training Loss = 0.8044201731681824\n","Epoch: 887, Training Loss = 0.8043559193611145\n","Epoch: 888, Training Loss = 0.8042917847633362\n","Epoch: 889, Training Loss = 0.8042277693748474\n","Epoch: 890, Training Loss = 0.8041636347770691\n","Accuracy =  0.6495771408081055 F1 weighted =  0.6060606241226196 F1 macro =  0.406235009431839\n","Epoch: 891, Training Loss = 0.8040997982025146\n","Epoch: 892, Training Loss = 0.8040358424186707\n","Epoch: 893, Training Loss = 0.8039720058441162\n","Epoch: 894, Training Loss = 0.8039084076881409\n","Epoch: 895, Training Loss = 0.803844690322876\n","Epoch: 896, Training Loss = 0.8037810921669006\n","Epoch: 897, Training Loss = 0.8037175536155701\n","Epoch: 898, Training Loss = 0.8036540150642395\n","Epoch: 899, Training Loss = 0.8035906553268433\n","Epoch: 900, Training Loss = 0.803527295589447\n","Accuracy =  0.6493789553642273 F1 weighted =  0.605994462966919 F1 macro =  0.40616288781166077\n","Epoch: 901, Training Loss = 0.8034639954566956\n","Epoch: 902, Training Loss = 0.8034008145332336\n","Epoch: 903, Training Loss = 0.8033376336097717\n","Epoch: 904, Training Loss = 0.8032745122909546\n","Epoch: 905, Training Loss = 0.803211510181427\n","Epoch: 906, Training Loss = 0.8031485080718994\n","Epoch: 907, Training Loss = 0.8030855655670166\n","Epoch: 908, Training Loss = 0.8030227422714233\n","Epoch: 909, Training Loss = 0.8029599189758301\n","Epoch: 910, Training Loss = 0.8028972148895264\n","Accuracy =  0.6495110988616943 F1 weighted =  0.6064119338989258 F1 macro =  0.406760573387146\n","Epoch: 911, Training Loss = 0.8028345108032227\n","Epoch: 912, Training Loss = 0.802772045135498\n","Epoch: 913, Training Loss = 0.8027095198631287\n","Epoch: 914, Training Loss = 0.8026469349861145\n","Epoch: 915, Training Loss = 0.8025845885276794\n","Epoch: 916, Training Loss = 0.8025222420692444\n","Epoch: 917, Training Loss = 0.8024598956108093\n","Epoch: 918, Training Loss = 0.8023977279663086\n","Epoch: 919, Training Loss = 0.8023355603218079\n","Epoch: 920, Training Loss = 0.8022734522819519\n","Accuracy =  0.6495110988616943 F1 weighted =  0.6066288948059082 F1 macro =  0.40705063939094543\n","Epoch: 921, Training Loss = 0.8022114038467407\n","Epoch: 922, Training Loss = 0.8021494150161743\n","Epoch: 923, Training Loss = 0.8020874857902527\n","Epoch: 924, Training Loss = 0.8020256161689758\n","Epoch: 925, Training Loss = 0.8019639253616333\n","Epoch: 926, Training Loss = 0.8019022941589355\n","Epoch: 927, Training Loss = 0.8018403649330139\n","Epoch: 928, Training Loss = 0.8017789125442505\n","Epoch: 929, Training Loss = 0.8017172813415527\n","Epoch: 930, Training Loss = 0.8016557693481445\n","Accuracy =  0.6492468118667603 F1 weighted =  0.6065711975097656 F1 macro =  0.40698790550231934\n","Epoch: 931, Training Loss = 0.8015943765640259\n","Epoch: 932, Training Loss = 0.8015329837799072\n","Epoch: 933, Training Loss = 0.8014717102050781\n","Epoch: 934, Training Loss = 0.801410436630249\n","Epoch: 935, Training Loss = 0.8013492226600647\n","Epoch: 936, Training Loss = 0.8012881278991699\n","Epoch: 937, Training Loss = 0.8012270927429199\n","Epoch: 938, Training Loss = 0.8011660575866699\n","Epoch: 939, Training Loss = 0.8011050820350647\n","Epoch: 940, Training Loss = 0.801044225692749\n","Accuracy =  0.6496432423591614 F1 weighted =  0.6073434948921204 F1 macro =  0.41006335616111755\n","Epoch: 941, Training Loss = 0.8009833097457886\n","Epoch: 942, Training Loss = 0.8009226322174072\n","Epoch: 943, Training Loss = 0.8008618354797363\n","Epoch: 944, Training Loss = 0.800801157951355\n","Epoch: 945, Training Loss = 0.8007405996322632\n","Epoch: 946, Training Loss = 0.8006799817085266\n","Epoch: 947, Training Loss = 0.8006195425987244\n","Epoch: 948, Training Loss = 0.8005591034889221\n","Epoch: 949, Training Loss = 0.8004987835884094\n","Epoch: 950, Training Loss = 0.800438404083252\n","Accuracy =  0.6499075293540955 F1 weighted =  0.607808530330658 F1 macro =  0.41164442896842957\n","Epoch: 951, Training Loss = 0.8003782033920288\n","Epoch: 952, Training Loss = 0.8003179430961609\n","Epoch: 953, Training Loss = 0.8002578020095825\n","Epoch: 954, Training Loss = 0.8001977801322937\n","Epoch: 955, Training Loss = 0.8001377582550049\n","Epoch: 956, Training Loss = 0.8000777363777161\n","Epoch: 957, Training Loss = 0.8000178337097168\n","Epoch: 958, Training Loss = 0.7999579310417175\n","Epoch: 959, Training Loss = 0.7998982071876526\n","Epoch: 960, Training Loss = 0.7998384237289429\n","Accuracy =  0.6502378582954407 F1 weighted =  0.6083641648292542 F1 macro =  0.4122079908847809\n","Epoch: 961, Training Loss = 0.7997787594795227\n","Epoch: 962, Training Loss = 0.7997191548347473\n","Epoch: 963, Training Loss = 0.7996596097946167\n","Epoch: 964, Training Loss = 0.7996001243591309\n","Epoch: 965, Training Loss = 0.799540638923645\n","Epoch: 966, Training Loss = 0.7994812726974487\n","Epoch: 967, Training Loss = 0.7994219660758972\n","Epoch: 968, Training Loss = 0.7993625402450562\n","Epoch: 969, Training Loss = 0.7993033528327942\n","Epoch: 970, Training Loss = 0.7992441654205322\n","Accuracy =  0.6501717567443848 F1 weighted =  0.60833340883255 F1 macro =  0.4121610224246979\n","Epoch: 971, Training Loss = 0.799185037612915\n","Epoch: 972, Training Loss = 0.7991260290145874\n","Epoch: 973, Training Loss = 0.799066960811615\n","Epoch: 974, Training Loss = 0.7990080118179321\n","Epoch: 975, Training Loss = 0.798949122428894\n","Epoch: 976, Training Loss = 0.7988902926445007\n","Epoch: 977, Training Loss = 0.7988314628601074\n","Epoch: 978, Training Loss = 0.7987727522850037\n","Epoch: 979, Training Loss = 0.7987141013145447\n","Epoch: 980, Training Loss = 0.7986555099487305\n","Accuracy =  0.6499735713005066 F1 weighted =  0.6083881258964539 F1 macro =  0.4121827483177185\n","Epoch: 981, Training Loss = 0.7985968589782715\n","Epoch: 982, Training Loss = 0.7985384464263916\n","Epoch: 983, Training Loss = 0.7984800338745117\n","Epoch: 984, Training Loss = 0.7984215617179871\n","Epoch: 985, Training Loss = 0.7983631491661072\n","Epoch: 986, Training Loss = 0.7983048558235168\n","Epoch: 987, Training Loss = 0.7982465624809265\n","Epoch: 988, Training Loss = 0.7981884479522705\n","Epoch: 989, Training Loss = 0.7981303334236145\n","Epoch: 990, Training Loss = 0.7980722784996033\n","Accuracy =  0.6496432423591614 F1 weighted =  0.6083461046218872 F1 macro =  0.41223371028900146\n","Epoch: 991, Training Loss = 0.798014223575592\n","Epoch: 992, Training Loss = 0.7979562282562256\n","Epoch: 993, Training Loss = 0.7978982925415039\n","Epoch: 994, Training Loss = 0.797840416431427\n","Epoch: 995, Training Loss = 0.7977825999259949\n","Epoch: 996, Training Loss = 0.7977249026298523\n","Epoch: 997, Training Loss = 0.7976672053337097\n","Epoch: 998, Training Loss = 0.7976095080375671\n","Epoch: 999, Training Loss = 0.7975518703460693\n","Epoch: 1000, Training Loss = 0.7974943518638611\n","Accuracy =  0.6497753858566284 F1 weighted =  0.6087568998336792 F1 macro =  0.41357189416885376\n","Epoch: 1001, Training Loss = 0.7974368929862976\n","Epoch: 1002, Training Loss = 0.7973793745040894\n","Epoch: 1003, Training Loss = 0.7973220348358154\n","Epoch: 1004, Training Loss = 0.7972646951675415\n","Epoch: 1005, Training Loss = 0.7972074151039124\n","Epoch: 1006, Training Loss = 0.7971501350402832\n","Epoch: 1007, Training Loss = 0.7970930337905884\n","Epoch: 1008, Training Loss = 0.7970358729362488\n","Epoch: 1009, Training Loss = 0.7969788312911987\n","Epoch: 1010, Training Loss = 0.7969218492507935\n","Accuracy =  0.6502378582954407 F1 weighted =  0.6094688773155212 F1 macro =  0.4145156741142273\n","Epoch: 1011, Training Loss = 0.7968648672103882\n","Epoch: 1012, Training Loss = 0.7968078851699829\n","Epoch: 1013, Training Loss = 0.7967510223388672\n","Epoch: 1014, Training Loss = 0.7966942191123962\n","Epoch: 1015, Training Loss = 0.7966373562812805\n","Epoch: 1016, Training Loss = 0.7965806722640991\n","Epoch: 1017, Training Loss = 0.7965240478515625\n","Epoch: 1018, Training Loss = 0.7964674234390259\n","Epoch: 1019, Training Loss = 0.796410858631134\n","Epoch: 1020, Training Loss = 0.796354353427887\n","Accuracy =  0.6507003307342529 F1 weighted =  0.6100456714630127 F1 macro =  0.41484200954437256\n","Epoch: 1021, Training Loss = 0.7962978482246399\n","Epoch: 1022, Training Loss = 0.7962415218353271\n","Epoch: 1023, Training Loss = 0.7961851954460144\n","Epoch: 1024, Training Loss = 0.7961288094520569\n","Epoch: 1025, Training Loss = 0.7960725426673889\n","Epoch: 1026, Training Loss = 0.7960163354873657\n","Epoch: 1027, Training Loss = 0.7959601283073425\n","Epoch: 1028, Training Loss = 0.7959040403366089\n","Epoch: 1029, Training Loss = 0.7958480715751648\n","Epoch: 1030, Training Loss = 0.7957920432090759\n","Accuracy =  0.6507663726806641 F1 weighted =  0.6102572679519653 F1 macro =  0.41512367129325867\n","Epoch: 1031, Training Loss = 0.7957360744476318\n","Epoch: 1032, Training Loss = 0.7956801652908325\n","Epoch: 1033, Training Loss = 0.795624315738678\n","Epoch: 1034, Training Loss = 0.7955684661865234\n","Epoch: 1035, Training Loss = 0.7955126762390137\n","Epoch: 1036, Training Loss = 0.7954570055007935\n","Epoch: 1037, Training Loss = 0.795401394367218\n","Epoch: 1038, Training Loss = 0.7953457236289978\n","Epoch: 1039, Training Loss = 0.7952901721000671\n","Epoch: 1040, Training Loss = 0.795234739780426\n","Accuracy =  0.6507003307342529 F1 weighted =  0.6102907061576843 F1 macro =  0.41622233390808105\n","Epoch: 1041, Training Loss = 0.7951791882514954\n","Epoch: 1042, Training Loss = 0.7951239347457886\n","Epoch: 1043, Training Loss = 0.7950684428215027\n","Epoch: 1044, Training Loss = 0.7950131893157959\n","Epoch: 1045, Training Loss = 0.7949579358100891\n","Epoch: 1046, Training Loss = 0.7949026226997375\n","Epoch: 1047, Training Loss = 0.7948474287986755\n","Epoch: 1048, Training Loss = 0.7947923541069031\n","Epoch: 1049, Training Loss = 0.7947373390197754\n","Epoch: 1050, Training Loss = 0.7946823239326477\n","Accuracy =  0.6507663726806641 F1 weighted =  0.610565721988678 F1 macro =  0.41731226444244385\n","Epoch: 1051, Training Loss = 0.79462730884552\n","Epoch: 1052, Training Loss = 0.7945724129676819\n","Epoch: 1053, Training Loss = 0.794517457485199\n","Epoch: 1054, Training Loss = 0.7944626212120056\n","Epoch: 1055, Training Loss = 0.7944079041481018\n","Epoch: 1056, Training Loss = 0.7943531274795532\n","Epoch: 1057, Training Loss = 0.7942984104156494\n","Epoch: 1058, Training Loss = 0.7942438125610352\n","Epoch: 1059, Training Loss = 0.7941891551017761\n","Epoch: 1060, Training Loss = 0.7941346764564514\n","Accuracy =  0.6510967016220093 F1 weighted =  0.6111973524093628 F1 macro =  0.4177626371383667\n","Epoch: 1061, Training Loss = 0.7940801978111267\n","Epoch: 1062, Training Loss = 0.794025719165802\n","Epoch: 1063, Training Loss = 0.7939714193344116\n","Epoch: 1064, Training Loss = 0.7939170002937317\n","Epoch: 1065, Training Loss = 0.7938626408576965\n","Epoch: 1066, Training Loss = 0.7938084006309509\n","Epoch: 1067, Training Loss = 0.7937542200088501\n","Epoch: 1068, Training Loss = 0.7936999797821045\n","Epoch: 1069, Training Loss = 0.7936459183692932\n","Epoch: 1070, Training Loss = 0.7935917973518372\n","Accuracy =  0.6511628031730652 F1 weighted =  0.611466109752655 F1 macro =  0.4180135726928711\n","Epoch: 1071, Training Loss = 0.7935377955436707\n","Epoch: 1072, Training Loss = 0.7934838533401489\n","Epoch: 1073, Training Loss = 0.793429970741272\n","Epoch: 1074, Training Loss = 0.7933759689331055\n","Epoch: 1075, Training Loss = 0.7933222055435181\n","Epoch: 1076, Training Loss = 0.7932683229446411\n","Epoch: 1077, Training Loss = 0.7932146191596985\n","Epoch: 1078, Training Loss = 0.7931608557701111\n","Epoch: 1079, Training Loss = 0.793107271194458\n","Epoch: 1080, Training Loss = 0.7930536866188049\n","Accuracy =  0.6515591740608215 F1 weighted =  0.6120145916938782 F1 macro =  0.41872650384902954\n","Epoch: 1081, Training Loss = 0.7930000424385071\n","Epoch: 1082, Training Loss = 0.7929466366767883\n","Epoch: 1083, Training Loss = 0.7928931713104248\n","Epoch: 1084, Training Loss = 0.7928396463394165\n","Epoch: 1085, Training Loss = 0.7927863001823425\n","Epoch: 1086, Training Loss = 0.7927330136299133\n","Epoch: 1087, Training Loss = 0.7926797866821289\n","Epoch: 1088, Training Loss = 0.7926265001296997\n","Epoch: 1089, Training Loss = 0.7925732731819153\n","Epoch: 1090, Training Loss = 0.7925201058387756\n","Accuracy =  0.6517574191093445 F1 weighted =  0.6123166680335999 F1 macro =  0.4190782308578491\n","Epoch: 1091, Training Loss = 0.7924669981002808\n","Epoch: 1092, Training Loss = 0.7924140095710754\n","Epoch: 1093, Training Loss = 0.7923609018325806\n","Epoch: 1094, Training Loss = 0.7923078536987305\n","Epoch: 1095, Training Loss = 0.7922549247741699\n","Epoch: 1096, Training Loss = 0.7922021746635437\n","Epoch: 1097, Training Loss = 0.7921491265296936\n","Epoch: 1098, Training Loss = 0.7920965552330017\n","Epoch: 1099, Training Loss = 0.7920437455177307\n","Epoch: 1100, Training Loss = 0.7919910550117493\n","Accuracy =  0.6519556045532227 F1 weighted =  0.6126580834388733 F1 macro =  0.41934114694595337\n","Epoch: 1101, Training Loss = 0.7919383645057678\n","Epoch: 1102, Training Loss = 0.7918857336044312\n","Epoch: 1103, Training Loss = 0.791833221912384\n","Epoch: 1104, Training Loss = 0.7917806506156921\n","Epoch: 1105, Training Loss = 0.7917280793190002\n","Epoch: 1106, Training Loss = 0.7916757464408875\n","Epoch: 1107, Training Loss = 0.7916232943534851\n","Epoch: 1108, Training Loss = 0.7915710210800171\n","Epoch: 1109, Training Loss = 0.7915186882019043\n","Epoch: 1110, Training Loss = 0.7914664149284363\n","Accuracy =  0.6521537899971008 F1 weighted =  0.6129814386367798 F1 macro =  0.4206732213497162\n","Epoch: 1111, Training Loss = 0.791414201259613\n","Epoch: 1112, Training Loss = 0.7913620471954346\n","Epoch: 1113, Training Loss = 0.7913099527359009\n","Epoch: 1114, Training Loss = 0.7912577986717224\n","Epoch: 1115, Training Loss = 0.7912057042121887\n","Epoch: 1116, Training Loss = 0.7911536693572998\n","Epoch: 1117, Training Loss = 0.7911018133163452\n","Epoch: 1118, Training Loss = 0.7910497784614563\n","Epoch: 1119, Training Loss = 0.7909979820251465\n","Epoch: 1120, Training Loss = 0.7909461259841919\n","Accuracy =  0.6521537899971008 F1 weighted =  0.6131566762924194 F1 macro =  0.4207307696342468\n","Epoch: 1121, Training Loss = 0.7908944487571716\n","Epoch: 1122, Training Loss = 0.790842592716217\n","Epoch: 1123, Training Loss = 0.7907910346984863\n","Epoch: 1124, Training Loss = 0.7907392978668213\n","Epoch: 1125, Training Loss = 0.7906876802444458\n","Epoch: 1126, Training Loss = 0.7906361222267151\n","Epoch: 1127, Training Loss = 0.7905845642089844\n","Epoch: 1128, Training Loss = 0.7905331254005432\n","Epoch: 1129, Training Loss = 0.7904816269874573\n","Epoch: 1130, Training Loss = 0.7904301881790161\n","Accuracy =  0.6524180769920349 F1 weighted =  0.6134958863258362 F1 macro =  0.42102861404418945\n","Epoch: 1131, Training Loss = 0.7903788685798645\n","Epoch: 1132, Training Loss = 0.7903276085853577\n","Epoch: 1133, Training Loss = 0.7902763485908508\n","Epoch: 1134, Training Loss = 0.790225088596344\n","Epoch: 1135, Training Loss = 0.7901739478111267\n","Epoch: 1136, Training Loss = 0.7901227474212646\n","Epoch: 1137, Training Loss = 0.7900717258453369\n","Epoch: 1138, Training Loss = 0.7900205850601196\n","Epoch: 1139, Training Loss = 0.7899695038795471\n","Epoch: 1140, Training Loss = 0.7899186015129089\n","Accuracy =  0.652484118938446 F1 weighted =  0.6137248873710632 F1 macro =  0.42131125926971436\n","Epoch: 1141, Training Loss = 0.7898675799369812\n","Epoch: 1142, Training Loss = 0.7898166179656982\n","Epoch: 1143, Training Loss = 0.7897658944129944\n","Epoch: 1144, Training Loss = 0.789715051651001\n","Epoch: 1145, Training Loss = 0.7896643280982971\n","Epoch: 1146, Training Loss = 0.7896135449409485\n","Epoch: 1147, Training Loss = 0.7895628809928894\n","Epoch: 1148, Training Loss = 0.7895122170448303\n","Epoch: 1149, Training Loss = 0.7894615530967712\n","Epoch: 1150, Training Loss = 0.7894110083580017\n","Accuracy =  0.652814507484436 F1 weighted =  0.6142328381538391 F1 macro =  0.4217468202114105\n","Epoch: 1151, Training Loss = 0.7893604636192322\n","Epoch: 1152, Training Loss = 0.7893100380897522\n","Epoch: 1153, Training Loss = 0.7892596125602722\n","Epoch: 1154, Training Loss = 0.789209246635437\n","Epoch: 1155, Training Loss = 0.7891588807106018\n","Epoch: 1156, Training Loss = 0.7891084551811218\n","Epoch: 1157, Training Loss = 0.7890581488609314\n","Epoch: 1158, Training Loss = 0.7890079021453857\n","Epoch: 1159, Training Loss = 0.7889576554298401\n","Epoch: 1160, Training Loss = 0.7889075875282288\n","Accuracy =  0.6532769799232483 F1 weighted =  0.6149235963821411 F1 macro =  0.42349839210510254\n","Epoch: 1161, Training Loss = 0.7888575196266174\n","Epoch: 1162, Training Loss = 0.7888073325157166\n","Epoch: 1163, Training Loss = 0.7887572646141052\n","Epoch: 1164, Training Loss = 0.7887073755264282\n","Epoch: 1165, Training Loss = 0.7886574864387512\n","Epoch: 1166, Training Loss = 0.7886075973510742\n","Epoch: 1167, Training Loss = 0.7885576486587524\n","Epoch: 1168, Training Loss = 0.7885077595710754\n","Epoch: 1169, Training Loss = 0.7884579300880432\n","Epoch: 1170, Training Loss = 0.7884082794189453\n","Accuracy =  0.6534090638160706 F1 weighted =  0.6151522994041443 F1 macro =  0.42368918657302856\n","Epoch: 1171, Training Loss = 0.7883584499359131\n","Epoch: 1172, Training Loss = 0.78830885887146\n","Epoch: 1173, Training Loss = 0.7882591485977173\n","Epoch: 1174, Training Loss = 0.7882095575332642\n","Epoch: 1175, Training Loss = 0.7881600260734558\n","Epoch: 1176, Training Loss = 0.7881104946136475\n","Epoch: 1177, Training Loss = 0.7880610227584839\n","Epoch: 1178, Training Loss = 0.7880116105079651\n","Epoch: 1179, Training Loss = 0.7879621386528015\n","Epoch: 1180, Training Loss = 0.787912905216217\n","Accuracy =  0.6531448364257812 F1 weighted =  0.6149740219116211 F1 macro =  0.4234691560268402\n","Epoch: 1181, Training Loss = 0.787863552570343\n","Epoch: 1182, Training Loss = 0.7878142595291138\n","Epoch: 1183, Training Loss = 0.7877649664878845\n","Epoch: 1184, Training Loss = 0.7877158522605896\n","Epoch: 1185, Training Loss = 0.7876666188240051\n","Epoch: 1186, Training Loss = 0.7876175045967102\n","Epoch: 1187, Training Loss = 0.7875683903694153\n","Epoch: 1188, Training Loss = 0.7875192761421204\n","Epoch: 1189, Training Loss = 0.7874703407287598\n","Epoch: 1190, Training Loss = 0.7874214053153992\n","Accuracy =  0.6530787348747253 F1 weighted =  0.6150020360946655 F1 macro =  0.423594206571579\n","Epoch: 1191, Training Loss = 0.787372350692749\n","Epoch: 1192, Training Loss = 0.787323534488678\n","Epoch: 1193, Training Loss = 0.7872746586799622\n","Epoch: 1194, Training Loss = 0.7872258424758911\n","Epoch: 1195, Training Loss = 0.7871770262718201\n","Epoch: 1196, Training Loss = 0.7871283888816833\n","Epoch: 1197, Training Loss = 0.7870796322822571\n","Epoch: 1198, Training Loss = 0.7870309948921204\n","Epoch: 1199, Training Loss = 0.7869822978973389\n","Epoch: 1200, Training Loss = 0.7869337201118469\n","Accuracy =  0.6532108783721924 F1 weighted =  0.6153369545936584 F1 macro =  0.4240586757659912\n","Epoch: 1201, Training Loss = 0.786885142326355\n","Epoch: 1202, Training Loss = 0.7868366241455078\n","Epoch: 1203, Training Loss = 0.7867882251739502\n","Epoch: 1204, Training Loss = 0.7867397665977478\n","Epoch: 1205, Training Loss = 0.7866913676261902\n","Epoch: 1206, Training Loss = 0.7866430282592773\n","Epoch: 1207, Training Loss = 0.7865947484970093\n","Epoch: 1208, Training Loss = 0.7865464091300964\n","Epoch: 1209, Training Loss = 0.7864981293678284\n","Epoch: 1210, Training Loss = 0.7864499092102051\n","Accuracy =  0.6533430218696594 F1 weighted =  0.6156042814254761 F1 macro =  0.4242938160896301\n","Epoch: 1211, Training Loss = 0.7864017486572266\n","Epoch: 1212, Training Loss = 0.786353588104248\n","Epoch: 1213, Training Loss = 0.7863054871559143\n","Epoch: 1214, Training Loss = 0.7862574458122253\n","Epoch: 1215, Training Loss = 0.7862094640731812\n","Epoch: 1216, Training Loss = 0.786161482334137\n","Epoch: 1217, Training Loss = 0.7861135005950928\n","Epoch: 1218, Training Loss = 0.7860655784606934\n","Epoch: 1219, Training Loss = 0.7860177755355835\n","Epoch: 1220, Training Loss = 0.7859699130058289\n","Accuracy =  0.6536073088645935 F1 weighted =  0.6160019040107727 F1 macro =  0.42567893862724304\n","Epoch: 1221, Training Loss = 0.7859220504760742\n","Epoch: 1222, Training Loss = 0.7858743071556091\n","Epoch: 1223, Training Loss = 0.7858266234397888\n","Epoch: 1224, Training Loss = 0.7857788801193237\n","Epoch: 1225, Training Loss = 0.7857312560081482\n","Epoch: 1226, Training Loss = 0.7856836318969727\n","Epoch: 1227, Training Loss = 0.7856360077857971\n","Epoch: 1228, Training Loss = 0.7855886220932007\n","Epoch: 1229, Training Loss = 0.7855410575866699\n","Epoch: 1230, Training Loss = 0.7854935526847839\n","Accuracy =  0.6534090638160706 F1 weighted =  0.6159391403198242 F1 macro =  0.42571017146110535\n","Epoch: 1231, Training Loss = 0.7854461073875427\n","Epoch: 1232, Training Loss = 0.7853986620903015\n","Epoch: 1233, Training Loss = 0.7853513360023499\n","Epoch: 1234, Training Loss = 0.7853041291236877\n","Epoch: 1235, Training Loss = 0.7852567434310913\n","Epoch: 1236, Training Loss = 0.7852094173431396\n","Epoch: 1237, Training Loss = 0.7851623296737671\n","Epoch: 1238, Training Loss = 0.7851150035858154\n","Epoch: 1239, Training Loss = 0.7850679159164429\n","Epoch: 1240, Training Loss = 0.7850208878517151\n","Accuracy =  0.6534751653671265 F1 weighted =  0.6159905791282654 F1 macro =  0.42576077580451965\n","Epoch: 1241, Training Loss = 0.784973680973053\n","Epoch: 1242, Training Loss = 0.7849266529083252\n","Epoch: 1243, Training Loss = 0.7848796844482422\n","Epoch: 1244, Training Loss = 0.7848327159881592\n","Epoch: 1245, Training Loss = 0.784785807132721\n","Epoch: 1246, Training Loss = 0.7847388982772827\n","Epoch: 1247, Training Loss = 0.7846920490264893\n","Epoch: 1248, Training Loss = 0.7846453189849854\n","Epoch: 1249, Training Loss = 0.7845984697341919\n","Epoch: 1250, Training Loss = 0.784551739692688\n","Accuracy =  0.6538715362548828 F1 weighted =  0.6164160966873169 F1 macro =  0.42607608437538147\n","Epoch: 1251, Training Loss = 0.7845050692558289\n","Epoch: 1252, Training Loss = 0.784458339214325\n","Epoch: 1253, Training Loss = 0.7844117283821106\n","Epoch: 1254, Training Loss = 0.7843651175498962\n","Epoch: 1255, Training Loss = 0.7843185067176819\n","Epoch: 1256, Training Loss = 0.7842718958854675\n","Epoch: 1257, Training Loss = 0.7842254638671875\n","Epoch: 1258, Training Loss = 0.7841789722442627\n","Epoch: 1259, Training Loss = 0.7841325402259827\n","Epoch: 1260, Training Loss = 0.7840861678123474\n","Accuracy =  0.6539376378059387 F1 weighted =  0.6164984107017517 F1 macro =  0.42603376507759094\n","Epoch: 1261, Training Loss = 0.7840397953987122\n","Epoch: 1262, Training Loss = 0.7839934229850769\n","Epoch: 1263, Training Loss = 0.7839471101760864\n","Epoch: 1264, Training Loss = 0.7839008569717407\n","Epoch: 1265, Training Loss = 0.783854603767395\n","Epoch: 1266, Training Loss = 0.7838084697723389\n","Epoch: 1267, Training Loss = 0.7837623953819275\n","Epoch: 1268, Training Loss = 0.7837161421775818\n","Epoch: 1269, Training Loss = 0.7836701273918152\n","Epoch: 1270, Training Loss = 0.783623993396759\n","Accuracy =  0.654400110244751 F1 weighted =  0.6172382831573486 F1 macro =  0.42905139923095703\n","Epoch: 1271, Training Loss = 0.7835779786109924\n","Epoch: 1272, Training Loss = 0.7835320234298706\n","Epoch: 1273, Training Loss = 0.7834860682487488\n","Epoch: 1274, Training Loss = 0.7834401726722717\n","Epoch: 1275, Training Loss = 0.7833942770957947\n","Epoch: 1276, Training Loss = 0.7833484411239624\n","Epoch: 1277, Training Loss = 0.7833026051521301\n","Epoch: 1278, Training Loss = 0.7832568287849426\n","Epoch: 1279, Training Loss = 0.7832110524177551\n","Epoch: 1280, Training Loss = 0.7831653356552124\n","Accuracy =  0.6545982956886292 F1 weighted =  0.61752849817276 F1 macro =  0.429341584444046\n","Epoch: 1281, Training Loss = 0.7831197381019592\n","Epoch: 1282, Training Loss = 0.7830739617347717\n","Epoch: 1283, Training Loss = 0.7830284237861633\n","Epoch: 1284, Training Loss = 0.7829829454421997\n","Epoch: 1285, Training Loss = 0.7829374074935913\n","Epoch: 1286, Training Loss = 0.7828918695449829\n","Epoch: 1287, Training Loss = 0.7828462719917297\n","Epoch: 1288, Training Loss = 0.7828009724617004\n","Epoch: 1289, Training Loss = 0.7827555537223816\n","Epoch: 1290, Training Loss = 0.7827101349830627\n","Accuracy =  0.6547304391860962 F1 weighted =  0.6177821755409241 F1 macro =  0.430603951215744\n","Epoch: 1291, Training Loss = 0.7826647758483887\n","Epoch: 1292, Training Loss = 0.7826195359230042\n","Epoch: 1293, Training Loss = 0.7825741767883301\n","Epoch: 1294, Training Loss = 0.7825289368629456\n","Epoch: 1295, Training Loss = 0.7824838161468506\n","Epoch: 1296, Training Loss = 0.7824386358261108\n","Epoch: 1297, Training Loss = 0.7823934555053711\n","Epoch: 1298, Training Loss = 0.7823483347892761\n","Epoch: 1299, Training Loss = 0.7823032140731812\n","Epoch: 1300, Training Loss = 0.7822582721710205\n","Accuracy =  0.6547304391860962 F1 weighted =  0.6179576516151428 F1 macro =  0.43065983057022095\n","Epoch: 1301, Training Loss = 0.7822132706642151\n","Epoch: 1302, Training Loss = 0.7821683287620544\n","Epoch: 1303, Training Loss = 0.782123327255249\n","Epoch: 1304, Training Loss = 0.7820784449577332\n","Epoch: 1305, Training Loss = 0.7820335030555725\n","Epoch: 1306, Training Loss = 0.7819886803627014\n","Epoch: 1307, Training Loss = 0.7819438576698303\n","Epoch: 1308, Training Loss = 0.7818990349769592\n","Epoch: 1309, Training Loss = 0.7818543314933777\n","Epoch: 1310, Training Loss = 0.7818095684051514\n","Accuracy =  0.6549947261810303 F1 weighted =  0.6183574199676514 F1 macro =  0.43106698989868164\n","Epoch: 1311, Training Loss = 0.7817649245262146\n","Epoch: 1312, Training Loss = 0.7817203402519226\n","Epoch: 1313, Training Loss = 0.7816757559776306\n","Epoch: 1314, Training Loss = 0.7816310524940491\n","Epoch: 1315, Training Loss = 0.7815864682197571\n","Epoch: 1316, Training Loss = 0.7815420627593994\n","Epoch: 1317, Training Loss = 0.781497597694397\n","Epoch: 1318, Training Loss = 0.781453013420105\n","Epoch: 1319, Training Loss = 0.7814086675643921\n","Epoch: 1320, Training Loss = 0.7813643217086792\n","Accuracy =  0.6549286246299744 F1 weighted =  0.6183574199676514 F1 macro =  0.4310484230518341\n","Epoch: 1321, Training Loss = 0.7813199162483215\n","Epoch: 1322, Training Loss = 0.7812756896018982\n","Epoch: 1323, Training Loss = 0.7812314033508301\n","Epoch: 1324, Training Loss = 0.7811870574951172\n","Epoch: 1325, Training Loss = 0.7811428308486938\n","Epoch: 1326, Training Loss = 0.7810986042022705\n","Epoch: 1327, Training Loss = 0.7810544967651367\n","Epoch: 1328, Training Loss = 0.7810102701187134\n","Epoch: 1329, Training Loss = 0.7809662222862244\n","Epoch: 1330, Training Loss = 0.7809222340583801\n","Accuracy =  0.6549947261810303 F1 weighted =  0.6185311079025269 F1 macro =  0.43124884366989136\n","Epoch: 1331, Training Loss = 0.7808781266212463\n","Epoch: 1332, Training Loss = 0.7808341383934021\n","Epoch: 1333, Training Loss = 0.7807902097702026\n","Epoch: 1334, Training Loss = 0.7807462215423584\n","Epoch: 1335, Training Loss = 0.7807023525238037\n","Epoch: 1336, Training Loss = 0.7806584239006042\n","Epoch: 1337, Training Loss = 0.7806145548820496\n","Epoch: 1338, Training Loss = 0.7805707454681396\n","Epoch: 1339, Training Loss = 0.7805269956588745\n","Epoch: 1340, Training Loss = 0.7804831266403198\n","Accuracy =  0.6551268696784973 F1 weighted =  0.6187624335289001 F1 macro =  0.43149328231811523\n","Epoch: 1341, Training Loss = 0.780439555644989\n","Epoch: 1342, Training Loss = 0.7803958058357239\n","Epoch: 1343, Training Loss = 0.7803521156311035\n","Epoch: 1344, Training Loss = 0.7803086042404175\n","Epoch: 1345, Training Loss = 0.7802649140357971\n","Epoch: 1346, Training Loss = 0.7802212834358215\n","Epoch: 1347, Training Loss = 0.780177891254425\n","Epoch: 1348, Training Loss = 0.7801343202590942\n","Epoch: 1349, Training Loss = 0.7800908088684082\n","Epoch: 1350, Training Loss = 0.7800473570823669\n","Accuracy =  0.6551929116249084 F1 weighted =  0.6188911199569702 F1 macro =  0.43180033564567566\n","Epoch: 1351, Training Loss = 0.7800039052963257\n","Epoch: 1352, Training Loss = 0.7799606919288635\n","Epoch: 1353, Training Loss = 0.779917299747467\n","Epoch: 1354, Training Loss = 0.7798739075660706\n","Epoch: 1355, Training Loss = 0.7798306345939636\n","Epoch: 1356, Training Loss = 0.7797874808311462\n","Epoch: 1357, Training Loss = 0.7797442078590393\n","Epoch: 1358, Training Loss = 0.7797009944915771\n","Epoch: 1359, Training Loss = 0.779657781124115\n","Epoch: 1360, Training Loss = 0.7796146869659424\n","Accuracy =  0.6549947261810303 F1 weighted =  0.6187368035316467 F1 macro =  0.4317936301231384\n","Epoch: 1361, Training Loss = 0.7795715928077698\n","Epoch: 1362, Training Loss = 0.7795284986495972\n","Epoch: 1363, Training Loss = 0.7794854640960693\n","Epoch: 1364, Training Loss = 0.7794424295425415\n","Epoch: 1365, Training Loss = 0.7793994545936584\n","Epoch: 1366, Training Loss = 0.7793564796447754\n","Epoch: 1367, Training Loss = 0.7793135046958923\n","Epoch: 1368, Training Loss = 0.7792707085609436\n","Epoch: 1369, Training Loss = 0.7792277932167053\n","Epoch: 1370, Training Loss = 0.7791849970817566\n","Accuracy =  0.6551929116249084 F1 weighted =  0.6190588474273682 F1 macro =  0.431984543800354\n","Epoch: 1371, Training Loss = 0.7791421413421631\n","Epoch: 1372, Training Loss = 0.7790994048118591\n","Epoch: 1373, Training Loss = 0.7790566086769104\n","Epoch: 1374, Training Loss = 0.779013991355896\n","Epoch: 1375, Training Loss = 0.7789713144302368\n","Epoch: 1376, Training Loss = 0.7789286971092224\n","Epoch: 1377, Training Loss = 0.7788859605789185\n","Epoch: 1378, Training Loss = 0.7788434028625488\n","Epoch: 1379, Training Loss = 0.7788008451461792\n","Epoch: 1380, Training Loss = 0.7787583470344543\n","Accuracy =  0.6551929116249084 F1 weighted =  0.6191366910934448 F1 macro =  0.4321146309375763\n","Epoch: 1381, Training Loss = 0.7787158489227295\n","Epoch: 1382, Training Loss = 0.7786734104156494\n","Epoch: 1383, Training Loss = 0.7786308526992798\n","Epoch: 1384, Training Loss = 0.7785885334014893\n","Epoch: 1385, Training Loss = 0.7785460948944092\n","Epoch: 1386, Training Loss = 0.7785037159919739\n","Epoch: 1387, Training Loss = 0.7784613966941833\n","Epoch: 1388, Training Loss = 0.7784191966056824\n","Epoch: 1389, Training Loss = 0.7783767580986023\n","Epoch: 1390, Training Loss = 0.7783344984054565\n","Accuracy =  0.6551929116249084 F1 weighted =  0.6191688776016235 F1 macro =  0.4321651756763458\n","Epoch: 1391, Training Loss = 0.7782922983169556\n","Epoch: 1392, Training Loss = 0.7782502770423889\n","Epoch: 1393, Training Loss = 0.7782080769538879\n","Epoch: 1394, Training Loss = 0.7781659364700317\n","Epoch: 1395, Training Loss = 0.7781237959861755\n","Epoch: 1396, Training Loss = 0.7780817747116089\n","Epoch: 1397, Training Loss = 0.778039813041687\n","Epoch: 1398, Training Loss = 0.7779977321624756\n","Epoch: 1399, Training Loss = 0.7779557704925537\n","Epoch: 1400, Training Loss = 0.7779138684272766\n","Accuracy =  0.6551268696784973 F1 weighted =  0.6191549897193909 F1 macro =  0.4322008192539215\n","Epoch: 1401, Training Loss = 0.7778719663619995\n","Epoch: 1402, Training Loss = 0.7778300642967224\n","Epoch: 1403, Training Loss = 0.7777881622314453\n","Epoch: 1404, Training Loss = 0.7777463793754578\n","Epoch: 1405, Training Loss = 0.7777044773101807\n","Epoch: 1406, Training Loss = 0.7776627540588379\n","Epoch: 1407, Training Loss = 0.7776209712028503\n","Epoch: 1408, Training Loss = 0.7775793671607971\n","Epoch: 1409, Training Loss = 0.7775375843048096\n","Epoch: 1410, Training Loss = 0.7774960398674011\n","Accuracy =  0.6551268696784973 F1 weighted =  0.6192312836647034 F1 macro =  0.4324355125427246\n","Epoch: 1411, Training Loss = 0.7774543166160583\n","Epoch: 1412, Training Loss = 0.7774127125740051\n","Epoch: 1413, Training Loss = 0.7773712277412415\n","Epoch: 1414, Training Loss = 0.7773295640945435\n","Epoch: 1415, Training Loss = 0.7772880792617798\n","Epoch: 1416, Training Loss = 0.7772466540336609\n","Epoch: 1417, Training Loss = 0.7772051692008972\n","Epoch: 1418, Training Loss = 0.7771636843681335\n","Epoch: 1419, Training Loss = 0.7771223187446594\n","Epoch: 1420, Training Loss = 0.7770808935165405\n","Accuracy =  0.6552590131759644 F1 weighted =  0.6195262670516968 F1 macro =  0.4327165484428406\n","Epoch: 1421, Training Loss = 0.777039647102356\n","Epoch: 1422, Training Loss = 0.7769981622695923\n","Epoch: 1423, Training Loss = 0.7769569754600525\n","Epoch: 1424, Training Loss = 0.7769157886505127\n","Epoch: 1425, Training Loss = 0.7768744826316833\n","Epoch: 1426, Training Loss = 0.7768333554267883\n","Epoch: 1427, Training Loss = 0.7767921090126038\n","Epoch: 1428, Training Loss = 0.7767508625984192\n","Epoch: 1429, Training Loss = 0.7767098546028137\n","Epoch: 1430, Training Loss = 0.7766687870025635\n","Accuracy =  0.6553910970687866 F1 weighted =  0.6198205351829529 F1 macro =  0.4330804646015167\n","Epoch: 1431, Training Loss = 0.7766276001930237\n","Epoch: 1432, Training Loss = 0.776586651802063\n","Epoch: 1433, Training Loss = 0.7765456438064575\n","Epoch: 1434, Training Loss = 0.776504635810852\n","Epoch: 1435, Training Loss = 0.7764638066291809\n","Epoch: 1436, Training Loss = 0.7764227986335754\n","Epoch: 1437, Training Loss = 0.7763819098472595\n","Epoch: 1438, Training Loss = 0.7763410210609436\n","Epoch: 1439, Training Loss = 0.7763001322746277\n","Epoch: 1440, Training Loss = 0.7762593626976013\n","Accuracy =  0.6555232405662537 F1 weighted =  0.6200506091117859 F1 macro =  0.4332599341869354\n","Epoch: 1441, Training Loss = 0.776218593120575\n","Epoch: 1442, Training Loss = 0.7761778235435486\n","Epoch: 1443, Training Loss = 0.7761369943618774\n","Epoch: 1444, Training Loss = 0.7760963439941406\n","Epoch: 1445, Training Loss = 0.776055634021759\n","Epoch: 1446, Training Loss = 0.776015043258667\n","Epoch: 1447, Training Loss = 0.7759743928909302\n","Epoch: 1448, Training Loss = 0.7759338021278381\n","Epoch: 1449, Training Loss = 0.7758932709693909\n","Epoch: 1450, Training Loss = 0.775852620601654\n","Accuracy =  0.6554571986198425 F1 weighted =  0.6200814247131348 F1 macro =  0.43337389826774597\n","Epoch: 1451, Training Loss = 0.7758120894432068\n","Epoch: 1452, Training Loss = 0.7757717967033386\n","Epoch: 1453, Training Loss = 0.7757312655448914\n","Epoch: 1454, Training Loss = 0.7756907939910889\n","Epoch: 1455, Training Loss = 0.7756503820419312\n","Epoch: 1456, Training Loss = 0.775610089302063\n","Epoch: 1457, Training Loss = 0.7755696177482605\n","Epoch: 1458, Training Loss = 0.7755293846130371\n","Epoch: 1459, Training Loss = 0.775489091873169\n","Epoch: 1460, Training Loss = 0.7754487991333008\n","Accuracy =  0.6555232405662537 F1 weighted =  0.6202786564826965 F1 macro =  0.43366891145706177\n","Epoch: 1461, Training Loss = 0.7754085659980774\n","Epoch: 1462, Training Loss = 0.775368332862854\n","Epoch: 1463, Training Loss = 0.7753281593322754\n","Epoch: 1464, Training Loss = 0.775287926197052\n","Epoch: 1465, Training Loss = 0.7752478122711182\n","Epoch: 1466, Training Loss = 0.7752076983451843\n","Epoch: 1467, Training Loss = 0.7751675844192505\n","Epoch: 1468, Training Loss = 0.7751275300979614\n","Epoch: 1469, Training Loss = 0.7750875949859619\n","Epoch: 1470, Training Loss = 0.7750476002693176\n","Accuracy =  0.6559196710586548 F1 weighted =  0.6208177804946899 F1 macro =  0.43520623445510864\n","Epoch: 1471, Training Loss = 0.7750075459480286\n","Epoch: 1472, Training Loss = 0.774967610836029\n","Epoch: 1473, Training Loss = 0.7749276757240295\n","Epoch: 1474, Training Loss = 0.77488774061203\n","Epoch: 1475, Training Loss = 0.7748479843139648\n","Epoch: 1476, Training Loss = 0.7748079895973206\n","Epoch: 1477, Training Loss = 0.7747682332992554\n","Epoch: 1478, Training Loss = 0.774728536605835\n","Epoch: 1479, Training Loss = 0.774688720703125\n","Epoch: 1480, Training Loss = 0.7746490240097046\n","Accuracy =  0.6557214856147766 F1 weighted =  0.6206439733505249 F1 macro =  0.43494510650634766\n","Epoch: 1481, Training Loss = 0.7746091485023499\n","Epoch: 1482, Training Loss = 0.774569571018219\n","Epoch: 1483, Training Loss = 0.7745299339294434\n","Epoch: 1484, Training Loss = 0.774490237236023\n","Epoch: 1485, Training Loss = 0.7744506597518921\n","Epoch: 1486, Training Loss = 0.7744110822677612\n","Epoch: 1487, Training Loss = 0.7743715047836304\n","Epoch: 1488, Training Loss = 0.7743319869041443\n","Epoch: 1489, Training Loss = 0.774292528629303\n","Epoch: 1490, Training Loss = 0.7742529511451721\n","Accuracy =  0.6559857130050659 F1 weighted =  0.6210013628005981 F1 macro =  0.4352197051048279\n","Epoch: 1491, Training Loss = 0.7742135524749756\n","Epoch: 1492, Training Loss = 0.7741740942001343\n","Epoch: 1493, Training Loss = 0.7741346955299377\n","Epoch: 1494, Training Loss = 0.7740952968597412\n","Epoch: 1495, Training Loss = 0.7740559577941895\n","Epoch: 1496, Training Loss = 0.7740166783332825\n","Epoch: 1497, Training Loss = 0.7739773392677307\n","Epoch: 1498, Training Loss = 0.7739381194114685\n","Epoch: 1499, Training Loss = 0.7738988399505615\n","Epoch: 1500, Training Loss = 0.7738596796989441\n","Accuracy =  0.6561839580535889 F1 weighted =  0.6212695837020874 F1 macro =  0.43552443385124207\n","Epoch: 1501, Training Loss = 0.7738204598426819\n","Epoch: 1502, Training Loss = 0.7737812995910645\n","Epoch: 1503, Training Loss = 0.7737420797348022\n","Epoch: 1504, Training Loss = 0.7737029790878296\n","Epoch: 1505, Training Loss = 0.7736639380455017\n","Epoch: 1506, Training Loss = 0.773624837398529\n","Epoch: 1507, Training Loss = 0.7735857963562012\n","Epoch: 1508, Training Loss = 0.7735468149185181\n","Epoch: 1509, Training Loss = 0.773507833480835\n","Epoch: 1510, Training Loss = 0.7734687924385071\n","Accuracy =  0.6561839580535889 F1 weighted =  0.6213762760162354 F1 macro =  0.4357236623764038\n","Epoch: 1511, Training Loss = 0.773429811000824\n","Epoch: 1512, Training Loss = 0.7733909487724304\n","Epoch: 1513, Training Loss = 0.7733520865440369\n","Epoch: 1514, Training Loss = 0.7733131647109985\n","Epoch: 1515, Training Loss = 0.7732744216918945\n","Epoch: 1516, Training Loss = 0.773235559463501\n","Epoch: 1517, Training Loss = 0.7731967568397522\n","Epoch: 1518, Training Loss = 0.7731580138206482\n","Epoch: 1519, Training Loss = 0.7731192708015442\n","Epoch: 1520, Training Loss = 0.773080587387085\n","Accuracy =  0.6559857130050659 F1 weighted =  0.6212276816368103 F1 macro =  0.43562644720077515\n","Epoch: 1521, Training Loss = 0.7730419039726257\n","Epoch: 1522, Training Loss = 0.7730032205581665\n","Epoch: 1523, Training Loss = 0.772964596748352\n","Epoch: 1524, Training Loss = 0.7729259729385376\n","Epoch: 1525, Training Loss = 0.7728873491287231\n","Epoch: 1526, Training Loss = 0.7728487849235535\n","Epoch: 1527, Training Loss = 0.7728102207183838\n","Epoch: 1528, Training Loss = 0.7727716565132141\n","Epoch: 1529, Training Loss = 0.7727332711219788\n","Epoch: 1530, Training Loss = 0.7726948261260986\n","Accuracy =  0.656117856502533 F1 weighted =  0.6214182376861572 F1 macro =  0.4357195496559143\n","Epoch: 1531, Training Loss = 0.7726563215255737\n","Epoch: 1532, Training Loss = 0.7726178765296936\n","Epoch: 1533, Training Loss = 0.7725794911384583\n","Epoch: 1534, Training Loss = 0.7725411653518677\n","Epoch: 1535, Training Loss = 0.7725028395652771\n","Epoch: 1536, Training Loss = 0.7724645137786865\n","Epoch: 1537, Training Loss = 0.772426187992096\n","Epoch: 1538, Training Loss = 0.7723879814147949\n","Epoch: 1539, Training Loss = 0.7723497748374939\n","Epoch: 1540, Training Loss = 0.7723115086555481\n","Accuracy =  0.65625 F1 weighted =  0.6216468811035156 F1 macro =  0.4357903003692627\n","Epoch: 1541, Training Loss = 0.7722733020782471\n","Epoch: 1542, Training Loss = 0.772235095500946\n","Epoch: 1543, Training Loss = 0.772196888923645\n","Epoch: 1544, Training Loss = 0.7721588611602783\n","Epoch: 1545, Training Loss = 0.7721207141876221\n","Epoch: 1546, Training Loss = 0.7720826864242554\n","Epoch: 1547, Training Loss = 0.7720445394515991\n","Epoch: 1548, Training Loss = 0.7720065712928772\n","Epoch: 1549, Training Loss = 0.7719685435295105\n","Epoch: 1550, Training Loss = 0.7719306349754333\n","Accuracy =  0.6561839580535889 F1 weighted =  0.6216768026351929 F1 macro =  0.43575429916381836\n","Epoch: 1551, Training Loss = 0.7718926072120667\n","Epoch: 1552, Training Loss = 0.7718546986579895\n","Epoch: 1553, Training Loss = 0.7718169093132019\n","Epoch: 1554, Training Loss = 0.77177894115448\n","Epoch: 1555, Training Loss = 0.7717410922050476\n","Epoch: 1556, Training Loss = 0.7717032432556152\n","Epoch: 1557, Training Loss = 0.7716655731201172\n","Epoch: 1558, Training Loss = 0.7716276049613953\n","Epoch: 1559, Training Loss = 0.7715899348258972\n","Epoch: 1560, Training Loss = 0.7715522646903992\n","Accuracy =  0.656117856502533 F1 weighted =  0.6217064261436462 F1 macro =  0.4359496831893921\n","Epoch: 1561, Training Loss = 0.7715145349502563\n","Epoch: 1562, Training Loss = 0.7714767456054688\n","Epoch: 1563, Training Loss = 0.7714390754699707\n","Epoch: 1564, Training Loss = 0.7714015245437622\n","Epoch: 1565, Training Loss = 0.7713639140129089\n","Epoch: 1566, Training Loss = 0.7713263034820557\n","Epoch: 1567, Training Loss = 0.7712886929512024\n","Epoch: 1568, Training Loss = 0.7712512016296387\n","Epoch: 1569, Training Loss = 0.7712136507034302\n","Epoch: 1570, Training Loss = 0.7711760997772217\n","Accuracy =  0.656117856502533 F1 weighted =  0.6217935085296631 F1 macro =  0.4360025227069855\n","Epoch: 1571, Training Loss = 0.7711386680603027\n","Epoch: 1572, Training Loss = 0.7711012959480286\n","Epoch: 1573, Training Loss = 0.7710638046264648\n","Epoch: 1574, Training Loss = 0.7710264325141907\n","Epoch: 1575, Training Loss = 0.7709890604019165\n","Epoch: 1576, Training Loss = 0.7709516882896423\n","Epoch: 1577, Training Loss = 0.7709142565727234\n","Epoch: 1578, Training Loss = 0.7708770632743835\n","Epoch: 1579, Training Loss = 0.7708397507667542\n","Epoch: 1580, Training Loss = 0.7708024382591248\n","Accuracy =  0.6563160419464111 F1 weighted =  0.6221786141395569 F1 macro =  0.4364078640937805\n","Epoch: 1581, Training Loss = 0.7707652449607849\n","Epoch: 1582, Training Loss = 0.7707280516624451\n","Epoch: 1583, Training Loss = 0.7706907391548157\n","Epoch: 1584, Training Loss = 0.7706536054611206\n","Epoch: 1585, Training Loss = 0.7706164717674255\n","Epoch: 1586, Training Loss = 0.7705793380737305\n","Epoch: 1587, Training Loss = 0.770542323589325\n","Epoch: 1588, Training Loss = 0.7705052495002747\n","Epoch: 1589, Training Loss = 0.7704681158065796\n","Epoch: 1590, Training Loss = 0.7704311013221741\n","Accuracy =  0.6563160419464111 F1 weighted =  0.6221844553947449 F1 macro =  0.43636006116867065\n","Epoch: 1591, Training Loss = 0.7703940272331238\n","Epoch: 1592, Training Loss = 0.770357072353363\n","Epoch: 1593, Training Loss = 0.7703201174736023\n","Epoch: 1594, Training Loss = 0.7702832221984863\n","Epoch: 1595, Training Loss = 0.7702463865280151\n","Epoch: 1596, Training Loss = 0.7702094316482544\n","Epoch: 1597, Training Loss = 0.7701725959777832\n","Epoch: 1598, Training Loss = 0.7701357007026672\n","Epoch: 1599, Training Loss = 0.770098865032196\n","Epoch: 1600, Training Loss = 0.7700621485710144\n","Accuracy =  0.6565142869949341 F1 weighted =  0.6224948763847351 F1 macro =  0.4366995394229889\n","Epoch: 1601, Training Loss = 0.770025372505188\n","Epoch: 1602, Training Loss = 0.7699885964393616\n","Epoch: 1603, Training Loss = 0.7699518203735352\n","Epoch: 1604, Training Loss = 0.7699151635169983\n","Epoch: 1605, Training Loss = 0.7698783874511719\n","Epoch: 1606, Training Loss = 0.769841730594635\n","Epoch: 1607, Training Loss = 0.7698050737380981\n","Epoch: 1608, Training Loss = 0.7697684168815613\n","Epoch: 1609, Training Loss = 0.7697319388389587\n","Epoch: 1610, Training Loss = 0.7696952819824219\n","Accuracy =  0.6566464304924011 F1 weighted =  0.622854471206665 F1 macro =  0.4381069540977478\n","Epoch: 1611, Training Loss = 0.7696587443351746\n","Epoch: 1612, Training Loss = 0.7696222066879272\n","Epoch: 1613, Training Loss = 0.7695857882499695\n","Epoch: 1614, Training Loss = 0.7695493102073669\n","Epoch: 1615, Training Loss = 0.7695127129554749\n","Epoch: 1616, Training Loss = 0.7694762945175171\n","Epoch: 1617, Training Loss = 0.7694399952888489\n","Epoch: 1618, Training Loss = 0.7694035768508911\n","Epoch: 1619, Training Loss = 0.7693671584129333\n","Epoch: 1620, Training Loss = 0.7693309187889099\n","Accuracy =  0.6565803289413452 F1 weighted =  0.6228461265563965 F1 macro =  0.4381752610206604\n","Epoch: 1621, Training Loss = 0.7692945003509521\n","Epoch: 1622, Training Loss = 0.7692582011222839\n","Epoch: 1623, Training Loss = 0.769221842288971\n","Epoch: 1624, Training Loss = 0.7691856622695923\n","Epoch: 1625, Training Loss = 0.7691494226455688\n","Epoch: 1626, Training Loss = 0.7691131830215454\n","Epoch: 1627, Training Loss = 0.7690770030021667\n","Epoch: 1628, Training Loss = 0.7690408825874329\n","Epoch: 1629, Training Loss = 0.7690046429634094\n","Epoch: 1630, Training Loss = 0.7689685225486755\n","Accuracy =  0.6567785143852234 F1 weighted =  0.6232742667198181 F1 macro =  0.43939363956451416\n","Epoch: 1631, Training Loss = 0.7689324617385864\n","Epoch: 1632, Training Loss = 0.7688963413238525\n","Epoch: 1633, Training Loss = 0.7688602805137634\n","Epoch: 1634, Training Loss = 0.7688242793083191\n","Epoch: 1635, Training Loss = 0.76878821849823\n","Epoch: 1636, Training Loss = 0.7687522768974304\n","Epoch: 1637, Training Loss = 0.7687162756919861\n","Epoch: 1638, Training Loss = 0.7686803340911865\n","Epoch: 1639, Training Loss = 0.7686443328857422\n","Epoch: 1640, Training Loss = 0.7686084508895874\n","Accuracy =  0.6569767594337463 F1 weighted =  0.6236267685890198 F1 macro =  0.4398304224014282\n","Epoch: 1641, Training Loss = 0.7685725688934326\n","Epoch: 1642, Training Loss = 0.7685367465019226\n","Epoch: 1643, Training Loss = 0.7685009241104126\n","Epoch: 1644, Training Loss = 0.7684651017189026\n","Epoch: 1645, Training Loss = 0.7684293389320374\n","Epoch: 1646, Training Loss = 0.7683935165405273\n","Epoch: 1647, Training Loss = 0.7683578133583069\n","Epoch: 1648, Training Loss = 0.7683220505714417\n","Epoch: 1649, Training Loss = 0.768286406993866\n","Epoch: 1650, Training Loss = 0.7682506442070007\n","Accuracy =  0.6571089029312134 F1 weighted =  0.6238427758216858 F1 macro =  0.4410467743873596\n","Epoch: 1651, Training Loss = 0.768215000629425\n","Epoch: 1652, Training Loss = 0.7681792974472046\n","Epoch: 1653, Training Loss = 0.7681437134742737\n","Epoch: 1654, Training Loss = 0.768108069896698\n","Epoch: 1655, Training Loss = 0.7680724263191223\n","Epoch: 1656, Training Loss = 0.768036961555481\n","Epoch: 1657, Training Loss = 0.76800137758255\n","Epoch: 1658, Training Loss = 0.7679658532142639\n","Epoch: 1659, Training Loss = 0.7679303884506226\n","Epoch: 1660, Training Loss = 0.767894983291626\n","Accuracy =  0.6571089029312134 F1 weighted =  0.6240138411521912 F1 macro =  0.44103682041168213\n","Epoch: 1661, Training Loss = 0.7678595185279846\n","Epoch: 1662, Training Loss = 0.7678240537643433\n","Epoch: 1663, Training Loss = 0.7677886486053467\n","Epoch: 1664, Training Loss = 0.7677532434463501\n","Epoch: 1665, Training Loss = 0.7677178978919983\n","Epoch: 1666, Training Loss = 0.7676826119422913\n","Epoch: 1667, Training Loss = 0.7676472663879395\n","Epoch: 1668, Training Loss = 0.7676119804382324\n","Epoch: 1669, Training Loss = 0.7675766348838806\n","Epoch: 1670, Training Loss = 0.7675413489341736\n","Accuracy =  0.6573070883750916 F1 weighted =  0.6242184042930603 F1 macro =  0.44106635451316833\n","Epoch: 1671, Training Loss = 0.7675061225891113\n","Epoch: 1672, Training Loss = 0.7674709558486938\n","Epoch: 1673, Training Loss = 0.7674357295036316\n","Epoch: 1674, Training Loss = 0.7674005031585693\n","Epoch: 1675, Training Loss = 0.7673654556274414\n","Epoch: 1676, Training Loss = 0.7673302292823792\n","Epoch: 1677, Training Loss = 0.7672951221466064\n","Epoch: 1678, Training Loss = 0.7672600150108337\n","Epoch: 1679, Training Loss = 0.7672249674797058\n","Epoch: 1680, Training Loss = 0.7671898603439331\n","Accuracy =  0.6574392318725586 F1 weighted =  0.6244640946388245 F1 macro =  0.4423627257347107\n","Epoch: 1681, Training Loss = 0.7671549320220947\n","Epoch: 1682, Training Loss = 0.767119824886322\n","Epoch: 1683, Training Loss = 0.7670848965644836\n","Epoch: 1684, Training Loss = 0.7670499086380005\n","Epoch: 1685, Training Loss = 0.7670149803161621\n","Epoch: 1686, Training Loss = 0.7669800519943237\n","Epoch: 1687, Training Loss = 0.7669451832771301\n","Epoch: 1688, Training Loss = 0.7669102549552917\n","Epoch: 1689, Training Loss = 0.7668753266334534\n","Epoch: 1690, Training Loss = 0.7668405175209045\n","Accuracy =  0.6575713753700256 F1 weighted =  0.624751091003418 F1 macro =  0.4428005516529083\n","Epoch: 1691, Training Loss = 0.7668057680130005\n","Epoch: 1692, Training Loss = 0.7667708396911621\n","Epoch: 1693, Training Loss = 0.7667360901832581\n","Epoch: 1694, Training Loss = 0.7667014002799988\n","Epoch: 1695, Training Loss = 0.7666666507720947\n","Epoch: 1696, Training Loss = 0.7666319012641907\n","Epoch: 1697, Training Loss = 0.7665972113609314\n","Epoch: 1698, Training Loss = 0.7665625214576721\n","Epoch: 1699, Training Loss = 0.7665278911590576\n","Epoch: 1700, Training Loss = 0.7664933204650879\n","Accuracy =  0.6577695608139038 F1 weighted =  0.6250165104866028 F1 macro =  0.44310128688812256\n","Epoch: 1701, Training Loss = 0.7664587497711182\n","Epoch: 1702, Training Loss = 0.7664241194725037\n","Epoch: 1703, Training Loss = 0.7663894891738892\n","Epoch: 1704, Training Loss = 0.7663548588752747\n","Epoch: 1705, Training Loss = 0.7663203477859497\n","Epoch: 1706, Training Loss = 0.7662858963012695\n","Epoch: 1707, Training Loss = 0.7662513256072998\n","Epoch: 1708, Training Loss = 0.7662168741226196\n","Epoch: 1709, Training Loss = 0.766182541847229\n","Epoch: 1710, Training Loss = 0.766148030757904\n","Accuracy =  0.6574392318725586 F1 weighted =  0.6248356103897095 F1 macro =  0.44297462701797485\n","Epoch: 1711, Training Loss = 0.7661135792732239\n","Epoch: 1712, Training Loss = 0.7660791277885437\n","Epoch: 1713, Training Loss = 0.7660447955131531\n","Epoch: 1714, Training Loss = 0.7660104632377625\n","Epoch: 1715, Training Loss = 0.7659761905670166\n","Epoch: 1716, Training Loss = 0.765941858291626\n","Epoch: 1717, Training Loss = 0.7659075260162354\n","Epoch: 1718, Training Loss = 0.7658732533454895\n","Epoch: 1719, Training Loss = 0.7658389806747437\n","Epoch: 1720, Training Loss = 0.7658047676086426\n","Accuracy =  0.6573070883750916 F1 weighted =  0.6246950030326843 F1 macro =  0.4427889585494995\n","Epoch: 1721, Training Loss = 0.7657706141471863\n","Epoch: 1722, Training Loss = 0.76573646068573\n","Epoch: 1723, Training Loss = 0.7657023072242737\n","Epoch: 1724, Training Loss = 0.7656681537628174\n","Epoch: 1725, Training Loss = 0.7656339406967163\n","Epoch: 1726, Training Loss = 0.7655997276306152\n","Epoch: 1727, Training Loss = 0.7655657529830933\n","Epoch: 1728, Training Loss = 0.7655317783355713\n","Epoch: 1729, Training Loss = 0.765497624874115\n","Epoch: 1730, Training Loss = 0.7654635906219482\n","Accuracy =  0.6576374173164368 F1 weighted =  0.6252397298812866 F1 macro =  0.4442746639251709\n","Epoch: 1731, Training Loss = 0.7654295563697815\n","Epoch: 1732, Training Loss = 0.7653956413269043\n","Epoch: 1733, Training Loss = 0.7653616070747375\n","Epoch: 1734, Training Loss = 0.7653276920318604\n","Epoch: 1735, Training Loss = 0.7652937769889832\n","Epoch: 1736, Training Loss = 0.765259861946106\n","Epoch: 1737, Training Loss = 0.7652259469032288\n","Epoch: 1738, Training Loss = 0.7651920318603516\n","Epoch: 1739, Training Loss = 0.7651582360267639\n","Epoch: 1740, Training Loss = 0.7651243805885315\n","Accuracy =  0.6580338478088379 F1 weighted =  0.6258423328399658 F1 macro =  0.44588181376457214\n","Epoch: 1741, Training Loss = 0.7650905847549438\n","Epoch: 1742, Training Loss = 0.7650567889213562\n","Epoch: 1743, Training Loss = 0.7650229930877686\n","Epoch: 1744, Training Loss = 0.7649892568588257\n","Epoch: 1745, Training Loss = 0.7649555802345276\n","Epoch: 1746, Training Loss = 0.7649218440055847\n","Epoch: 1747, Training Loss = 0.7648881673812866\n","Epoch: 1748, Training Loss = 0.764854371547699\n","Epoch: 1749, Training Loss = 0.7648208141326904\n","Epoch: 1750, Training Loss = 0.7647870779037476\n","Accuracy =  0.658099889755249 F1 weighted =  0.6259667277336121 F1 macro =  0.4460371434688568\n","Epoch: 1751, Training Loss = 0.7647535800933838\n","Epoch: 1752, Training Loss = 0.7647199630737305\n","Epoch: 1753, Training Loss = 0.7646863460540771\n","Epoch: 1754, Training Loss = 0.7646528482437134\n","Epoch: 1755, Training Loss = 0.7646192908287048\n","Epoch: 1756, Training Loss = 0.7645858526229858\n","Epoch: 1757, Training Loss = 0.7645522356033325\n","Epoch: 1758, Training Loss = 0.7645187377929688\n","Epoch: 1759, Training Loss = 0.7644852995872498\n","Epoch: 1760, Training Loss = 0.764451801776886\n","Accuracy =  0.6582320332527161 F1 weighted =  0.6261488795280457 F1 macro =  0.4461546540260315\n","Epoch: 1761, Training Loss = 0.7644184231758118\n","Epoch: 1762, Training Loss = 0.7643849849700928\n","Epoch: 1763, Training Loss = 0.7643516659736633\n","Epoch: 1764, Training Loss = 0.7643182873725891\n","Epoch: 1765, Training Loss = 0.7642849087715149\n","Epoch: 1766, Training Loss = 0.7642516493797302\n","Epoch: 1767, Training Loss = 0.764218270778656\n","Epoch: 1768, Training Loss = 0.7641849517822266\n","Epoch: 1769, Training Loss = 0.7641516923904419\n","Epoch: 1770, Training Loss = 0.7641184329986572\n","Accuracy =  0.6581659913063049 F1 weighted =  0.6261512637138367 F1 macro =  0.4460844397544861\n","Epoch: 1771, Training Loss = 0.7640853524208069\n","Epoch: 1772, Training Loss = 0.7640520334243774\n","Epoch: 1773, Training Loss = 0.7640187740325928\n","Epoch: 1774, Training Loss = 0.7639857530593872\n","Epoch: 1775, Training Loss = 0.7639524936676025\n","Epoch: 1776, Training Loss = 0.7639194130897522\n","Epoch: 1777, Training Loss = 0.7638862133026123\n","Epoch: 1778, Training Loss = 0.7638532519340515\n","Epoch: 1779, Training Loss = 0.7638200521469116\n","Epoch: 1780, Training Loss = 0.7637869715690613\n","Accuracy =  0.6584963202476501 F1 weighted =  0.6266516447067261 F1 macro =  0.4475845694541931\n","Epoch: 1781, Training Loss = 0.7637538909912109\n","Epoch: 1782, Training Loss = 0.7637209296226501\n","Epoch: 1783, Training Loss = 0.7636879086494446\n","Epoch: 1784, Training Loss = 0.763654887676239\n","Epoch: 1785, Training Loss = 0.7636219263076782\n","Epoch: 1786, Training Loss = 0.7635890245437622\n","Epoch: 1787, Training Loss = 0.7635561227798462\n","Epoch: 1788, Training Loss = 0.7635231614112854\n","Epoch: 1789, Training Loss = 0.7634903192520142\n","Epoch: 1790, Training Loss = 0.7634574770927429\n","Accuracy =  0.6584302186965942 F1 weighted =  0.6266416311264038 F1 macro =  0.44756847620010376\n","Epoch: 1791, Training Loss = 0.7634245753288269\n","Epoch: 1792, Training Loss = 0.7633917331695557\n","Epoch: 1793, Training Loss = 0.7633588314056396\n","Epoch: 1794, Training Loss = 0.763326108455658\n","Epoch: 1795, Training Loss = 0.7632933855056763\n","Epoch: 1796, Training Loss = 0.763260543346405\n","Epoch: 1797, Training Loss = 0.7632277607917786\n","Epoch: 1798, Training Loss = 0.7631950974464417\n","Epoch: 1799, Training Loss = 0.76316237449646\n","Epoch: 1800, Training Loss = 0.763129711151123\n","Accuracy =  0.6585623621940613 F1 weighted =  0.626824140548706 F1 macro =  0.44780921936035156\n","Epoch: 1801, Training Loss = 0.7630970478057861\n","Epoch: 1802, Training Loss = 0.7630643844604492\n","Epoch: 1803, Training Loss = 0.7630317807197571\n","Epoch: 1804, Training Loss = 0.7629991769790649\n","Epoch: 1805, Training Loss = 0.7629665732383728\n","Epoch: 1806, Training Loss = 0.7629340291023254\n","Epoch: 1807, Training Loss = 0.7629014253616333\n","Epoch: 1808, Training Loss = 0.7628688812255859\n","Epoch: 1809, Training Loss = 0.7628363370895386\n","Epoch: 1810, Training Loss = 0.762803852558136\n","Accuracy =  0.6587605476379395 F1 weighted =  0.6271249055862427 F1 macro =  0.4491046965122223\n","Epoch: 1811, Training Loss = 0.7627713084220886\n","Epoch: 1812, Training Loss = 0.762738823890686\n","Epoch: 1813, Training Loss = 0.7627063989639282\n","Epoch: 1814, Training Loss = 0.7626739740371704\n","Epoch: 1815, Training Loss = 0.7626415491104126\n","Epoch: 1816, Training Loss = 0.7626092433929443\n","Epoch: 1817, Training Loss = 0.762576699256897\n","Epoch: 1818, Training Loss = 0.7625444531440735\n","Epoch: 1819, Training Loss = 0.7625120878219604\n","Epoch: 1820, Training Loss = 0.7624797821044922\n","Accuracy =  0.6586945056915283 F1 weighted =  0.6270853281021118 F1 macro =  0.4490404427051544\n","Epoch: 1821, Training Loss = 0.7624474167823792\n","Epoch: 1822, Training Loss = 0.7624152898788452\n","Epoch: 1823, Training Loss = 0.7623829245567322\n","Epoch: 1824, Training Loss = 0.7623506784439087\n","Epoch: 1825, Training Loss = 0.7623184323310852\n","Epoch: 1826, Training Loss = 0.7622863054275513\n","Epoch: 1827, Training Loss = 0.7622540593147278\n","Epoch: 1828, Training Loss = 0.7622219920158386\n","Epoch: 1829, Training Loss = 0.7621896862983704\n","Epoch: 1830, Training Loss = 0.7621576189994812\n","Accuracy =  0.6586945056915283 F1 weighted =  0.6272149085998535 F1 macro =  0.45006605982780457\n","Epoch: 1831, Training Loss = 0.7621254920959473\n","Epoch: 1832, Training Loss = 0.7620934247970581\n","Epoch: 1833, Training Loss = 0.7620612978935242\n","Epoch: 1834, Training Loss = 0.762029230594635\n","Epoch: 1835, Training Loss = 0.7619971632957458\n","Epoch: 1836, Training Loss = 0.7619650959968567\n","Epoch: 1837, Training Loss = 0.7619330286979675\n","Epoch: 1838, Training Loss = 0.7619011998176575\n","Epoch: 1839, Training Loss = 0.7618691325187683\n","Epoch: 1840, Training Loss = 0.7618372440338135\n","Accuracy =  0.6586284637451172 F1 weighted =  0.6272278428077698 F1 macro =  0.4510679841041565\n","Epoch: 1841, Training Loss = 0.7618051767349243\n","Epoch: 1842, Training Loss = 0.7617733478546143\n","Epoch: 1843, Training Loss = 0.7617414593696594\n","Epoch: 1844, Training Loss = 0.761709451675415\n","Epoch: 1845, Training Loss = 0.7616775631904602\n","Epoch: 1846, Training Loss = 0.7616457939147949\n","Epoch: 1847, Training Loss = 0.7616139650344849\n","Epoch: 1848, Training Loss = 0.76158207654953\n","Epoch: 1849, Training Loss = 0.7615503072738647\n","Epoch: 1850, Training Loss = 0.7615185976028442\n","Accuracy =  0.6587605476379395 F1 weighted =  0.6274333000183105 F1 macro =  0.4513629972934723\n","Epoch: 1851, Training Loss = 0.761486828327179\n","Epoch: 1852, Training Loss = 0.7614549994468689\n","Epoch: 1853, Training Loss = 0.7614232897758484\n","Epoch: 1854, Training Loss = 0.7613916397094727\n","Epoch: 1855, Training Loss = 0.7613599300384521\n","Epoch: 1856, Training Loss = 0.7613282203674316\n","Epoch: 1857, Training Loss = 0.7612965106964111\n","Epoch: 1858, Training Loss = 0.761264979839325\n","Epoch: 1859, Training Loss = 0.7612333297729492\n","Epoch: 1860, Training Loss = 0.7612016201019287\n","Accuracy =  0.6588266491889954 F1 weighted =  0.6275463700294495 F1 macro =  0.4517594873905182\n","Epoch: 1861, Training Loss = 0.761169970035553\n","Epoch: 1862, Training Loss = 0.7611384987831116\n","Epoch: 1863, Training Loss = 0.7611069083213806\n","Epoch: 1864, Training Loss = 0.7610753178596497\n","Epoch: 1865, Training Loss = 0.7610438466072083\n","Epoch: 1866, Training Loss = 0.7610124945640564\n","Epoch: 1867, Training Loss = 0.7609809637069702\n","Epoch: 1868, Training Loss = 0.760949432849884\n","Epoch: 1869, Training Loss = 0.7609179019927979\n","Epoch: 1870, Training Loss = 0.7608864903450012\n","Accuracy =  0.6588926911354065 F1 weighted =  0.6276451945304871 F1 macro =  0.45167112350463867\n","Epoch: 1871, Training Loss = 0.7608550786972046\n","Epoch: 1872, Training Loss = 0.7608237862586975\n","Epoch: 1873, Training Loss = 0.7607923746109009\n","Epoch: 1874, Training Loss = 0.7607609629631042\n","Epoch: 1875, Training Loss = 0.7607296705245972\n","Epoch: 1876, Training Loss = 0.7606983184814453\n","Epoch: 1877, Training Loss = 0.7606669068336487\n","Epoch: 1878, Training Loss = 0.7606356739997864\n","Epoch: 1879, Training Loss = 0.7606043815612793\n","Epoch: 1880, Training Loss = 0.7605732083320618\n","Accuracy =  0.6591569781303406 F1 weighted =  0.6280670762062073 F1 macro =  0.4521028399467468\n","Epoch: 1881, Training Loss = 0.7605418562889099\n","Epoch: 1882, Training Loss = 0.7605107426643372\n","Epoch: 1883, Training Loss = 0.7604794502258301\n","Epoch: 1884, Training Loss = 0.7604482173919678\n","Epoch: 1885, Training Loss = 0.7604170441627502\n","Epoch: 1886, Training Loss = 0.7603859305381775\n","Epoch: 1887, Training Loss = 0.7603548169136047\n","Epoch: 1888, Training Loss = 0.7603235840797424\n","Epoch: 1889, Training Loss = 0.7602925896644592\n","Epoch: 1890, Training Loss = 0.7602614760398865\n","Accuracy =  0.6592891216278076 F1 weighted =  0.628248929977417 F1 macro =  0.45232194662094116\n","Epoch: 1891, Training Loss = 0.7602304220199585\n","Epoch: 1892, Training Loss = 0.7601993083953857\n","Epoch: 1893, Training Loss = 0.7601683139801025\n","Epoch: 1894, Training Loss = 0.7601372003555298\n","Epoch: 1895, Training Loss = 0.7601062655448914\n","Epoch: 1896, Training Loss = 0.7600752115249634\n","Epoch: 1897, Training Loss = 0.760044276714325\n","Epoch: 1898, Training Loss = 0.7600134015083313\n","Epoch: 1899, Training Loss = 0.7599824070930481\n","Epoch: 1900, Training Loss = 0.7599514126777649\n","Accuracy =  0.6594873070716858 F1 weighted =  0.62857586145401 F1 macro =  0.4526263475418091\n","Epoch: 1901, Training Loss = 0.7599205374717712\n","Epoch: 1902, Training Loss = 0.7598896622657776\n","Epoch: 1903, Training Loss = 0.7598587274551392\n","Epoch: 1904, Training Loss = 0.7598279118537903\n","Epoch: 1905, Training Loss = 0.7597970962524414\n","Epoch: 1906, Training Loss = 0.7597662806510925\n","Epoch: 1907, Training Loss = 0.7597353458404541\n","Epoch: 1908, Training Loss = 0.7597046494483948\n","Epoch: 1909, Training Loss = 0.7596738934516907\n","Epoch: 1910, Training Loss = 0.7596431374549866\n","Accuracy =  0.6592891216278076 F1 weighted =  0.6283547878265381 F1 macro =  0.45240405201911926\n","Epoch: 1911, Training Loss = 0.7596123814582825\n","Epoch: 1912, Training Loss = 0.7595817446708679\n","Epoch: 1913, Training Loss = 0.7595511078834534\n","Epoch: 1914, Training Loss = 0.7595202922821045\n","Epoch: 1915, Training Loss = 0.7594895958900452\n","Epoch: 1916, Training Loss = 0.7594590187072754\n","Epoch: 1917, Training Loss = 0.7594282627105713\n","Epoch: 1918, Training Loss = 0.7593976855278015\n","Epoch: 1919, Training Loss = 0.7593671083450317\n","Epoch: 1920, Training Loss = 0.759336531162262\n","Accuracy =  0.6592230200767517 F1 weighted =  0.6283736228942871 F1 macro =  0.4525373578071594\n","Epoch: 1921, Training Loss = 0.759306013584137\n","Epoch: 1922, Training Loss = 0.7592754364013672\n","Epoch: 1923, Training Loss = 0.7592447996139526\n","Epoch: 1924, Training Loss = 0.7592142820358276\n","Epoch: 1925, Training Loss = 0.7591838836669922\n","Epoch: 1926, Training Loss = 0.7591533660888672\n","Epoch: 1927, Training Loss = 0.7591228485107422\n","Epoch: 1928, Training Loss = 0.7590923309326172\n","Epoch: 1929, Training Loss = 0.7590619325637817\n","Epoch: 1930, Training Loss = 0.7590315341949463\n","Accuracy =  0.6592891216278076 F1 weighted =  0.6284445524215698 F1 macro =  0.4525277316570282\n","Epoch: 1931, Training Loss = 0.7590010166168213\n","Epoch: 1932, Training Loss = 0.7589707374572754\n","Epoch: 1933, Training Loss = 0.7589403390884399\n","Epoch: 1934, Training Loss = 0.7589100003242493\n","Epoch: 1935, Training Loss = 0.7588796019554138\n","Epoch: 1936, Training Loss = 0.7588493227958679\n","Epoch: 1937, Training Loss = 0.7588189840316772\n","Epoch: 1938, Training Loss = 0.7587887048721313\n","Epoch: 1939, Training Loss = 0.7587584257125854\n","Epoch: 1940, Training Loss = 0.7587281465530396\n","Accuracy =  0.6592891216278076 F1 weighted =  0.6284922361373901 F1 macro =  0.4525349736213684\n","Epoch: 1941, Training Loss = 0.7586979269981384\n","Epoch: 1942, Training Loss = 0.7586677670478821\n","Epoch: 1943, Training Loss = 0.7586374878883362\n","Epoch: 1944, Training Loss = 0.7586072683334351\n","Epoch: 1945, Training Loss = 0.7585770487785339\n","Epoch: 1946, Training Loss = 0.7585469484329224\n","Epoch: 1947, Training Loss = 0.758516788482666\n","Epoch: 1948, Training Loss = 0.7584866285324097\n","Epoch: 1949, Training Loss = 0.7584565281867981\n","Epoch: 1950, Training Loss = 0.7584264874458313\n","Accuracy =  0.6593551635742188 F1 weighted =  0.6286028623580933 F1 macro =  0.45364120602607727\n","Epoch: 1951, Training Loss = 0.7583962678909302\n","Epoch: 1952, Training Loss = 0.7583662867546082\n","Epoch: 1953, Training Loss = 0.7583361864089966\n","Epoch: 1954, Training Loss = 0.758306086063385\n","Epoch: 1955, Training Loss = 0.758276104927063\n","Epoch: 1956, Training Loss = 0.758246123790741\n","Epoch: 1957, Training Loss = 0.7582160830497742\n","Epoch: 1958, Training Loss = 0.7581861615180969\n","Epoch: 1959, Training Loss = 0.7581562995910645\n","Epoch: 1960, Training Loss = 0.7581263184547424\n","Accuracy =  0.6594873070716858 F1 weighted =  0.6287492513656616 F1 macro =  0.45377737283706665\n","Epoch: 1961, Training Loss = 0.7580963373184204\n","Epoch: 1962, Training Loss = 0.7580664753913879\n","Epoch: 1963, Training Loss = 0.7580366134643555\n","Epoch: 1964, Training Loss = 0.7580066919326782\n","Epoch: 1965, Training Loss = 0.757976770401001\n","Epoch: 1966, Training Loss = 0.7579469680786133\n","Epoch: 1967, Training Loss = 0.7579171061515808\n","Epoch: 1968, Training Loss = 0.7578873634338379\n","Epoch: 1969, Training Loss = 0.7578575015068054\n","Epoch: 1970, Training Loss = 0.7578276991844177\n","Accuracy =  0.6594873070716858 F1 weighted =  0.6287611722946167 F1 macro =  0.45368263125419617\n","Epoch: 1971, Training Loss = 0.7577979564666748\n","Epoch: 1972, Training Loss = 0.7577681541442871\n","Epoch: 1973, Training Loss = 0.757738471031189\n","Epoch: 1974, Training Loss = 0.7577087879180908\n","Epoch: 1975, Training Loss = 0.7576791048049927\n","Epoch: 1976, Training Loss = 0.7576493620872498\n","Epoch: 1977, Training Loss = 0.7576197385787964\n","Epoch: 1978, Training Loss = 0.7575900554656982\n","Epoch: 1979, Training Loss = 0.7575603127479553\n","Epoch: 1980, Training Loss = 0.7575308084487915\n","Accuracy =  0.659685492515564 F1 weighted =  0.6290631294250488 F1 macro =  0.45483213663101196\n","Epoch: 1981, Training Loss = 0.7575011253356934\n","Epoch: 1982, Training Loss = 0.7574715614318848\n","Epoch: 1983, Training Loss = 0.7574419975280762\n","Epoch: 1984, Training Loss = 0.7574123740196228\n","Epoch: 1985, Training Loss = 0.757382869720459\n","Epoch: 1986, Training Loss = 0.7573533058166504\n","Epoch: 1987, Training Loss = 0.7573238611221313\n","Epoch: 1988, Training Loss = 0.757294237613678\n","Epoch: 1989, Training Loss = 0.7572647333145142\n","Epoch: 1990, Training Loss = 0.7572353482246399\n","Accuracy =  0.6595534086227417 F1 weighted =  0.6289584636688232 F1 macro =  0.45472925901412964\n","Epoch: 1991, Training Loss = 0.7572059035301208\n","Epoch: 1992, Training Loss = 0.757176399230957\n","Epoch: 1993, Training Loss = 0.757146954536438\n","Epoch: 1994, Training Loss = 0.7571176290512085\n","Epoch: 1995, Training Loss = 0.7570881843566895\n","Epoch: 1996, Training Loss = 0.75705885887146\n","Epoch: 1997, Training Loss = 0.7570294737815857\n","Epoch: 1998, Training Loss = 0.7570001482963562\n","Epoch: 1999, Training Loss = 0.7569707632064819\n"]}],"source":["from torchmetrics import F1Score, Accuracy\n","\n","model = Model(768, 1536, 768, qp_graph.etypes)\n","query_feats = qp_graph.nodes['query'].data['embed']\n","product_feats = qp_graph.nodes['product'].data['embed']\n","node_features = {'query': query_feats, 'product': product_feats}\n","\n","\n","\n","acc_list = []\n","f1_w = []\n","f1_m = []\n","\n","opt = torch.optim.Adam(model.parameters(), lr=0.001)\n","for epoch in range(2000):\n","    model.train()\n","    logits = model(qp_graph, node_features, dec_graph)\n","    loss = F.cross_entropy(logits[train_mask], edge_label[train_mask])\n","    opt.zero_grad()\n","    loss.backward()\n","    opt.step()\n","    print(f\"Epoch: {epoch}, Training Loss = {loss.item()}\")\n","\n","    if epoch % 10 == 0:\n","      model.eval()\n","      with torch.no_grad():\n","          logits = model(qp_graph, node_features, dec_graph)\n","          logits = logits[val_mask]\n","          labels = edge_label[val_mask]\n","          _, indices = torch.max(logits, dim=1)\n","          correct = torch.sum(indices == labels)\n","          f1 = F1Score(num_classes=4, average = 'weighted')\n","          f1_weighted = f1(indices, labels)\n","          f1 = F1Score(num_classes=4, average = 'macro')\n","          f1_macro = f1(indices, labels)\n","          accuracy = Accuracy()\n","          acc = accuracy(indices, labels)\n","          acc_list.append(acc.item())\n","          f1_w.append(f1_weighted.item())\n","          f1_m.append(f1_macro.item())\n","          print(\"Accuracy = \", acc.item(), \"F1 weighted = \", f1_weighted.item(), \"F1 macro = \", f1_macro.item())"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.rcParams[\"figure.figsize\"] = (12,8)\n","plt.plot(list(range(200)), acc_list, label=\"Accuracy\")\n","plt.plot(list(range(200)), f1_w, label=\"F1 Weighted\")\n","plt.plot(list(range(200)), f1_m, label=\"F1 Macro\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"GNN Training Detail (768D)\")\n","plt.xlabel(\"epoches (*10)\")\n","plt.xticks(np.arange(0, 200, 10))\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"JlntS4TugatT","executionInfo":{"status":"ok","timestamp":1651968097135,"user_tz":300,"elapsed":704,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"697c7992-51ca-4945-c78c-7dfb36e8e160"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"31-heteograph-approach-768d.ipynb","provenance":[{"file_id":"1wOHKWuVK01UvCgY1qm2g8t8_cYwQS_D-","timestamp":1651883203985}],"authorship_tag":"ABX9TyPNg4Bew937ZkoDtERXV69W"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}