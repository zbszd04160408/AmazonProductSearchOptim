{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21929,"status":"ok","timestamp":1651911448384,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"HLUA9V2uyAyL","outputId":"8fcd1849-d6f9-47e8-b8db-721dda69a186"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Othercomputers/Vivian's MacBook Pro 2021/DS5720/FinalProject\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","cur_path = \"./drive/Othercomputers/Vivian's MacBook Pro 2021/DS5720/FinalProject\"\n","os.chdir(cur_path)\n","!pwd"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28068,"status":"ok","timestamp":1651911476448,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"eZt_o-qjx0ns","outputId":"f63bddbb-7992-4d7b-dfd9-ff3902f34e7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dgl\n","  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n","Installing collected packages: dgl\n","Successfully installed dgl-0.6.1\n","\u001b[33mWARNING: Skipping umap as it is not installed.\u001b[0m\n","Collecting umap-learn\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n","Collecting pynndescent>=0.5\n","  Downloading pynndescent-0.5.6.tar.gz (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 24.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.64.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n","Building wheels for collected packages: umap-learn, pynndescent\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=7355c6e4e1a5f602c8ff4b8c1ffd1d16742e6919e419a4c09acb2dcbd0469950\n","  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pynndescent: filename=pynndescent-0.5.6-py3-none-any.whl size=53943 sha256=12dd9937e64acb46e0746d7908368cc45000ce789b9a0897408c75decb505737\n","  Stored in directory: /root/.cache/pip/wheels/03/f1/56/f80d72741e400345b5a5b50ec3d929aca581bf45e0225d5c50\n","Successfully built umap-learn pynndescent\n","Installing collected packages: pynndescent, umap-learn\n","Successfully installed pynndescent-0.5.6 umap-learn-0.5.3\n","Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Using backend: pytorch\n"]}],"source":["! pip install dgl\n","! pip uninstall umap\n","! pip install umap-learn\n","import dgl\n","import torch\n","import pandas as pd \n","import umap.umap_ as umap"]},{"cell_type":"code","source":["reducer = umap.UMAP()"],"metadata":{"id":"VxhGpTyo1HUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BBiHzbsPr-CI"},"source":["# 1. Data Import"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"KA7FwfwGmx8-","executionInfo":{"status":"ok","timestamp":1651911563194,"user_tz":300,"elapsed":40769,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["task = pd.read_csv(\"./data/task2/train-v0.2.csv\")\n","mega_table = pd.read_csv(\"./data/product_catalogue-v0.2.csv\")\n","merged_df = pd.merge(task, mega_table, how = 'left', left_on = ['product_id', 'query_locale'], right_on = ['product_id', 'product_locale'])\n","# query_embed = pd.read_csv(\"./data/us50k_query_embedding.csv\")\n","# product_title_embed = pd.read_csv(\"./data/us50k_product_title_embedding.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gIk7nG3X6qFj","executionInfo":{"status":"ok","timestamp":1651911565070,"user_tz":300,"elapsed":1884,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["merged_df = merged_df[merged_df['product_locale'] == 'us']\n","merged_df = merged_df.fillna('')"]},{"cell_type":"markdown","metadata":{"id":"5i0_7sPXzTK4"},"source":["## 1.1 Get nodes"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3061,"status":"ok","timestamp":1651911739186,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"D5HE_xW87Igb","outputId":"5bf52702-f36b-42db-dd7d-bca59c465850"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       query_id                           Query  \\\n","0             0                   revent 80 cfm   \n","1             1       # 2 pencils not sharpened   \n","2             2                # do not disturb   \n","3             3                      # mom life   \n","4             4       # sharp not hashtag shirt   \n","...         ...                             ...   \n","68134     68134                    tach adapter   \n","68135     68135  the armorer vintage collection   \n","68136     68136   trojan magnum condoms for men   \n","68137     68137         white adirondack chairs   \n","68138     68138            zephyr polishing kit   \n","\n","                                                combined  \n","0      [6.707994892386412, -1.1259202660754608, -1.87...  \n","1      [19.398371324702136, 4.7386912652123625, 0.152...  \n","2      [19.078527339962307, 4.277098531521469, -0.785...  \n","3      [-5.775765065166072, 1.2687145926624706, -2.55...  \n","4      [15.151273246281065, 1.5357711704597623, -1.36...  \n","...                                                  ...  \n","68134  [-3.378503751095054, -1.3066904223212252, 1.34...  \n","68135  [-5.44916096928764, 1.8461803490483888, -0.324...  \n","68136  [3.833861734968945, -2.2165069732520517, -0.93...  \n","68137  [-1.5253085263156851, -0.8573476160719742, 0.2...  \n","68138  [-3.797512703650293, -1.3904562297866971, 0.83...  \n","\n","[68139 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-dbfa9716-cd82-486b-b305-d64a7896fef4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>Query</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[6.707994892386412, -1.1259202660754608, -1.87...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td># 2 pencils not sharpened</td>\n","      <td>[19.398371324702136, 4.7386912652123625, 0.152...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td># do not disturb</td>\n","      <td>[19.078527339962307, 4.277098531521469, -0.785...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td># mom life</td>\n","      <td>[-5.775765065166072, 1.2687145926624706, -2.55...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td># sharp not hashtag shirt</td>\n","      <td>[15.151273246281065, 1.5357711704597623, -1.36...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>68134</th>\n","      <td>68134</td>\n","      <td>tach adapter</td>\n","      <td>[-3.378503751095054, -1.3066904223212252, 1.34...</td>\n","    </tr>\n","    <tr>\n","      <th>68135</th>\n","      <td>68135</td>\n","      <td>the armorer vintage collection</td>\n","      <td>[-5.44916096928764, 1.8461803490483888, -0.324...</td>\n","    </tr>\n","    <tr>\n","      <th>68136</th>\n","      <td>68136</td>\n","      <td>trojan magnum condoms for men</td>\n","      <td>[3.833861734968945, -2.2165069732520517, -0.93...</td>\n","    </tr>\n","    <tr>\n","      <th>68137</th>\n","      <td>68137</td>\n","      <td>white adirondack chairs</td>\n","      <td>[-1.5253085263156851, -0.8573476160719742, 0.2...</td>\n","    </tr>\n","    <tr>\n","      <th>68138</th>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[-3.797512703650293, -1.3904562297866971, 0.83...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>68139 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbfa9716-cd82-486b-b305-d64a7896fef4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dbfa9716-cd82-486b-b305-d64a7896fef4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dbfa9716-cd82-486b-b305-d64a7896fef4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}],"source":["query_embed = pd.read_csv(\"./data/query_88d_embedding.csv\")\n","query_embed = pd.merge(query_embed, pd.DataFrame(merged_df['query'].unique(), columns=['Query']), on = 'Query')\n","query_embed.insert(0, 'query_id', range(0, 0 + len(query_embed)))\n","query_embed['combined']=query_embed.drop(columns=['query_id', 'Query']).values.tolist()\n","query_embed = query_embed[['query_id', 'Query', 'combined']]\n","query_embed"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":61731,"status":"ok","timestamp":1651911800906,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"YCroXLcK1mh4","outputId":"70be5c23-647e-459b-a6b1-c37ecbc82b90"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        product_id                                            Product  \\\n","0                0  Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...   \n","1                1  Broan Very Quiet Ceiling Bathroom Exhaust Fan,...   \n","2                2  Delta BreezSignature VFB25ACH 80 CFM Exhaust B...   \n","3                3  Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...   \n","4                4  Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...   \n","...            ...                                                ...   \n","856997      856997  VY4AOS2 My Hero Academia That Wasn't Very Plus...   \n","856998      856998  Phoetya Women's My Hero Academia Hoodie That's...   \n","856999      856999  Defrosting Tray (Largest Size) for Rapid thaw ...   \n","857000      857000  Danoib Fast Defrosting Tray Rapid Thaw Plate M...   \n","857001      857001  Quadow Defrost Tray,Easy Thaw Tray Defrost Foo...   \n","\n","                                                 combined  \n","0       [-4.361595723502376, 0.9364387358669418, -0.63...  \n","1       [-4.179065625209809, 0.471360105629001, -0.715...  \n","2       [-2.8169267146903616, -1.1865155362619637, -0....  \n","3       [13.84494645659871, 4.88867980213354, -2.33215...  \n","4       [-1.6226850900844525, -1.629046474344177, -0.7...  \n","...                                                   ...  \n","856997  [12.097629648495747, 2.7960729345119284, 1.175...  \n","856998  [15.60419244951624, 8.029572555596365, 0.66361...  \n","856999  [-3.527773138502794, 0.3512122295462834, -0.45...  \n","857000  [-3.0487363856102108, -0.232905261681144, -0.4...  \n","857001  [3.2936403245841244, -2.1883559747775845, -0.8...  \n","\n","[857002 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-18f5c462-1192-449a-bb9b-8e2c481eebba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>Product</th>\n","      <th>combined</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>[-4.361595723502376, 0.9364387358669418, -0.63...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>[-4.179065625209809, 0.471360105629001, -0.715...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>[-2.8169267146903616, -1.1865155362619637, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>[13.84494645659871, 4.88867980213354, -2.33215...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>[-1.6226850900844525, -1.629046474344177, -0.7...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>856997</th>\n","      <td>856997</td>\n","      <td>VY4AOS2 My Hero Academia That Wasn't Very Plus...</td>\n","      <td>[12.097629648495747, 2.7960729345119284, 1.175...</td>\n","    </tr>\n","    <tr>\n","      <th>856998</th>\n","      <td>856998</td>\n","      <td>Phoetya Women's My Hero Academia Hoodie That's...</td>\n","      <td>[15.60419244951624, 8.029572555596365, 0.66361...</td>\n","    </tr>\n","    <tr>\n","      <th>856999</th>\n","      <td>856999</td>\n","      <td>Defrosting Tray (Largest Size) for Rapid thaw ...</td>\n","      <td>[-3.527773138502794, 0.3512122295462834, -0.45...</td>\n","    </tr>\n","    <tr>\n","      <th>857000</th>\n","      <td>857000</td>\n","      <td>Danoib Fast Defrosting Tray Rapid Thaw Plate M...</td>\n","      <td>[-3.0487363856102108, -0.232905261681144, -0.4...</td>\n","    </tr>\n","    <tr>\n","      <th>857001</th>\n","      <td>857001</td>\n","      <td>Quadow Defrost Tray,Easy Thaw Tray Defrost Foo...</td>\n","      <td>[3.2936403245841244, -2.1883559747775845, -0.8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>857002 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18f5c462-1192-449a-bb9b-8e2c481eebba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-18f5c462-1192-449a-bb9b-8e2c481eebba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-18f5c462-1192-449a-bb9b-8e2c481eebba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["product_title_embed = pd.read_csv(\"./data/product_88d_embedding.csv\")\n","# product_title_embed = product_title_embed[:857004]\n","merged_df['product'] = merged_df['product_title'] +  merged_df['product_description'] +  merged_df['product_bullet_point'] +  merged_df['product_brand'] +  merged_df['product_color_name']\n","product_title_embed = pd.merge(product_title_embed, pd.DataFrame(merged_df['product'].unique(), columns=['Product']), on = 'Product')\n","product_title_embed.insert(0, 'product_id', range(0, 0 + len(product_title_embed)))\n","product_title_embed['combined']=product_title_embed.drop(columns=['product_id', 'Product']).values.tolist()\n","product_title_embed = product_title_embed[['product_id', 'Product', 'combined']]\n","product_title_embed"]},{"cell_type":"markdown","metadata":{"id":"X2Nc3vOS4sTY"},"source":["## 1.2 Get edges"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"GQHv1R--2mDf","colab":{"base_uri":"https://localhost:8080/","height":641},"executionInfo":{"status":"ok","timestamp":1651911805346,"user_tz":300,"elapsed":4443,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}},"outputId":"7146f921-3e60-4dc4-abb6-7e3d48bc668b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                        query  \\\n","0               revent 80 cfm   \n","1               revent 80 cfm   \n","2               revent 80 cfm   \n","3               revent 80 cfm   \n","4               revent 80 cfm   \n","...                       ...   \n","1272621  zephyr polishing kit   \n","1272622  zephyr polishing kit   \n","1272623  zephyr polishing kit   \n","1272624  zephyr polishing kit   \n","1272625  zephyr polishing kit   \n","\n","                                                   product  esci_label  \\\n","0        Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...  irrelevant   \n","1        Broan Very Quiet Ceiling Bathroom Exhaust Fan,...       exact   \n","2        Delta BreezSignature VFB25ACH 80 CFM Exhaust B...       exact   \n","3        Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...       exact   \n","4        Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...       exact   \n","...                                                    ...         ...   \n","1272621  Buffing Wheel Rake Remove Residual Compounds/M...  irrelevant   \n","1272622  Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...  complement   \n","1272623  7 Inch Polishing Pads Kit Car Foam Sponge Pads...  substitute   \n","1272624  Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...  substitute   \n","1272625  KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...       exact   \n","\n","         query_id                 Query  \\\n","0               0         revent 80 cfm   \n","1               0         revent 80 cfm   \n","2               0         revent 80 cfm   \n","3               0         revent 80 cfm   \n","4               0         revent 80 cfm   \n","...           ...                   ...   \n","1272621     68138  zephyr polishing kit   \n","1272622     68138  zephyr polishing kit   \n","1272623     68138  zephyr polishing kit   \n","1272624     68138  zephyr polishing kit   \n","1272625     68138  zephyr polishing kit   \n","\n","                                            combined_query  product_id  \\\n","0        [6.707994892386412, -1.1259202660754608, -1.87...         0.0   \n","1        [6.707994892386412, -1.1259202660754608, -1.87...         1.0   \n","2        [6.707994892386412, -1.1259202660754608, -1.87...         2.0   \n","3        [6.707994892386412, -1.1259202660754608, -1.87...         3.0   \n","4        [6.707994892386412, -1.1259202660754608, -1.87...         4.0   \n","...                                                    ...         ...   \n","1272621  [-3.797512703650293, -1.3904562297866971, 0.83...    766998.0   \n","1272622  [-3.797512703650293, -1.3904562297866971, 0.83...    766999.0   \n","1272623  [-3.797512703650293, -1.3904562297866971, 0.83...    804146.0   \n","1272624  [-3.797512703650293, -1.3904562297866971, 0.83...    767000.0   \n","1272625  [-3.797512703650293, -1.3904562297866971, 0.83...    767001.0   \n","\n","                                                   Product  \\\n","0        Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...   \n","1        Broan Very Quiet Ceiling Bathroom Exhaust Fan,...   \n","2        Delta BreezSignature VFB25ACH 80 CFM Exhaust B...   \n","3        Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...   \n","4        Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...   \n","...                                                    ...   \n","1272621  Buffing Wheel Rake Remove Residual Compounds/M...   \n","1272622  Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...   \n","1272623  7 Inch Polishing Pads Kit Car Foam Sponge Pads...   \n","1272624  Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...   \n","1272625  KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...   \n","\n","                                          combined_product  \n","0        [-4.361595723502376, 0.9364387358669418, -0.63...  \n","1        [-4.179065625209809, 0.471360105629001, -0.715...  \n","2        [-2.8169267146903616, -1.1865155362619637, -0....  \n","3        [13.84494645659871, 4.88867980213354, -2.33215...  \n","4        [-1.6226850900844525, -1.629046474344177, -0.7...  \n","...                                                    ...  \n","1272621  [-0.697468466278092, -1.3145220845254135, -0.2...  \n","1272622  [8.05669257171573, -1.8337681391569216, -0.647...  \n","1272623  [-2.720129723442238, -0.4235162043279317, 0.32...  \n","1272624  [0.1792142899080548, -2.1200385937646584, -0.3...  \n","1272625  [1.0424881163377784, -1.8271990373520643, -1.1...  \n","\n","[1200960 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-1918baeb-c972-4019-947f-f8c0e140714f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query</th>\n","      <th>product</th>\n","      <th>esci_label</th>\n","      <th>query_id</th>\n","      <th>Query</th>\n","      <th>combined_query</th>\n","      <th>product_id</th>\n","      <th>Product</th>\n","      <th>combined_product</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>revent 80 cfm</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>irrelevant</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[6.707994892386412, -1.1259202660754608, -1.87...</td>\n","      <td>0.0</td>\n","      <td>Panasonic FV-20VQ3 WhisperCeiling 190 CFM Ceil...</td>\n","      <td>[-4.361595723502376, 0.9364387358669418, -0.63...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>revent 80 cfm</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[6.707994892386412, -1.1259202660754608, -1.87...</td>\n","      <td>1.0</td>\n","      <td>Broan Very Quiet Ceiling Bathroom Exhaust Fan,...</td>\n","      <td>[-4.179065625209809, 0.471360105629001, -0.715...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>revent 80 cfm</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[6.707994892386412, -1.1259202660754608, -1.87...</td>\n","      <td>2.0</td>\n","      <td>Delta BreezSignature VFB25ACH 80 CFM Exhaust B...</td>\n","      <td>[-2.8169267146903616, -1.1865155362619637, -0....</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>revent 80 cfm</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[6.707994892386412, -1.1259202660754608, -1.87...</td>\n","      <td>3.0</td>\n","      <td>Aero Pure AP80RVLW Super Quiet 80 CFM Recessed...</td>\n","      <td>[13.84494645659871, 4.88867980213354, -2.33215...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>revent 80 cfm</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>exact</td>\n","      <td>0</td>\n","      <td>revent 80 cfm</td>\n","      <td>[6.707994892386412, -1.1259202660754608, -1.87...</td>\n","      <td>4.0</td>\n","      <td>Panasonic FV-0811VF5 WhisperFit EZ Retrofit Ve...</td>\n","      <td>[-1.6226850900844525, -1.629046474344177, -0.7...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1272621</th>\n","      <td>zephyr polishing kit</td>\n","      <td>Buffing Wheel Rake Remove Residual Compounds/M...</td>\n","      <td>irrelevant</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[-3.797512703650293, -1.3904562297866971, 0.83...</td>\n","      <td>766998.0</td>\n","      <td>Buffing Wheel Rake Remove Residual Compounds/M...</td>\n","      <td>[-0.697468466278092, -1.3145220845254135, -0.2...</td>\n","    </tr>\n","    <tr>\n","      <th>1272622</th>\n","      <td>zephyr polishing kit</td>\n","      <td>Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...</td>\n","      <td>complement</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[-3.797512703650293, -1.3904562297866971, 0.83...</td>\n","      <td>766999.0</td>\n","      <td>Zephyr Orange Ruffy Heavy Cut Clear Dip Airway...</td>\n","      <td>[8.05669257171573, -1.8337681391569216, -0.647...</td>\n","    </tr>\n","    <tr>\n","      <th>1272623</th>\n","      <td>zephyr polishing kit</td>\n","      <td>7 Inch Polishing Pads Kit Car Foam Sponge Pads...</td>\n","      <td>substitute</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[-3.797512703650293, -1.3904562297866971, 0.83...</td>\n","      <td>804146.0</td>\n","      <td>7 Inch Polishing Pads Kit Car Foam Sponge Pads...</td>\n","      <td>[-2.720129723442238, -0.4235162043279317, 0.32...</td>\n","    </tr>\n","    <tr>\n","      <th>1272624</th>\n","      <td>zephyr polishing kit</td>\n","      <td>Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...</td>\n","      <td>substitute</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[-3.797512703650293, -1.3904562297866971, 0.83...</td>\n","      <td>767000.0</td>\n","      <td>Kshineni Car Foam Drill 3-Inch Buffing Pad,11 ...</td>\n","      <td>[0.1792142899080548, -2.1200385937646584, -0.3...</td>\n","    </tr>\n","    <tr>\n","      <th>1272625</th>\n","      <td>zephyr polishing kit</td>\n","      <td>KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...</td>\n","      <td>exact</td>\n","      <td>68138</td>\n","      <td>zephyr polishing kit</td>\n","      <td>[-3.797512703650293, -1.3904562297866971, 0.83...</td>\n","      <td>767001.0</td>\n","      <td>KingTool Airway Buffing Wheel Kit - 3PCS 8\" Ai...</td>\n","      <td>[1.0424881163377784, -1.8271990373520643, -1.1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1200960 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1918baeb-c972-4019-947f-f8c0e140714f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1918baeb-c972-4019-947f-f8c0e140714f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1918baeb-c972-4019-947f-f8c0e140714f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["cleaned_df = merged_df[merged_df['product_locale'] == 'us'][['query', 'product', 'esci_label']]\n","temp_merged = pd.merge(cleaned_df, query_embed, left_on = ['query'], right_on = ['Query'], how = 'left')\n","total_index = pd.merge(temp_merged, product_title_embed, left_on = ['product'], right_on = ['Product'], how = 'left', suffixes = ('_query', '_product') )\n","total_index = total_index.dropna()\n","# total_index\n","query_idx = total_index[['query_id', 'query', 'combined_query', 'esci_label']]\n","product_idx = total_index[['product_id', 'product', 'combined_product', 'esci_label']]\n","total_index"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"PyOobiRHBOld","executionInfo":{"status":"ok","timestamp":1651911806191,"user_tz":300,"elapsed":851,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["i_edge_q = query_idx[query_idx['esci_label'] == 'irrelevant']\n","i_edge_p = product_idx[product_idx['esci_label'] == 'irrelevant']\n","i_edge_idx = [i_edge_q['query_id'].tolist(), i_edge_p['product_id'].tolist()]\n","\n","e_edge_q = query_idx[query_idx['esci_label'] == 'exact']\n","e_edge_p = product_idx[product_idx['esci_label'] == 'exact']\n","e_edge_idx = [e_edge_q['query_id'].tolist(), e_edge_p['product_id'].tolist()]\n","\n","c_edge_q = query_idx[query_idx['esci_label'] == 'complement']\n","c_edge_p = product_idx[product_idx['esci_label'] == 'complement']\n","c_edge_idx = [c_edge_q['query_id'].tolist(), c_edge_p['product_id'].tolist()]\n","\n","\n","s_edge_q = query_idx[query_idx['esci_label'] == 'substitute']\n","s_edge_p = product_idx[product_idx['esci_label'] == 'substitute']\n","s_edge_idx = [s_edge_q['query_id'].tolist(), s_edge_p['product_id'].tolist()]\n"]},{"cell_type":"markdown","metadata":{"id":"vKlnJGYY4uOK"},"source":["# 2. Create Graph"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ClMfrGUGCCbE","executionInfo":{"status":"ok","timestamp":1651911806192,"user_tz":300,"elapsed":4,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["graph_data = {\n","   ('query', 'irrelevant', 'product'): (torch.tensor(i_edge_idx[0], dtype=torch.int32), torch.tensor(i_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'exact', 'product'): (torch.tensor(e_edge_idx[0], dtype=torch.int32), torch.tensor(e_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'complement', 'product'): (torch.tensor(c_edge_idx[0], dtype=torch.int32), torch.tensor(c_edge_idx[1], dtype=torch.int32)),\n","   ('query', 'substitute', 'product'): (torch.tensor(s_edge_idx[0], dtype=torch.int32), torch.tensor(s_edge_idx[1], dtype=torch.int32))\n","}\n","qp_graph = dgl.heterograph(graph_data)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651911806192,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"9nKvaNwv4w42","outputId":"def4a937-08c1-45be-c66c-8ebdb9c9031f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Graph(num_nodes={'product': 857002, 'query': 68139},\n","      num_edges={('query', 'complement', 'product'): 26648, ('query', 'exact', 'product'): 823409, ('query', 'irrelevant', 'product'): 107121, ('query', 'substitute', 'product'): 243782},\n","      metagraph=[('query', 'product', 'complement'), ('query', 'product', 'exact'), ('query', 'product', 'irrelevant'), ('query', 'product', 'substitute')])"]},"metadata":{},"execution_count":11}],"source":["qp_graph"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"m6TOHP4lRhQX","executionInfo":{"status":"ok","timestamp":1651911809889,"user_tz":300,"elapsed":273,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["qp_graph.nodes['query'].data['embed'] = torch.tensor(query_embed['combined'].tolist())\n","qp_graph.nodes['product'].data['embed'] = torch.tensor(product_title_embed['combined'].tolist())"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1478,"status":"ok","timestamp":1651911812455,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"eiK-aQkgK0-T","outputId":"544c8c0b-d9f0-46f9-ed3d-a727fa24ec8c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["238"]},"metadata":{},"execution_count":13}],"source":["import gc\n","\n","del task\n","del mega_table\n","del merged_df\n","del cleaned_df\n","\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"a4yINMxKUMc-"},"source":["# 3. Train a model"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"lO5glZJjVhtP","executionInfo":{"status":"ok","timestamp":1651911839107,"user_tz":300,"elapsed":233,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["import dgl.nn as dglnn\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class RGCN(nn.Module):\n","    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n","        super().__init__()\n","\n","        self.conv1 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(in_feats, hid_feats)\n","            for rel in rel_names}, aggregate='sum')\n","        self.conv2 = dglnn.HeteroGraphConv({\n","            rel: dglnn.GraphConv(hid_feats, out_feats)\n","            for rel in rel_names}, aggregate='sum')\n","\n","    def forward(self, graph, inputs):\n","        # inputs are features of nodes\n","        h = self.conv1(graph, inputs)\n","        h = {k: F.relu(v) for k, v in h.items()}\n","        h = self.conv2(graph, h)\n","        return h\n","\n","class HeteroMLPPredictor(nn.Module):\n","    def __init__(self, in_dims, n_classes):\n","        super().__init__()\n","        self.W = nn.Linear(in_dims * 2, n_classes)\n","\n","    def apply_edges(self, edges):\n","        x = torch.cat([edges.src['embed'], edges.dst['embed']], 1)\n","        y = self.W(x)\n","        return {'score': y}\n","\n","    def forward(self, graph, h):\n","        # h contains the node representations for each edge type computed from\n","        # the GNN for heterogeneous graphs defined in the node classification\n","        # section (Section 5.1).\n","        with graph.local_scope():\n","            graph.ndata['h'] = h   # assigns 'h' of all node types in one shot\n","            graph.apply_edges(self.apply_edges)\n","            return graph.edata['score']\n","\n","class Model(nn.Module):\n","    def __init__(self, in_features, hidden_features, out_features, rel_names):\n","        super().__init__()\n","        self.sage = RGCN(in_features, hidden_features, out_features, rel_names)\n","        self.pred = HeteroMLPPredictor(out_features, len(rel_names))\n","    def forward(self, g, x, dec_graph):\n","        h = self.sage(g, x)\n","        return self.pred(dec_graph, h)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1651911841166,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"y1zgKw8NUOMp","outputId":"44d415cf-84b2-4296-e157-fff48927ee12"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"]}],"source":["dec_graph = qp_graph['query', :, 'product']\n","edge_label = torch.tensor(dec_graph.edata[dgl.ETYPE], dtype=torch.long)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"x4m9gDuGbWmG","executionInfo":{"status":"ok","timestamp":1651911847626,"user_tz":300,"elapsed":4901,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["dec_graph.edata['train_mask'] = torch.zeros(dec_graph.num_edges('complement+exact+irrelevant+substitute'), dtype=torch.bool).bernoulli(0.7)\n","dec_graph.edata['val_mask'] = torch.tensor([not x for x in dec_graph.edata['train_mask'] ], dtype=torch.bool)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"4Jj9pateWQ8x","executionInfo":{"status":"ok","timestamp":1651911847626,"user_tz":300,"elapsed":3,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"}}},"outputs":[],"source":["train_mask = dec_graph.edata['train_mask']\n","val_mask = dec_graph.edata['val_mask']"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3460,"status":"ok","timestamp":1651911851083,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"SLKfCjd7rRiq","outputId":"b40d48c1-9c93-4e9b-c10b-8e53814d434c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 409 kB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Collecting pyDeprecate==0.3.*\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n","Installing collected packages: pyDeprecate, torchmetrics\n","Successfully installed pyDeprecate-0.3.2 torchmetrics-0.8.2\n"]}],"source":["! pip install torchmetrics"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7298753,"status":"ok","timestamp":1651919153426,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"7nkUVsnuV_bD","outputId":"5a903573-4120-4380-c4b2-ed7b31a72749"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Training Loss = 1.5377602577209473\n","Accuracy =  0.24428123235702515 F1 weighted =  0.3111568093299866 F1 macro =  0.1803833395242691\n","Epoch: 1, Training Loss = 1.5312258005142212\n","Epoch: 2, Training Loss = 1.5247867107391357\n","Epoch: 3, Training Loss = 1.5184451341629028\n","Epoch: 4, Training Loss = 1.5122032165527344\n","Epoch: 5, Training Loss = 1.506062626838684\n","Epoch: 6, Training Loss = 1.5000258684158325\n","Epoch: 7, Training Loss = 1.4940941333770752\n","Epoch: 8, Training Loss = 1.4882686138153076\n","Epoch: 9, Training Loss = 1.4825509786605835\n","Epoch: 10, Training Loss = 1.4769412279129028\n","Accuracy =  0.26876404881477356 F1 weighted =  0.33717453479766846 F1 macro =  0.19303807616233826\n","Epoch: 11, Training Loss = 1.4714409112930298\n","Epoch: 12, Training Loss = 1.466049075126648\n","Epoch: 13, Training Loss = 1.4607667922973633\n","Epoch: 14, Training Loss = 1.4555938243865967\n","Epoch: 15, Training Loss = 1.4505305290222168\n","Epoch: 16, Training Loss = 1.4455764293670654\n","Epoch: 17, Training Loss = 1.4407321214675903\n","Epoch: 18, Training Loss = 1.4359965324401855\n","Epoch: 19, Training Loss = 1.4313700199127197\n","Epoch: 20, Training Loss = 1.4268522262573242\n","Accuracy =  0.3012578785419464 F1 weighted =  0.3693835735321045 F1 macro =  0.2103705108165741\n","Epoch: 21, Training Loss = 1.4224424362182617\n","Epoch: 22, Training Loss = 1.4181406497955322\n","Epoch: 23, Training Loss = 1.4139457941055298\n","Epoch: 24, Training Loss = 1.4098570346832275\n","Epoch: 25, Training Loss = 1.4058740139007568\n","Epoch: 26, Training Loss = 1.4019955396652222\n","Epoch: 27, Training Loss = 1.3982200622558594\n","Epoch: 28, Training Loss = 1.394546627998352\n","Epoch: 29, Training Loss = 1.3909738063812256\n","Epoch: 30, Training Loss = 1.3874998092651367\n","Accuracy =  0.3389859199523926 F1 weighted =  0.4047890305519104 F1 macro =  0.23068250715732574\n","Epoch: 31, Training Loss = 1.3841229677200317\n","Epoch: 32, Training Loss = 1.3808414936065674\n","Epoch: 33, Training Loss = 1.3776532411575317\n","Epoch: 34, Training Loss = 1.3745564222335815\n","Epoch: 35, Training Loss = 1.3715486526489258\n","Epoch: 36, Training Loss = 1.368627905845642\n","Epoch: 37, Training Loss = 1.3657912015914917\n","Epoch: 38, Training Loss = 1.363036870956421\n","Epoch: 39, Training Loss = 1.3603625297546387\n","Epoch: 40, Training Loss = 1.3577650785446167\n","Accuracy =  0.3781273365020752 F1 weighted =  0.44012323021888733 F1 macro =  0.2518008351325989\n","Epoch: 41, Training Loss = 1.3552426099777222\n","Epoch: 42, Training Loss = 1.3527923822402954\n","Epoch: 43, Training Loss = 1.3504115343093872\n","Epoch: 44, Training Loss = 1.3480981588363647\n","Epoch: 45, Training Loss = 1.3458493947982788\n","Epoch: 46, Training Loss = 1.3436630964279175\n","Epoch: 47, Training Loss = 1.341536521911621\n","Epoch: 48, Training Loss = 1.3394672870635986\n","Epoch: 49, Training Loss = 1.3374534845352173\n","Epoch: 50, Training Loss = 1.3354922533035278\n","Accuracy =  0.41893482208251953 F1 weighted =  0.47533780336380005 F1 macro =  0.2717016339302063\n","Epoch: 51, Training Loss = 1.3335816860198975\n","Epoch: 52, Training Loss = 1.331719994544983\n","Epoch: 53, Training Loss = 1.329904556274414\n","Epoch: 54, Training Loss = 1.328133463859558\n","Epoch: 55, Training Loss = 1.3264052867889404\n","Epoch: 56, Training Loss = 1.3247175216674805\n","Epoch: 57, Training Loss = 1.3230687379837036\n","Epoch: 58, Training Loss = 1.321457028388977\n","Epoch: 59, Training Loss = 1.3198810815811157\n","Epoch: 60, Training Loss = 1.3183389902114868\n","Accuracy =  0.4583122730255127 F1 weighted =  0.506937563419342 F1 macro =  0.2902485132217407\n","Epoch: 61, Training Loss = 1.3168294429779053\n","Epoch: 62, Training Loss = 1.3153507709503174\n","Epoch: 63, Training Loss = 1.3139019012451172\n","Epoch: 64, Training Loss = 1.3124812841415405\n","Epoch: 65, Training Loss = 1.31108820438385\n","Epoch: 66, Training Loss = 1.309720754623413\n","Epoch: 67, Training Loss = 1.3083778619766235\n","Epoch: 68, Training Loss = 1.3070588111877441\n","Epoch: 69, Training Loss = 1.3057622909545898\n","Epoch: 70, Training Loss = 1.3044875860214233\n","Accuracy =  0.4885097146034241 F1 weighted =  0.529583215713501 F1 macro =  0.3046954870223999\n","Epoch: 71, Training Loss = 1.30323326587677\n","Epoch: 72, Training Loss = 1.301998496055603\n","Epoch: 73, Training Loss = 1.3007826805114746\n","Epoch: 74, Training Loss = 1.2995847463607788\n","Epoch: 75, Training Loss = 1.2984042167663574\n","Epoch: 76, Training Loss = 1.2972396612167358\n","Epoch: 77, Training Loss = 1.2960909605026245\n","Epoch: 78, Training Loss = 1.2949570417404175\n","Epoch: 79, Training Loss = 1.293837547302246\n","Epoch: 80, Training Loss = 1.2927314043045044\n","Accuracy =  0.508580207824707 F1 weighted =  0.5438541769981384 F1 macro =  0.3136517107486725\n","Epoch: 81, Training Loss = 1.2916383743286133\n","Epoch: 82, Training Loss = 1.2905579805374146\n","Epoch: 83, Training Loss = 1.2894891500473022\n","Epoch: 84, Training Loss = 1.2884316444396973\n","Epoch: 85, Training Loss = 1.28738534450531\n","Epoch: 86, Training Loss = 1.2863495349884033\n","Epoch: 87, Training Loss = 1.2853232622146606\n","Epoch: 88, Training Loss = 1.2843068838119507\n","Epoch: 89, Training Loss = 1.2832995653152466\n","Epoch: 90, Training Loss = 1.2823010683059692\n","Accuracy =  0.5223669409751892 F1 weighted =  0.5531129240989685 F1 macro =  0.31923383474349976\n","Epoch: 91, Training Loss = 1.28131103515625\n","Epoch: 92, Training Loss = 1.2803289890289307\n","Epoch: 93, Training Loss = 1.2793548107147217\n","Epoch: 94, Training Loss = 1.278388261795044\n","Epoch: 95, Training Loss = 1.2774289846420288\n","Epoch: 96, Training Loss = 1.276476502418518\n","Epoch: 97, Training Loss = 1.2755310535430908\n","Epoch: 98, Training Loss = 1.2745919227600098\n","Epoch: 99, Training Loss = 1.2736592292785645\n","Epoch: 100, Training Loss = 1.2727326154708862\n","Accuracy =  0.5329714417457581 F1 weighted =  0.5601066946983337 F1 macro =  0.32314544916152954\n","Epoch: 101, Training Loss = 1.2718119621276855\n","Epoch: 102, Training Loss = 1.2708967924118042\n","Epoch: 103, Training Loss = 1.2699873447418213\n","Epoch: 104, Training Loss = 1.2690834999084473\n","Epoch: 105, Training Loss = 1.2681849002838135\n","Epoch: 106, Training Loss = 1.2672914266586304\n","Epoch: 107, Training Loss = 1.2664027214050293\n","Epoch: 108, Training Loss = 1.265519142150879\n","Epoch: 109, Training Loss = 1.2646404504776\n","Epoch: 110, Training Loss = 1.2637661695480347\n","Accuracy =  0.5416905283927917 F1 weighted =  0.5658550262451172 F1 macro =  0.3265096843242645\n","Epoch: 111, Training Loss = 1.2628966569900513\n","Epoch: 112, Training Loss = 1.2620315551757812\n","Epoch: 113, Training Loss = 1.261170506477356\n","Epoch: 114, Training Loss = 1.2603142261505127\n","Epoch: 115, Training Loss = 1.259461760520935\n","Epoch: 116, Training Loss = 1.2586134672164917\n","Epoch: 117, Training Loss = 1.2577694654464722\n","Epoch: 118, Training Loss = 1.2569291591644287\n","Epoch: 119, Training Loss = 1.25609290599823\n","Epoch: 120, Training Loss = 1.2552602291107178\n","Accuracy =  0.5481936931610107 F1 weighted =  0.5698383450508118 F1 macro =  0.3278670907020569\n","Epoch: 121, Training Loss = 1.2544316053390503\n","Epoch: 122, Training Loss = 1.2536065578460693\n","Epoch: 123, Training Loss = 1.252785086631775\n","Epoch: 124, Training Loss = 1.2519673109054565\n","Epoch: 125, Training Loss = 1.2511528730392456\n","Epoch: 126, Training Loss = 1.2503422498703003\n","Epoch: 127, Training Loss = 1.2495348453521729\n","Epoch: 128, Training Loss = 1.2487305402755737\n","Epoch: 129, Training Loss = 1.2479299306869507\n","Epoch: 130, Training Loss = 1.2471323013305664\n","Accuracy =  0.5543609261512756 F1 weighted =  0.5736819505691528 F1 macro =  0.3294157087802887\n","Epoch: 131, Training Loss = 1.246337890625\n","Epoch: 132, Training Loss = 1.2455466985702515\n","Epoch: 133, Training Loss = 1.2447586059570312\n","Epoch: 134, Training Loss = 1.2439734935760498\n","Epoch: 135, Training Loss = 1.2431915998458862\n","Epoch: 136, Training Loss = 1.2424126863479614\n","Epoch: 137, Training Loss = 1.2416365146636963\n","Epoch: 138, Training Loss = 1.24086332321167\n","Epoch: 139, Training Loss = 1.2400929927825928\n","Epoch: 140, Training Loss = 1.2393255233764648\n","Accuracy =  0.5602005124092102 F1 weighted =  0.5773517489433289 F1 macro =  0.33075597882270813\n","Epoch: 141, Training Loss = 1.2385607957839966\n","Epoch: 142, Training Loss = 1.2377986907958984\n","Epoch: 143, Training Loss = 1.237039566040039\n","Epoch: 144, Training Loss = 1.2362827062606812\n","Epoch: 145, Training Loss = 1.235528826713562\n","Epoch: 146, Training Loss = 1.2347774505615234\n","Epoch: 147, Training Loss = 1.2340285778045654\n","Epoch: 148, Training Loss = 1.2332823276519775\n","Epoch: 149, Training Loss = 1.2325385808944702\n","Epoch: 150, Training Loss = 1.2317970991134644\n","Accuracy =  0.5653541684150696 F1 weighted =  0.5804280638694763 F1 macro =  0.33193087577819824\n","Epoch: 151, Training Loss = 1.231058120727539\n","Epoch: 152, Training Loss = 1.2303216457366943\n","Epoch: 153, Training Loss = 1.2295875549316406\n","Epoch: 154, Training Loss = 1.2288556098937988\n","Epoch: 155, Training Loss = 1.228126049041748\n","Epoch: 156, Training Loss = 1.2273986339569092\n","Epoch: 157, Training Loss = 1.2266736030578613\n","Epoch: 158, Training Loss = 1.2259507179260254\n","Epoch: 159, Training Loss = 1.2252299785614014\n","Epoch: 160, Training Loss = 1.2245116233825684\n","Accuracy =  0.5698941946029663 F1 weighted =  0.5829954743385315 F1 macro =  0.33234336972236633\n","Epoch: 161, Training Loss = 1.2237951755523682\n","Epoch: 162, Training Loss = 1.223081111907959\n","Epoch: 163, Training Loss = 1.222368836402893\n","Epoch: 164, Training Loss = 1.221658706665039\n","Epoch: 165, Training Loss = 1.2209504842758179\n","Epoch: 166, Training Loss = 1.2202445268630981\n","Epoch: 167, Training Loss = 1.2195403575897217\n","Epoch: 168, Training Loss = 1.2188382148742676\n","Epoch: 169, Training Loss = 1.2181377410888672\n","Epoch: 170, Training Loss = 1.2174394130706787\n","Accuracy =  0.5743398070335388 F1 weighted =  0.58548903465271 F1 macro =  0.3327265977859497\n","Epoch: 171, Training Loss = 1.216742992401123\n","Epoch: 172, Training Loss = 1.2160483598709106\n","Epoch: 173, Training Loss = 1.215355634689331\n","Epoch: 174, Training Loss = 1.2146645784378052\n","Epoch: 175, Training Loss = 1.2139755487442017\n","Epoch: 176, Training Loss = 1.2132879495620728\n","Epoch: 177, Training Loss = 1.2126023769378662\n","Epoch: 178, Training Loss = 1.211918592453003\n","Epoch: 179, Training Loss = 1.2112362384796143\n","Epoch: 180, Training Loss = 1.210555911064148\n","Accuracy =  0.5784522294998169 F1 weighted =  0.5876424312591553 F1 macro =  0.3326221704483032\n","Epoch: 181, Training Loss = 1.2098770141601562\n","Epoch: 182, Training Loss = 1.2091999053955078\n","Epoch: 183, Training Loss = 1.208524465560913\n","Epoch: 184, Training Loss = 1.207850456237793\n","Epoch: 185, Training Loss = 1.2071781158447266\n","Epoch: 186, Training Loss = 1.2065075635910034\n","Epoch: 187, Training Loss = 1.2058383226394653\n","Epoch: 188, Training Loss = 1.2051708698272705\n","Epoch: 189, Training Loss = 1.2045048475265503\n","Epoch: 190, Training Loss = 1.2038403749465942\n","Accuracy =  0.582439661026001 F1 weighted =  0.5897141695022583 F1 macro =  0.3327274024486542\n","Epoch: 191, Training Loss = 1.2031772136688232\n","Epoch: 192, Training Loss = 1.202515721321106\n","Epoch: 193, Training Loss = 1.2018557786941528\n","Epoch: 194, Training Loss = 1.2011971473693848\n","Epoch: 195, Training Loss = 1.2005401849746704\n","Epoch: 196, Training Loss = 1.1998844146728516\n","Epoch: 197, Training Loss = 1.1992303133010864\n","Epoch: 198, Training Loss = 1.1985774040222168\n","Epoch: 199, Training Loss = 1.1979258060455322\n","Epoch: 200, Training Loss = 1.1972758769989014\n","Accuracy =  0.5858606696128845 F1 weighted =  0.5913194417953491 F1 macro =  0.33249813318252563\n","Epoch: 201, Training Loss = 1.1966272592544556\n","Epoch: 202, Training Loss = 1.1959800720214844\n","Epoch: 203, Training Loss = 1.1953339576721191\n","Epoch: 204, Training Loss = 1.1946892738342285\n","Epoch: 205, Training Loss = 1.1940460205078125\n","Epoch: 206, Training Loss = 1.193403959274292\n","Epoch: 207, Training Loss = 1.1927632093429565\n","Epoch: 208, Training Loss = 1.1921238899230957\n","Epoch: 209, Training Loss = 1.1914857625961304\n","Epoch: 210, Training Loss = 1.1908488273620605\n","Accuracy =  0.5896120667457581 F1 weighted =  0.5931863188743591 F1 macro =  0.3323977291584015\n","Epoch: 211, Training Loss = 1.1902132034301758\n","Epoch: 212, Training Loss = 1.1895787715911865\n","Epoch: 213, Training Loss = 1.1889456510543823\n","Epoch: 214, Training Loss = 1.1883137226104736\n","Epoch: 215, Training Loss = 1.18768310546875\n","Epoch: 216, Training Loss = 1.1870536804199219\n","Epoch: 217, Training Loss = 1.1864254474639893\n","Epoch: 218, Training Loss = 1.1857984066009521\n","Epoch: 219, Training Loss = 1.185172438621521\n","Epoch: 220, Training Loss = 1.1845476627349854\n","Accuracy =  0.5932302474975586 F1 weighted =  0.5948160886764526 F1 macro =  0.33180171251296997\n","Epoch: 221, Training Loss = 1.1839241981506348\n","Epoch: 222, Training Loss = 1.1833018064498901\n","Epoch: 223, Training Loss = 1.1826804876327515\n","Epoch: 224, Training Loss = 1.1820604801177979\n","Epoch: 225, Training Loss = 1.1814414262771606\n","Epoch: 226, Training Loss = 1.1808236837387085\n","Epoch: 227, Training Loss = 1.1802068948745728\n","Epoch: 228, Training Loss = 1.1795912981033325\n","Epoch: 229, Training Loss = 1.1789767742156982\n","Epoch: 230, Training Loss = 1.1783634424209595\n","Accuracy =  0.5966373085975647 F1 weighted =  0.5963239669799805 F1 macro =  0.3314087986946106\n","Epoch: 231, Training Loss = 1.1777511835098267\n","Epoch: 232, Training Loss = 1.1771398782730103\n","Epoch: 233, Training Loss = 1.1765297651290894\n","Epoch: 234, Training Loss = 1.1759207248687744\n","Epoch: 235, Training Loss = 1.1753127574920654\n","Epoch: 236, Training Loss = 1.1747057437896729\n","Epoch: 237, Training Loss = 1.1740999221801758\n","Epoch: 238, Training Loss = 1.1734952926635742\n","Epoch: 239, Training Loss = 1.1728914976119995\n","Epoch: 240, Training Loss = 1.1722886562347412\n","Accuracy =  0.6002249121665955 F1 weighted =  0.5979827642440796 F1 macro =  0.33122992515563965\n","Epoch: 241, Training Loss = 1.1716870069503784\n","Epoch: 242, Training Loss = 1.171086311340332\n","Epoch: 243, Training Loss = 1.1704866886138916\n","Epoch: 244, Training Loss = 1.1698881387710571\n","Epoch: 245, Training Loss = 1.1692906618118286\n","Epoch: 246, Training Loss = 1.1686939001083374\n","Epoch: 247, Training Loss = 1.1680983304977417\n","Epoch: 248, Training Loss = 1.1675035953521729\n","Epoch: 249, Training Loss = 1.166910171508789\n","Epoch: 250, Training Loss = 1.1663177013397217\n","Accuracy =  0.6038180589675903 F1 weighted =  0.5996304154396057 F1 macro =  0.33110204339027405\n","Epoch: 251, Training Loss = 1.1657261848449707\n","Epoch: 252, Training Loss = 1.165135383605957\n","Epoch: 253, Training Loss = 1.1645457744598389\n","Epoch: 254, Training Loss = 1.1639572381973267\n","Epoch: 255, Training Loss = 1.1633695363998413\n","Epoch: 256, Training Loss = 1.1627827882766724\n","Epoch: 257, Training Loss = 1.162197232246399\n","Epoch: 258, Training Loss = 1.1616122722625732\n","Epoch: 259, Training Loss = 1.161028504371643\n","Epoch: 260, Training Loss = 1.1604458093643188\n","Accuracy =  0.6070863008499146 F1 weighted =  0.6009290814399719 F1 macro =  0.3303590416908264\n","Epoch: 261, Training Loss = 1.159863829612732\n","Epoch: 262, Training Loss = 1.159282922744751\n","Epoch: 263, Training Loss = 1.1587027311325073\n","Epoch: 264, Training Loss = 1.1581238508224487\n","Epoch: 265, Training Loss = 1.1575456857681274\n","Epoch: 266, Training Loss = 1.1569684743881226\n","Epoch: 267, Training Loss = 1.156392216682434\n","Epoch: 268, Training Loss = 1.155816912651062\n","Epoch: 269, Training Loss = 1.155242681503296\n","Epoch: 270, Training Loss = 1.154669165611267\n","Accuracy =  0.6103184819221497 F1 weighted =  0.6021943092346191 F1 macro =  0.3299468159675598\n","Epoch: 271, Training Loss = 1.1540967226028442\n","Epoch: 272, Training Loss = 1.1535251140594482\n","Epoch: 273, Training Loss = 1.1529544591903687\n","Epoch: 274, Training Loss = 1.152384638786316\n","Epoch: 275, Training Loss = 1.1518158912658691\n","Epoch: 276, Training Loss = 1.1512479782104492\n","Epoch: 277, Training Loss = 1.1506808996200562\n","Epoch: 278, Training Loss = 1.150114893913269\n","Epoch: 279, Training Loss = 1.1495497226715088\n","Epoch: 280, Training Loss = 1.1489852666854858\n","Accuracy =  0.6135506629943848 F1 weighted =  0.6034379601478577 F1 macro =  0.32944875955581665\n","Epoch: 281, Training Loss = 1.148422122001648\n","Epoch: 282, Training Loss = 1.1478594541549683\n","Epoch: 283, Training Loss = 1.1472978591918945\n","Epoch: 284, Training Loss = 1.1467370986938477\n","Epoch: 285, Training Loss = 1.1461774110794067\n","Epoch: 286, Training Loss = 1.1456185579299927\n","Epoch: 287, Training Loss = 1.1450605392456055\n","Epoch: 288, Training Loss = 1.1445034742355347\n","Epoch: 289, Training Loss = 1.1439472436904907\n","Epoch: 290, Training Loss = 1.1433918476104736\n","Accuracy =  0.6164968013763428 F1 weighted =  0.6044140458106995 F1 macro =  0.3285825848579407\n","Epoch: 291, Training Loss = 1.142837405204773\n","Epoch: 292, Training Loss = 1.1422837972640991\n","Epoch: 293, Training Loss = 1.1417310237884521\n","Epoch: 294, Training Loss = 1.1411792039871216\n","Epoch: 295, Training Loss = 1.140628457069397\n","Epoch: 296, Training Loss = 1.1400783061981201\n","Epoch: 297, Training Loss = 1.1395292282104492\n","Epoch: 298, Training Loss = 1.1389808654785156\n","Epoch: 299, Training Loss = 1.1384334564208984\n","Epoch: 300, Training Loss = 1.137886881828308\n","Accuracy =  0.6194096803665161 F1 weighted =  0.6053378582000732 F1 macro =  0.32762837409973145\n","Epoch: 301, Training Loss = 1.137341022491455\n","Epoch: 302, Training Loss = 1.1367963552474976\n","Epoch: 303, Training Loss = 1.1362524032592773\n","Epoch: 304, Training Loss = 1.135709285736084\n","Epoch: 305, Training Loss = 1.135167121887207\n","Epoch: 306, Training Loss = 1.134625792503357\n","Epoch: 307, Training Loss = 1.1340854167938232\n","Epoch: 308, Training Loss = 1.1335457563400269\n","Epoch: 309, Training Loss = 1.1330070495605469\n","Epoch: 310, Training Loss = 1.1324690580368042\n","Accuracy =  0.6222031116485596 F1 weighted =  0.6061385273933411 F1 macro =  0.3265067934989929\n","Epoch: 311, Training Loss = 1.1319317817687988\n","Epoch: 312, Training Loss = 1.131395697593689\n","Epoch: 313, Training Loss = 1.130860447883606\n","Epoch: 314, Training Loss = 1.1303260326385498\n","Epoch: 315, Training Loss = 1.1297922134399414\n","Epoch: 316, Training Loss = 1.129259467124939\n","Epoch: 317, Training Loss = 1.128727674484253\n","Epoch: 318, Training Loss = 1.1281965970993042\n","Epoch: 319, Training Loss = 1.1276663541793823\n","Epoch: 320, Training Loss = 1.1271369457244873\n","Accuracy =  0.6250964999198914 F1 weighted =  0.6070785522460938 F1 macro =  0.32566389441490173\n","Epoch: 321, Training Loss = 1.1266084909439087\n","Epoch: 322, Training Loss = 1.1260807514190674\n","Epoch: 323, Training Loss = 1.1255539655685425\n","Epoch: 324, Training Loss = 1.1250278949737549\n","Epoch: 325, Training Loss = 1.1245027780532837\n","Epoch: 326, Training Loss = 1.1239784955978394\n","Epoch: 327, Training Loss = 1.1234551668167114\n","Epoch: 328, Training Loss = 1.1229325532913208\n","Epoch: 329, Training Loss = 1.1224108934402466\n","Epoch: 330, Training Loss = 1.1218898296356201\n","Accuracy =  0.6281370520591736 F1 weighted =  0.6081554889678955 F1 macro =  0.32512930035591125\n","Epoch: 331, Training Loss = 1.12136971950531\n","Epoch: 332, Training Loss = 1.1208504438400269\n","Epoch: 333, Training Loss = 1.12033212184906\n","Epoch: 334, Training Loss = 1.1198145151138306\n","Epoch: 335, Training Loss = 1.119297742843628\n","Epoch: 336, Training Loss = 1.1187819242477417\n","Epoch: 337, Training Loss = 1.1182668209075928\n","Epoch: 338, Training Loss = 1.1177525520324707\n","Epoch: 339, Training Loss = 1.117239236831665\n","Epoch: 340, Training Loss = 1.1167266368865967\n","Accuracy =  0.6309582591056824 F1 weighted =  0.6090101599693298 F1 macro =  0.32418307662010193\n","Epoch: 341, Training Loss = 1.1162148714065552\n","Epoch: 342, Training Loss = 1.11570405960083\n","Epoch: 343, Training Loss = 1.1151939630508423\n","Epoch: 344, Training Loss = 1.1146847009658813\n","Epoch: 345, Training Loss = 1.1141761541366577\n","Epoch: 346, Training Loss = 1.1136685609817505\n","Epoch: 347, Training Loss = 1.1131618022918701\n","Epoch: 348, Training Loss = 1.1126558780670166\n","Epoch: 349, Training Loss = 1.11215078830719\n","Epoch: 350, Training Loss = 1.1116464138031006\n","Accuracy =  0.6334046125411987 F1 weighted =  0.6095743775367737 F1 macro =  0.32297220826148987\n","Epoch: 351, Training Loss = 1.1111429929733276\n","Epoch: 352, Training Loss = 1.110640287399292\n","Epoch: 353, Training Loss = 1.1101385354995728\n","Epoch: 354, Training Loss = 1.1096373796463013\n","Epoch: 355, Training Loss = 1.1091371774673462\n","Epoch: 356, Training Loss = 1.108637809753418\n","Epoch: 357, Training Loss = 1.1081393957138062\n","Epoch: 358, Training Loss = 1.107641577720642\n","Epoch: 359, Training Loss = 1.1071445941925049\n","Epoch: 360, Training Loss = 1.1066484451293945\n","Accuracy =  0.6357371211051941 F1 weighted =  0.6100625991821289 F1 macro =  0.3218102753162384\n","Epoch: 361, Training Loss = 1.1061532497406006\n","Epoch: 362, Training Loss = 1.1056586503982544\n","Epoch: 363, Training Loss = 1.105164885520935\n","Epoch: 364, Training Loss = 1.1046721935272217\n","Epoch: 365, Training Loss = 1.104180097579956\n","Epoch: 366, Training Loss = 1.1036889553070068\n","Epoch: 367, Training Loss = 1.1031984090805054\n","Epoch: 368, Training Loss = 1.1027089357376099\n","Epoch: 369, Training Loss = 1.1022201776504517\n","Epoch: 370, Training Loss = 1.1017320156097412\n","Accuracy =  0.6383889317512512 F1 weighted =  0.6107398271560669 F1 macro =  0.3206222653388977\n","Epoch: 371, Training Loss = 1.1012448072433472\n","Epoch: 372, Training Loss = 1.10075843334198\n","Epoch: 373, Training Loss = 1.10027277469635\n","Epoch: 374, Training Loss = 1.0997880697250366\n","Epoch: 375, Training Loss = 1.0993040800094604\n","Epoch: 376, Training Loss = 1.0988209247589111\n","Epoch: 377, Training Loss = 1.0983386039733887\n","Epoch: 378, Training Loss = 1.0978569984436035\n","Epoch: 379, Training Loss = 1.0973761081695557\n","Epoch: 380, Training Loss = 1.0968961715698242\n","Accuracy =  0.6406075358390808 F1 weighted =  0.6110813617706299 F1 macro =  0.3193037509918213\n","Epoch: 381, Training Loss = 1.09641695022583\n","Epoch: 382, Training Loss = 1.0959386825561523\n","Epoch: 383, Training Loss = 1.0954610109329224\n","Epoch: 384, Training Loss = 1.0949842929840088\n","Epoch: 385, Training Loss = 1.0945082902908325\n","Epoch: 386, Training Loss = 1.094033122062683\n","Epoch: 387, Training Loss = 1.0935587882995605\n","Epoch: 388, Training Loss = 1.0930851697921753\n","Epoch: 389, Training Loss = 1.092612385749817\n","Epoch: 390, Training Loss = 1.0921403169631958\n","Accuracy =  0.6430400013923645 F1 weighted =  0.6115976572036743 F1 macro =  0.3182024359703064\n","Epoch: 391, Training Loss = 1.0916690826416016\n","Epoch: 392, Training Loss = 1.0911988019943237\n","Epoch: 393, Training Loss = 1.0907291173934937\n","Epoch: 394, Training Loss = 1.0902602672576904\n","Epoch: 395, Training Loss = 1.089792251586914\n","Epoch: 396, Training Loss = 1.089324951171875\n","Epoch: 397, Training Loss = 1.0888583660125732\n","Epoch: 398, Training Loss = 1.088392734527588\n","Epoch: 399, Training Loss = 1.0879278182983398\n","Epoch: 400, Training Loss = 1.0874637365341187\n","Accuracy =  0.6454835534095764 F1 weighted =  0.6122536063194275 F1 macro =  0.3175210654735565\n","Epoch: 401, Training Loss = 1.0870003700256348\n","Epoch: 402, Training Loss = 1.0865378379821777\n","Epoch: 403, Training Loss = 1.086076021194458\n","Epoch: 404, Training Loss = 1.0856149196624756\n","Epoch: 405, Training Loss = 1.0851547718048096\n","Epoch: 406, Training Loss = 1.0846953392028809\n","Epoch: 407, Training Loss = 1.084236741065979\n","Epoch: 408, Training Loss = 1.0837786197662354\n","Epoch: 409, Training Loss = 1.0833216905593872\n","Epoch: 410, Training Loss = 1.0828652381896973\n","Accuracy =  0.6474800705909729 F1 weighted =  0.6124485731124878 F1 macro =  0.3162879943847656\n","Epoch: 411, Training Loss = 1.0824097394943237\n","Epoch: 412, Training Loss = 1.0819549560546875\n","Epoch: 413, Training Loss = 1.0815010070800781\n","Epoch: 414, Training Loss = 1.0810478925704956\n","Epoch: 415, Training Loss = 1.0805952548980713\n","Epoch: 416, Training Loss = 1.080143690109253\n","Epoch: 417, Training Loss = 1.0796927213668823\n","Epoch: 418, Training Loss = 1.0792425870895386\n","Epoch: 419, Training Loss = 1.0787930488586426\n","Epoch: 420, Training Loss = 1.0783445835113525\n","Accuracy =  0.6490711569786072 F1 weighted =  0.6122561097145081 F1 macro =  0.314594566822052\n","Epoch: 421, Training Loss = 1.0778967142105103\n","Epoch: 422, Training Loss = 1.0774495601654053\n","Epoch: 423, Training Loss = 1.0770033597946167\n","Epoch: 424, Training Loss = 1.0765578746795654\n","Epoch: 425, Training Loss = 1.076112985610962\n","Epoch: 426, Training Loss = 1.0756689310073853\n","Epoch: 427, Training Loss = 1.0752257108688354\n","Epoch: 428, Training Loss = 1.0747833251953125\n","Epoch: 429, Training Loss = 1.0743415355682373\n","Epoch: 430, Training Loss = 1.073900580406189\n","Accuracy =  0.6509260535240173 F1 weighted =  0.6123991012573242 F1 macro =  0.313187837600708\n","Epoch: 431, Training Loss = 1.073460340499878\n","Epoch: 432, Training Loss = 1.0730208158493042\n","Epoch: 433, Training Loss = 1.0725821256637573\n","Epoch: 434, Training Loss = 1.0721441507339478\n","Epoch: 435, Training Loss = 1.071707010269165\n","Epoch: 436, Training Loss = 1.0712705850601196\n","Epoch: 437, Training Loss = 1.0708348751068115\n","Epoch: 438, Training Loss = 1.0703998804092407\n","Epoch: 439, Training Loss = 1.0699657201766968\n","Epoch: 440, Training Loss = 1.0695323944091797\n","Accuracy =  0.6526115536689758 F1 weighted =  0.6122273206710815 F1 macro =  0.31134992837905884\n","Epoch: 441, Training Loss = 1.0690995454788208\n","Epoch: 442, Training Loss = 1.0686676502227783\n","Epoch: 443, Training Loss = 1.0682364702224731\n","Epoch: 444, Training Loss = 1.0678060054779053\n","Epoch: 445, Training Loss = 1.0673762559890747\n","Epoch: 446, Training Loss = 1.066947340965271\n","Epoch: 447, Training Loss = 1.0665191411972046\n","Epoch: 448, Training Loss = 1.0660916566848755\n","Epoch: 449, Training Loss = 1.0656648874282837\n","Epoch: 450, Training Loss = 1.0652390718460083\n","Accuracy =  0.6541054844856262 F1 weighted =  0.612040638923645 F1 macro =  0.30975979566574097\n","Epoch: 451, Training Loss = 1.0648138523101807\n","Epoch: 452, Training Loss = 1.0643893480300903\n","Epoch: 453, Training Loss = 1.0639655590057373\n","Epoch: 454, Training Loss = 1.0635424852371216\n","Epoch: 455, Training Loss = 1.0631202459335327\n","Epoch: 456, Training Loss = 1.0626987218856812\n","Epoch: 457, Training Loss = 1.062277913093567\n","Epoch: 458, Training Loss = 1.06185781955719\n","Epoch: 459, Training Loss = 1.0614384412765503\n","Epoch: 460, Training Loss = 1.0610198974609375\n","Accuracy =  0.655693769454956 F1 weighted =  0.6120089292526245 F1 macro =  0.3083662688732147\n","Epoch: 461, Training Loss = 1.060602068901062\n","Epoch: 462, Training Loss = 1.0601848363876343\n","Epoch: 463, Training Loss = 1.0597684383392334\n","Epoch: 464, Training Loss = 1.0593527555465698\n","Epoch: 465, Training Loss = 1.0589377880096436\n","Epoch: 466, Training Loss = 1.0585235357284546\n","Epoch: 467, Training Loss = 1.0581101179122925\n","Epoch: 468, Training Loss = 1.0576972961425781\n","Epoch: 469, Training Loss = 1.0572853088378906\n","Epoch: 470, Training Loss = 1.0568737983703613\n","Accuracy =  0.6571238040924072 F1 weighted =  0.6118089556694031 F1 macro =  0.3067411184310913\n","Epoch: 471, Training Loss = 1.056463360786438\n","Epoch: 472, Training Loss = 1.0560534000396729\n","Epoch: 473, Training Loss = 1.0556442737579346\n","Epoch: 474, Training Loss = 1.0552358627319336\n","Epoch: 475, Training Loss = 1.05482816696167\n","Epoch: 476, Training Loss = 1.054421067237854\n","Epoch: 477, Training Loss = 1.054014801979065\n","Epoch: 478, Training Loss = 1.0536092519760132\n","Epoch: 479, Training Loss = 1.0532042980194092\n","Epoch: 480, Training Loss = 1.0528002977371216\n","Accuracy =  0.658490002155304 F1 weighted =  0.6115700006484985 F1 macro =  0.30531662702560425\n","Epoch: 481, Training Loss = 1.0523967742919922\n","Epoch: 482, Training Loss = 1.0519942045211792\n","Epoch: 483, Training Loss = 1.0515923500061035\n","Epoch: 484, Training Loss = 1.051190972328186\n","Epoch: 485, Training Loss = 1.0507903099060059\n","Epoch: 486, Training Loss = 1.0503904819488525\n","Epoch: 487, Training Loss = 1.049991250038147\n","Epoch: 488, Training Loss = 1.0495928525924683\n","Epoch: 489, Training Loss = 1.0491951704025269\n","Epoch: 490, Training Loss = 1.0487980842590332\n","Accuracy =  0.6597256660461426 F1 weighted =  0.6112257838249207 F1 macro =  0.30360984802246094\n","Epoch: 491, Training Loss = 1.0484018325805664\n","Epoch: 492, Training Loss = 1.0480061769485474\n","Epoch: 493, Training Loss = 1.0476112365722656\n","Epoch: 494, Training Loss = 1.0472170114517212\n","Epoch: 495, Training Loss = 1.0468236207962036\n","Epoch: 496, Training Loss = 1.0464307069778442\n","Epoch: 497, Training Loss = 1.0460386276245117\n","Epoch: 498, Training Loss = 1.0456470251083374\n","Epoch: 499, Training Loss = 1.0452563762664795\n","Epoch: 500, Training Loss = 1.0448663234710693\n","Accuracy =  0.6609418988227844 F1 weighted =  0.6108987331390381 F1 macro =  0.3020095229148865\n","Epoch: 501, Training Loss = 1.0444769859313965\n","Epoch: 502, Training Loss = 1.0440884828567505\n","Epoch: 503, Training Loss = 1.0437006950378418\n","Epoch: 504, Training Loss = 1.0433133840560913\n","Epoch: 505, Training Loss = 1.0429269075393677\n","Epoch: 506, Training Loss = 1.0425409078598022\n","Epoch: 507, Training Loss = 1.0421557426452637\n","Epoch: 508, Training Loss = 1.0417711734771729\n","Epoch: 509, Training Loss = 1.0413874387741089\n","Epoch: 510, Training Loss = 1.0410041809082031\n","Accuracy =  0.6620914936065674 F1 weighted =  0.6105679273605347 F1 macro =  0.3005739152431488\n","Epoch: 511, Training Loss = 1.0406218767166138\n","Epoch: 512, Training Loss = 1.0402401685714722\n","Epoch: 513, Training Loss = 1.0398591756820679\n","Epoch: 514, Training Loss = 1.0394787788391113\n","Epoch: 515, Training Loss = 1.0390989780426025\n","Epoch: 516, Training Loss = 1.0387200117111206\n","Epoch: 517, Training Loss = 1.038341760635376\n","Epoch: 518, Training Loss = 1.037964105606079\n","Epoch: 519, Training Loss = 1.0375871658325195\n","Epoch: 520, Training Loss = 1.0372108221054077\n","Accuracy =  0.6633104681968689 F1 weighted =  0.6103509664535522 F1 macro =  0.29918372631073\n","Epoch: 521, Training Loss = 1.0368351936340332\n","Epoch: 522, Training Loss = 1.036460280418396\n","Epoch: 523, Training Loss = 1.0360859632492065\n","Epoch: 524, Training Loss = 1.0357123613357544\n","Epoch: 525, Training Loss = 1.0353394746780396\n","Epoch: 526, Training Loss = 1.0349671840667725\n","Epoch: 527, Training Loss = 1.0345957279205322\n","Epoch: 528, Training Loss = 1.0342247486114502\n","Epoch: 529, Training Loss = 1.033854603767395\n","Epoch: 530, Training Loss = 1.033484935760498\n","Accuracy =  0.6644406318664551 F1 weighted =  0.6101579666137695 F1 macro =  0.29819926619529724\n","Epoch: 531, Training Loss = 1.0331159830093384\n","Epoch: 532, Training Loss = 1.0327478647232056\n","Epoch: 533, Training Loss = 1.0323803424835205\n","Epoch: 534, Training Loss = 1.0320132970809937\n","Epoch: 535, Training Loss = 1.0316472053527832\n","Epoch: 536, Training Loss = 1.0312817096710205\n","Epoch: 537, Training Loss = 1.0309165716171265\n","Epoch: 538, Training Loss = 1.0305523872375488\n","Epoch: 539, Training Loss = 1.030188798904419\n","Epoch: 540, Training Loss = 1.0298259258270264\n","Accuracy =  0.6654513478279114 F1 weighted =  0.6097474098205566 F1 macro =  0.29662466049194336\n","Epoch: 541, Training Loss = 1.0294636487960815\n","Epoch: 542, Training Loss = 1.029101848602295\n","Epoch: 543, Training Loss = 1.0287411212921143\n","Epoch: 544, Training Loss = 1.0283807516098022\n","Epoch: 545, Training Loss = 1.028020977973938\n","Epoch: 546, Training Loss = 1.0276620388031006\n","Epoch: 547, Training Loss = 1.027303695678711\n","Epoch: 548, Training Loss = 1.0269461870193481\n","Epoch: 549, Training Loss = 1.026589035987854\n","Epoch: 550, Training Loss = 1.0262324810028076\n","Accuracy =  0.6663510203361511 F1 weighted =  0.6093354225158691 F1 macro =  0.29524824023246765\n","Epoch: 551, Training Loss = 1.0258768796920776\n","Epoch: 552, Training Loss = 1.0255217552185059\n","Epoch: 553, Training Loss = 1.0251673460006714\n","Epoch: 554, Training Loss = 1.0248135328292847\n","Epoch: 555, Training Loss = 1.0244603157043457\n","Epoch: 556, Training Loss = 1.024107813835144\n","Epoch: 557, Training Loss = 1.0237557888031006\n","Epoch: 558, Training Loss = 1.023404836654663\n","Epoch: 559, Training Loss = 1.0230541229248047\n","Epoch: 560, Training Loss = 1.0227042436599731\n","Accuracy =  0.6672146320343018 F1 weighted =  0.6088676452636719 F1 macro =  0.29378658533096313\n","Epoch: 561, Training Loss = 1.0223548412322998\n","Epoch: 562, Training Loss = 1.0220062732696533\n","Epoch: 563, Training Loss = 1.0216580629348755\n","Epoch: 564, Training Loss = 1.021310806274414\n","Epoch: 565, Training Loss = 1.0209639072418213\n","Epoch: 566, Training Loss = 1.0206178426742554\n","Epoch: 567, Training Loss = 1.0202722549438477\n","Epoch: 568, Training Loss = 1.0199275016784668\n","Epoch: 569, Training Loss = 1.0195833444595337\n","Epoch: 570, Training Loss = 1.0192396640777588\n","Accuracy =  0.6678810715675354 F1 weighted =  0.6082731485366821 F1 macro =  0.29217231273651123\n","Epoch: 571, Training Loss = 1.0188966989517212\n","Epoch: 572, Training Loss = 1.0185543298721313\n","Epoch: 573, Training Loss = 1.0182126760482788\n","Epoch: 574, Training Loss = 1.017871618270874\n","Epoch: 575, Training Loss = 1.0175310373306274\n","Epoch: 576, Training Loss = 1.0171911716461182\n","Epoch: 577, Training Loss = 1.0168519020080566\n","Epoch: 578, Training Loss = 1.0165133476257324\n","Epoch: 579, Training Loss = 1.0161755084991455\n","Epoch: 580, Training Loss = 1.0158381462097168\n","Accuracy =  0.6686168909072876 F1 weighted =  0.6078156232833862 F1 macro =  0.29071763157844543\n","Epoch: 581, Training Loss = 1.0155013799667358\n","Epoch: 582, Training Loss = 1.0151653289794922\n","Epoch: 583, Training Loss = 1.0148298740386963\n","Epoch: 584, Training Loss = 1.0144950151443481\n","Epoch: 585, Training Loss = 1.0141607522964478\n","Epoch: 586, Training Loss = 1.0138270854949951\n","Epoch: 587, Training Loss = 1.0134940147399902\n","Epoch: 588, Training Loss = 1.0131616592407227\n","Epoch: 589, Training Loss = 1.0128297805786133\n","Epoch: 590, Training Loss = 1.0124986171722412\n","Accuracy =  0.6694138050079346 F1 weighted =  0.6074947118759155 F1 macro =  0.2896742820739746\n","Epoch: 591, Training Loss = 1.0121681690216064\n","Epoch: 592, Training Loss = 1.0118381977081299\n","Epoch: 593, Training Loss = 1.011508822441101\n","Epoch: 594, Training Loss = 1.01118004322052\n","Epoch: 595, Training Loss = 1.0108518600463867\n","Epoch: 596, Training Loss = 1.0105243921279907\n","Epoch: 597, Training Loss = 1.010197401046753\n","Epoch: 598, Training Loss = 1.0098711252212524\n","Epoch: 599, Training Loss = 1.0095454454421997\n","Epoch: 600, Training Loss = 1.0092202425003052\n","Accuracy =  0.6701746582984924 F1 weighted =  0.6071546673774719 F1 macro =  0.2886432409286499\n","Epoch: 601, Training Loss = 1.0088956356048584\n","Epoch: 602, Training Loss = 1.0085718631744385\n","Epoch: 603, Training Loss = 1.0082484483718872\n","Epoch: 604, Training Loss = 1.0079257488250732\n","Epoch: 605, Training Loss = 1.0076037645339966\n","Epoch: 606, Training Loss = 1.0072821378707886\n","Epoch: 607, Training Loss = 1.0069612264633179\n","Epoch: 608, Training Loss = 1.006640911102295\n","Epoch: 609, Training Loss = 1.0063211917877197\n","Epoch: 610, Training Loss = 1.0060020685195923\n","Accuracy =  0.6708022356033325 F1 weighted =  0.606656014919281 F1 macro =  0.28730326890945435\n","Epoch: 611, Training Loss = 1.005683422088623\n","Epoch: 612, Training Loss = 1.0053654909133911\n","Epoch: 613, Training Loss = 1.0050480365753174\n","Epoch: 614, Training Loss = 1.004731297492981\n","Epoch: 615, Training Loss = 1.0044151544570923\n","Epoch: 616, Training Loss = 1.0040994882583618\n","Epoch: 617, Training Loss = 1.003784418106079\n","Epoch: 618, Training Loss = 1.0034700632095337\n","Epoch: 619, Training Loss = 1.0031561851501465\n","Epoch: 620, Training Loss = 1.002842903137207\n","Accuracy =  0.6715491414070129 F1 weighted =  0.6063008308410645 F1 macro =  0.28614214062690735\n","Epoch: 621, Training Loss = 1.0025302171707153\n","Epoch: 622, Training Loss = 1.002218246459961\n","Epoch: 623, Training Loss = 1.0019068717956543\n","Epoch: 624, Training Loss = 1.0015957355499268\n","Epoch: 625, Training Loss = 1.001285433769226\n","Epoch: 626, Training Loss = 1.000975489616394\n","Epoch: 627, Training Loss = 1.0006663799285889\n","Epoch: 628, Training Loss = 1.000357747077942\n","Epoch: 629, Training Loss = 1.0000497102737427\n","Epoch: 630, Training Loss = 0.9997422695159912\n","Accuracy =  0.6722405552864075 F1 weighted =  0.6058205366134644 F1 macro =  0.2847636640071869\n","Epoch: 631, Training Loss = 0.9994352459907532\n","Epoch: 632, Training Loss = 0.9991289377212524\n","Epoch: 633, Training Loss = 0.9988231658935547\n","Epoch: 634, Training Loss = 0.9985180497169495\n","Epoch: 635, Training Loss = 0.998213529586792\n","Epoch: 636, Training Loss = 0.997909426689148\n","Epoch: 637, Training Loss = 0.9976058602333069\n","Epoch: 638, Training Loss = 0.9973029494285583\n","Epoch: 639, Training Loss = 0.9970007538795471\n","Epoch: 640, Training Loss = 0.9966988563537598\n","Accuracy =  0.6727931499481201 F1 weighted =  0.6052689552307129 F1 macro =  0.28337961435317993\n","Epoch: 641, Training Loss = 0.9963976740837097\n","Epoch: 642, Training Loss = 0.9960970878601074\n","Epoch: 643, Training Loss = 0.9957969188690186\n","Epoch: 644, Training Loss = 0.9954972863197327\n","Epoch: 645, Training Loss = 0.9951984882354736\n","Epoch: 646, Training Loss = 0.9949000477790833\n","Epoch: 647, Training Loss = 0.9946022629737854\n","Epoch: 648, Training Loss = 0.994304895401001\n","Epoch: 649, Training Loss = 0.9940080642700195\n","Epoch: 650, Training Loss = 0.9937120079994202\n","Accuracy =  0.673356831073761 F1 weighted =  0.6047458052635193 F1 macro =  0.28223130106925964\n","Epoch: 651, Training Loss = 0.9934164881706238\n","Epoch: 652, Training Loss = 0.9931213855743408\n","Epoch: 653, Training Loss = 0.9928268194198608\n","Epoch: 654, Training Loss = 0.9925328493118286\n","Epoch: 655, Training Loss = 0.9922394156455994\n","Epoch: 656, Training Loss = 0.9919465780258179\n","Epoch: 657, Training Loss = 0.9916542172431946\n","Epoch: 658, Training Loss = 0.9913625717163086\n","Epoch: 659, Training Loss = 0.991071343421936\n","Epoch: 660, Training Loss = 0.9907805919647217\n","Accuracy =  0.673978865146637 F1 weighted =  0.6043481230735779 F1 macro =  0.2810973525047302\n","Epoch: 661, Training Loss = 0.9904905557632446\n","Epoch: 662, Training Loss = 0.9902010560035706\n","Epoch: 663, Training Loss = 0.9899120330810547\n","Epoch: 664, Training Loss = 0.9896235466003418\n","Epoch: 665, Training Loss = 0.9893355965614319\n","Epoch: 666, Training Loss = 0.989048182964325\n","Epoch: 667, Training Loss = 0.9887614250183105\n","Epoch: 668, Training Loss = 0.9884750247001648\n","Epoch: 669, Training Loss = 0.9881892204284668\n","Epoch: 670, Training Loss = 0.9879040718078613\n","Accuracy =  0.6743897795677185 F1 weighted =  0.6038001775741577 F1 macro =  0.2799343168735504\n","Epoch: 671, Training Loss = 0.9876194596290588\n","Epoch: 672, Training Loss = 0.987335205078125\n","Epoch: 673, Training Loss = 0.9870516061782837\n","Epoch: 674, Training Loss = 0.9867684245109558\n","Epoch: 675, Training Loss = 0.9864859580993652\n","Epoch: 676, Training Loss = 0.9862039685249329\n","Epoch: 677, Training Loss = 0.9859224557876587\n","Epoch: 678, Training Loss = 0.9856414794921875\n","Epoch: 679, Training Loss = 0.9853610396385193\n","Epoch: 680, Training Loss = 0.985081136226654\n","Accuracy =  0.6747757792472839 F1 weighted =  0.6032134294509888 F1 macro =  0.27871984243392944\n","Epoch: 681, Training Loss = 0.9848017692565918\n","Epoch: 682, Training Loss = 0.9845229387283325\n","Epoch: 683, Training Loss = 0.9842445850372314\n","Epoch: 684, Training Loss = 0.9839668869972229\n","Epoch: 685, Training Loss = 0.983689546585083\n","Epoch: 686, Training Loss = 0.9834129214286804\n","Epoch: 687, Training Loss = 0.9831366539001465\n","Epoch: 688, Training Loss = 0.9828609824180603\n","Epoch: 689, Training Loss = 0.9825859069824219\n","Epoch: 690, Training Loss = 0.9823112487792969\n","Accuracy =  0.6752284169197083 F1 weighted =  0.6027535200119019 F1 macro =  0.27771061658859253\n","Epoch: 691, Training Loss = 0.9820370078086853\n","Epoch: 692, Training Loss = 0.9817634224891663\n","Epoch: 693, Training Loss = 0.9814903140068054\n","Epoch: 694, Training Loss = 0.9812177419662476\n","Epoch: 695, Training Loss = 0.9809457659721375\n","Epoch: 696, Training Loss = 0.980674147605896\n","Epoch: 697, Training Loss = 0.9804033041000366\n","Epoch: 698, Training Loss = 0.9801326394081116\n","Epoch: 699, Training Loss = 0.979862630367279\n","Epoch: 700, Training Loss = 0.9795931577682495\n","Accuracy =  0.6755949258804321 F1 weighted =  0.6022335886955261 F1 macro =  0.2766232192516327\n","Epoch: 701, Training Loss = 0.9793241620063782\n","Epoch: 702, Training Loss = 0.979055643081665\n","Epoch: 703, Training Loss = 0.9787877202033997\n","Epoch: 704, Training Loss = 0.9785203337669373\n","Epoch: 705, Training Loss = 0.9782533049583435\n","Epoch: 706, Training Loss = 0.9779869914054871\n","Epoch: 707, Training Loss = 0.9777210354804993\n","Epoch: 708, Training Loss = 0.9774556159973145\n","Epoch: 709, Training Loss = 0.9771906733512878\n","Epoch: 710, Training Loss = 0.9769262671470642\n","Accuracy =  0.6760891675949097 F1 weighted =  0.6018621325492859 F1 macro =  0.2757588028907776\n","Epoch: 711, Training Loss = 0.9766623377799988\n","Epoch: 712, Training Loss = 0.9763989448547363\n","Epoch: 713, Training Loss = 0.9761360287666321\n","Epoch: 714, Training Loss = 0.9758737087249756\n","Epoch: 715, Training Loss = 0.9756117463111877\n","Epoch: 716, Training Loss = 0.9753503799438477\n","Epoch: 717, Training Loss = 0.9750893712043762\n","Epoch: 718, Training Loss = 0.9748290181159973\n","Epoch: 719, Training Loss = 0.9745692014694214\n","Epoch: 720, Training Loss = 0.9743096828460693\n","Accuracy =  0.6764085292816162 F1 weighted =  0.6012946963310242 F1 macro =  0.2746492922306061\n","Epoch: 721, Training Loss = 0.974050760269165\n","Epoch: 722, Training Loss = 0.9737922549247742\n","Epoch: 723, Training Loss = 0.9735344648361206\n","Epoch: 724, Training Loss = 0.9732769131660461\n","Epoch: 725, Training Loss = 0.9730198979377747\n","Epoch: 726, Training Loss = 0.9727633595466614\n","Epoch: 727, Training Loss = 0.9725075364112854\n","Epoch: 728, Training Loss = 0.9722521305084229\n","Epoch: 729, Training Loss = 0.9719970226287842\n","Epoch: 730, Training Loss = 0.9717424511909485\n","Accuracy =  0.676769495010376 F1 weighted =  0.6008929014205933 F1 macro =  0.27384454011917114\n","Epoch: 731, Training Loss = 0.9714885354042053\n","Epoch: 732, Training Loss = 0.9712349772453308\n","Epoch: 733, Training Loss = 0.9709818959236145\n","Epoch: 734, Training Loss = 0.9707292914390564\n","Epoch: 735, Training Loss = 0.9704772233963013\n","Epoch: 736, Training Loss = 0.9702255725860596\n","Epoch: 737, Training Loss = 0.9699743986129761\n","Epoch: 738, Training Loss = 0.9697238206863403\n","Epoch: 739, Training Loss = 0.9694736003875732\n","Epoch: 740, Training Loss = 0.9692239165306091\n","Accuracy =  0.6770749688148499 F1 weighted =  0.6003576517105103 F1 macro =  0.27274903655052185\n","Epoch: 741, Training Loss = 0.9689747095108032\n","Epoch: 742, Training Loss = 0.9687259793281555\n","Epoch: 743, Training Loss = 0.9684776663780212\n","Epoch: 744, Training Loss = 0.9682298898696899\n","Epoch: 745, Training Loss = 0.9679826498031616\n","Epoch: 746, Training Loss = 0.9677358269691467\n","Epoch: 747, Training Loss = 0.9674893617630005\n","Epoch: 748, Training Loss = 0.9672434329986572\n","Epoch: 749, Training Loss = 0.9669980406761169\n","Epoch: 750, Training Loss = 0.9667531847953796\n","Accuracy =  0.6774803400039673 F1 weighted =  0.5999736785888672 F1 macro =  0.2718409299850464\n","Epoch: 751, Training Loss = 0.9665085673332214\n","Epoch: 752, Training Loss = 0.9662644863128662\n","Epoch: 753, Training Loss = 0.9660210013389587\n","Epoch: 754, Training Loss = 0.9657779335975647\n","Epoch: 755, Training Loss = 0.9655353426933289\n","Epoch: 756, Training Loss = 0.9652931690216064\n","Epoch: 757, Training Loss = 0.9650514125823975\n","Epoch: 758, Training Loss = 0.9648100733757019\n","Epoch: 759, Training Loss = 0.9645694494247437\n","Epoch: 760, Training Loss = 0.9643291234970093\n","Accuracy =  0.6777913570404053 F1 weighted =  0.5995083451271057 F1 macro =  0.27090010046958923\n","Epoch: 761, Training Loss = 0.9640892744064331\n","Epoch: 762, Training Loss = 0.9638500213623047\n","Epoch: 763, Training Loss = 0.9636109471321106\n","Epoch: 764, Training Loss = 0.9633725881576538\n","Epoch: 765, Training Loss = 0.9631344676017761\n","Epoch: 766, Training Loss = 0.9628968834877014\n","Epoch: 767, Training Loss = 0.9626597166061401\n","Epoch: 768, Training Loss = 0.9624232053756714\n","Epoch: 769, Training Loss = 0.9621869921684265\n","Epoch: 770, Training Loss = 0.9619513154029846\n","Accuracy =  0.678193986415863 F1 weighted =  0.5991038084030151 F1 macro =  0.26996544003486633\n","Epoch: 771, Training Loss = 0.9617159366607666\n","Epoch: 772, Training Loss = 0.9614811539649963\n","Epoch: 773, Training Loss = 0.9612467885017395\n","Epoch: 774, Training Loss = 0.9610127806663513\n","Epoch: 775, Training Loss = 0.9607793688774109\n","Epoch: 776, Training Loss = 0.9605463743209839\n","Epoch: 777, Training Loss = 0.9603137969970703\n","Epoch: 778, Training Loss = 0.9600816369056702\n","Epoch: 779, Training Loss = 0.959850013256073\n","Epoch: 780, Training Loss = 0.9596186876296997\n","Accuracy =  0.6784855723381042 F1 weighted =  0.5986185073852539 F1 macro =  0.26896053552627563\n","Epoch: 781, Training Loss = 0.9593878388404846\n","Epoch: 782, Training Loss = 0.9591575264930725\n","Epoch: 783, Training Loss = 0.9589276909828186\n","Epoch: 784, Training Loss = 0.9586981534957886\n","Epoch: 785, Training Loss = 0.9584691524505615\n","Epoch: 786, Training Loss = 0.9582405090332031\n","Epoch: 787, Training Loss = 0.9580124020576477\n","Epoch: 788, Training Loss = 0.9577847719192505\n","Epoch: 789, Training Loss = 0.9575574994087219\n","Epoch: 790, Training Loss = 0.9573307037353516\n","Accuracy =  0.6788381934165955 F1 weighted =  0.5982295274734497 F1 macro =  0.26808786392211914\n","Epoch: 791, Training Loss = 0.9571042060852051\n","Epoch: 792, Training Loss = 0.9568782448768616\n","Epoch: 793, Training Loss = 0.9566527009010315\n","Epoch: 794, Training Loss = 0.9564277529716492\n","Epoch: 795, Training Loss = 0.956203043460846\n","Epoch: 796, Training Loss = 0.9559788107872009\n","Epoch: 797, Training Loss = 0.9557550549507141\n","Epoch: 798, Training Loss = 0.9555315971374512\n","Epoch: 799, Training Loss = 0.955308735370636\n","Epoch: 800, Training Loss = 0.9550861716270447\n","Accuracy =  0.6790936589241028 F1 weighted =  0.5977005958557129 F1 macro =  0.26703912019729614\n","Epoch: 801, Training Loss = 0.9548640847206116\n","Epoch: 802, Training Loss = 0.9546425938606262\n","Epoch: 803, Training Loss = 0.9544212818145752\n","Epoch: 804, Training Loss = 0.9542005658149719\n","Epoch: 805, Training Loss = 0.9539802074432373\n","Epoch: 806, Training Loss = 0.9537602663040161\n","Epoch: 807, Training Loss = 0.9535406827926636\n","Epoch: 808, Training Loss = 0.953321635723114\n","Epoch: 809, Training Loss = 0.9531030058860779\n","Epoch: 810, Training Loss = 0.9528847336769104\n","Accuracy =  0.6792935729026794 F1 weighted =  0.5972405672073364 F1 macro =  0.2661857008934021\n","Epoch: 811, Training Loss = 0.9526669979095459\n","Epoch: 812, Training Loss = 0.9524495601654053\n","Epoch: 813, Training Loss = 0.9522325992584229\n","Epoch: 814, Training Loss = 0.9520159959793091\n","Epoch: 815, Training Loss = 0.9517999291419983\n","Epoch: 816, Training Loss = 0.9515842199325562\n","Epoch: 817, Training Loss = 0.951369047164917\n","Epoch: 818, Training Loss = 0.9511540532112122\n","Epoch: 819, Training Loss = 0.9509395360946655\n","Epoch: 820, Training Loss = 0.9507255554199219\n","Accuracy =  0.6795990467071533 F1 weighted =  0.5968610644340515 F1 macro =  0.26539182662963867\n","Epoch: 821, Training Loss = 0.9505119323730469\n","Epoch: 822, Training Loss = 0.9502986073493958\n","Epoch: 823, Training Loss = 0.9500859379768372\n","Epoch: 824, Training Loss = 0.9498733878135681\n","Epoch: 825, Training Loss = 0.9496614933013916\n","Epoch: 826, Training Loss = 0.9494499564170837\n","Epoch: 827, Training Loss = 0.9492387771606445\n","Epoch: 828, Training Loss = 0.9490278959274292\n","Epoch: 829, Training Loss = 0.9488175511360168\n","Epoch: 830, Training Loss = 0.9486076235771179\n","Accuracy =  0.6798100471496582 F1 weighted =  0.5964040160179138 F1 macro =  0.26450395584106445\n","Epoch: 831, Training Loss = 0.9483979940414429\n","Epoch: 832, Training Loss = 0.9481889009475708\n","Epoch: 833, Training Loss = 0.9479802846908569\n","Epoch: 834, Training Loss = 0.9477718472480774\n","Epoch: 835, Training Loss = 0.9475640058517456\n","Epoch: 836, Training Loss = 0.9473564624786377\n","Epoch: 837, Training Loss = 0.9471493363380432\n","Epoch: 838, Training Loss = 0.9469426274299622\n","Epoch: 839, Training Loss = 0.9467363357543945\n","Epoch: 840, Training Loss = 0.9465303421020508\n","Accuracy =  0.6800766587257385 F1 weighted =  0.5960981845855713 F1 macro =  0.26388898491859436\n","Epoch: 841, Training Loss = 0.94632488489151\n","Epoch: 842, Training Loss = 0.9461197853088379\n","Epoch: 843, Training Loss = 0.9459149837493896\n","Epoch: 844, Training Loss = 0.9457108378410339\n","Epoch: 845, Training Loss = 0.9455068707466125\n","Epoch: 846, Training Loss = 0.9453033804893494\n","Epoch: 847, Training Loss = 0.9451002478599548\n","Epoch: 848, Training Loss = 0.9448973536491394\n","Epoch: 849, Training Loss = 0.9446950554847717\n","Epoch: 850, Training Loss = 0.9444931149482727\n","Accuracy =  0.6803126931190491 F1 weighted =  0.595718502998352 F1 macro =  0.2631745934486389\n","Epoch: 851, Training Loss = 0.9442915916442871\n","Epoch: 852, Training Loss = 0.9440903663635254\n","Epoch: 853, Training Loss = 0.9438894987106323\n","Epoch: 854, Training Loss = 0.9436891078948975\n","Epoch: 855, Training Loss = 0.9434891939163208\n","Epoch: 856, Training Loss = 0.9432895183563232\n","Epoch: 857, Training Loss = 0.9430903792381287\n","Epoch: 858, Training Loss = 0.9428914785385132\n","Epoch: 859, Training Loss = 0.9426930546760559\n","Epoch: 860, Training Loss = 0.9424949884414673\n","Accuracy =  0.6805209517478943 F1 weighted =  0.595289409160614 F1 macro =  0.2623600661754608\n","Epoch: 861, Training Loss = 0.9422972798347473\n","Epoch: 862, Training Loss = 0.9420999884605408\n","Epoch: 863, Training Loss = 0.9419031143188477\n","Epoch: 864, Training Loss = 0.9417064785957336\n","Epoch: 865, Training Loss = 0.9415103197097778\n","Epoch: 866, Training Loss = 0.9413145184516907\n","Epoch: 867, Training Loss = 0.9411191940307617\n","Epoch: 868, Training Loss = 0.9409242272377014\n","Epoch: 869, Training Loss = 0.9407296180725098\n","Epoch: 870, Training Loss = 0.9405353665351868\n","Accuracy =  0.6807069778442383 F1 weighted =  0.594869077205658 F1 macro =  0.26161429286003113\n","Epoch: 871, Training Loss = 0.9403415322303772\n","Epoch: 872, Training Loss = 0.9401479959487915\n","Epoch: 873, Training Loss = 0.9399548768997192\n","Epoch: 874, Training Loss = 0.9397621154785156\n","Epoch: 875, Training Loss = 0.9395696520805359\n","Epoch: 876, Training Loss = 0.9393777847290039\n","Epoch: 877, Training Loss = 0.9391859769821167\n","Epoch: 878, Training Loss = 0.938994824886322\n","Epoch: 879, Training Loss = 0.9388039112091064\n","Epoch: 880, Training Loss = 0.9386134147644043\n","Accuracy =  0.6808374524116516 F1 weighted =  0.5943560600280762 F1 macro =  0.26071691513061523\n","Epoch: 881, Training Loss = 0.9384233355522156\n","Epoch: 882, Training Loss = 0.938233494758606\n","Epoch: 883, Training Loss = 0.9380441308021545\n","Epoch: 884, Training Loss = 0.937855064868927\n","Epoch: 885, Training Loss = 0.9376664161682129\n","Epoch: 886, Training Loss = 0.9374780654907227\n","Epoch: 887, Training Loss = 0.9372902512550354\n","Epoch: 888, Training Loss = 0.9371026158332825\n","Epoch: 889, Training Loss = 0.936915397644043\n","Epoch: 890, Training Loss = 0.9367285966873169\n","Accuracy =  0.6810624003410339 F1 weighted =  0.5939679741859436 F1 macro =  0.2600158452987671\n","Epoch: 891, Training Loss = 0.9365421533584595\n","Epoch: 892, Training Loss = 0.9363561272621155\n","Epoch: 893, Training Loss = 0.9361703395843506\n","Epoch: 894, Training Loss = 0.9359849691390991\n","Epoch: 895, Training Loss = 0.9357998967170715\n","Epoch: 896, Training Loss = 0.9356152415275574\n","Epoch: 897, Training Loss = 0.9354310631752014\n","Epoch: 898, Training Loss = 0.9352470636367798\n","Epoch: 899, Training Loss = 0.9350634813308716\n","Epoch: 900, Training Loss = 0.934880256652832\n","Accuracy =  0.6812262535095215 F1 weighted =  0.593569815158844 F1 macro =  0.2592960298061371\n","Epoch: 901, Training Loss = 0.9346975088119507\n","Epoch: 902, Training Loss = 0.9345148801803589\n","Epoch: 903, Training Loss = 0.9343327283859253\n","Epoch: 904, Training Loss = 0.9341509938240051\n","Epoch: 905, Training Loss = 0.9339694976806641\n","Epoch: 906, Training Loss = 0.9337884187698364\n","Epoch: 907, Training Loss = 0.9336076974868774\n","Epoch: 908, Training Loss = 0.9334273934364319\n","Epoch: 909, Training Loss = 0.9332471489906311\n","Epoch: 910, Training Loss = 0.9330676198005676\n","Accuracy =  0.6813845038414001 F1 weighted =  0.593146800994873 F1 macro =  0.2584626078605652\n","Epoch: 911, Training Loss = 0.9328882694244385\n","Epoch: 912, Training Loss = 0.9327093362808228\n","Epoch: 913, Training Loss = 0.9325306415557861\n","Epoch: 914, Training Loss = 0.9323523044586182\n","Epoch: 915, Training Loss = 0.9321743845939636\n","Epoch: 916, Training Loss = 0.9319968819618225\n","Epoch: 917, Training Loss = 0.931819498538971\n","Epoch: 918, Training Loss = 0.9316425919532776\n","Epoch: 919, Training Loss = 0.9314661622047424\n","Epoch: 920, Training Loss = 0.9312899112701416\n","Accuracy =  0.6816011071205139 F1 weighted =  0.5928055644035339 F1 macro =  0.2577782869338989\n","Epoch: 921, Training Loss = 0.9311140775680542\n","Epoch: 922, Training Loss = 0.9309384822845459\n","Epoch: 923, Training Loss = 0.930763304233551\n","Epoch: 924, Training Loss = 0.9305885434150696\n","Epoch: 925, Training Loss = 0.9304139018058777\n","Epoch: 926, Training Loss = 0.9302398562431335\n","Epoch: 927, Training Loss = 0.9300659894943237\n","Epoch: 928, Training Loss = 0.9298925399780273\n","Epoch: 929, Training Loss = 0.9297194480895996\n","Epoch: 930, Training Loss = 0.929546594619751\n","Accuracy =  0.6817288398742676 F1 weighted =  0.5923895239830017 F1 macro =  0.2570374011993408\n","Epoch: 931, Training Loss = 0.9293741583824158\n","Epoch: 932, Training Loss = 0.9292020201683044\n","Epoch: 933, Training Loss = 0.9290302991867065\n","Epoch: 934, Training Loss = 0.9288588166236877\n","Epoch: 935, Training Loss = 0.9286876320838928\n","Epoch: 936, Training Loss = 0.9285169243812561\n","Epoch: 937, Training Loss = 0.9283464550971985\n","Epoch: 938, Training Loss = 0.92817622423172\n","Epoch: 939, Training Loss = 0.928006649017334\n","Epoch: 940, Training Loss = 0.927837073802948\n","Accuracy =  0.6818593144416809 F1 weighted =  0.5919789671897888 F1 macro =  0.2563154995441437\n","Epoch: 941, Training Loss = 0.9276679754257202\n","Epoch: 942, Training Loss = 0.9274991750717163\n","Epoch: 943, Training Loss = 0.927330732345581\n","Epoch: 944, Training Loss = 0.9271625280380249\n","Epoch: 945, Training Loss = 0.9269947409629822\n","Epoch: 946, Training Loss = 0.9268273115158081\n","Epoch: 947, Training Loss = 0.9266601204872131\n","Epoch: 948, Training Loss = 0.926493227481842\n","Epoch: 949, Training Loss = 0.9263267517089844\n","Epoch: 950, Training Loss = 0.9261606335639954\n","Accuracy =  0.6819925904273987 F1 weighted =  0.5916324853897095 F1 macro =  0.25573423504829407\n","Epoch: 951, Training Loss = 0.9259947538375854\n","Epoch: 952, Training Loss = 0.925829291343689\n","Epoch: 953, Training Loss = 0.9256641268730164\n","Epoch: 954, Training Loss = 0.9254992604255676\n","Epoch: 955, Training Loss = 0.9253348112106323\n","Epoch: 956, Training Loss = 0.9251704216003418\n","Epoch: 957, Training Loss = 0.925006628036499\n","Epoch: 958, Training Loss = 0.9248429536819458\n","Epoch: 959, Training Loss = 0.9246796369552612\n","Epoch: 960, Training Loss = 0.9245167970657349\n","Accuracy =  0.6821592450141907 F1 weighted =  0.5912438631057739 F1 macro =  0.2550334632396698\n","Epoch: 961, Training Loss = 0.924354076385498\n","Epoch: 962, Training Loss = 0.9241917729377747\n","Epoch: 963, Training Loss = 0.9240298271179199\n","Epoch: 964, Training Loss = 0.9238681793212891\n","Epoch: 965, Training Loss = 0.9237067103385925\n","Epoch: 966, Training Loss = 0.9235457181930542\n","Epoch: 967, Training Loss = 0.9233850240707397\n","Epoch: 968, Training Loss = 0.9232244491577148\n","Epoch: 969, Training Loss = 0.9230643510818481\n","Epoch: 970, Training Loss = 0.9229046106338501\n","Accuracy =  0.6823258399963379 F1 weighted =  0.5908828377723694 F1 macro =  0.25439223647117615\n","Epoch: 971, Training Loss = 0.9227451682090759\n","Epoch: 972, Training Loss = 0.9225860834121704\n","Epoch: 973, Training Loss = 0.922427237033844\n","Epoch: 974, Training Loss = 0.9222686886787415\n","Epoch: 975, Training Loss = 0.9221104383468628\n","Epoch: 976, Training Loss = 0.9219525456428528\n","Epoch: 977, Training Loss = 0.9217948913574219\n","Epoch: 978, Training Loss = 0.9216375350952148\n","Epoch: 979, Training Loss = 0.9214805364608765\n","Epoch: 980, Training Loss = 0.9213238954544067\n","Accuracy =  0.6825063228607178 F1 weighted =  0.5906462669372559 F1 macro =  0.2539154589176178\n","Epoch: 981, Training Loss = 0.9211674928665161\n","Epoch: 982, Training Loss = 0.9210114479064941\n","Epoch: 983, Training Loss = 0.9208556413650513\n","Epoch: 984, Training Loss = 0.9207001328468323\n","Epoch: 985, Training Loss = 0.9205450415611267\n","Epoch: 986, Training Loss = 0.9203901290893555\n","Epoch: 987, Training Loss = 0.9202356338500977\n","Epoch: 988, Training Loss = 0.920081377029419\n","Epoch: 989, Training Loss = 0.9199274778366089\n","Epoch: 990, Training Loss = 0.9197739362716675\n","Accuracy =  0.6826367974281311 F1 weighted =  0.5902858972549438 F1 macro =  0.2532263994216919\n","Epoch: 991, Training Loss = 0.9196203351020813\n","Epoch: 992, Training Loss = 0.9194673895835876\n","Epoch: 993, Training Loss = 0.9193146228790283\n","Epoch: 994, Training Loss = 0.9191621541976929\n","Epoch: 995, Training Loss = 0.9190101027488708\n","Epoch: 996, Training Loss = 0.9188581705093384\n","Epoch: 997, Training Loss = 0.9187065362930298\n","Epoch: 998, Training Loss = 0.9185553193092346\n","Epoch: 999, Training Loss = 0.9184044599533081\n","Epoch: 1000, Training Loss = 0.9182536602020264\n","Accuracy =  0.6827423572540283 F1 weighted =  0.5899255871772766 F1 macro =  0.2525786757469177\n","Epoch: 1001, Training Loss = 0.9181033968925476\n","Epoch: 1002, Training Loss = 0.9179531931877136\n","Epoch: 1003, Training Loss = 0.9178035259246826\n","Epoch: 1004, Training Loss = 0.9176539778709412\n","Epoch: 1005, Training Loss = 0.9175047278404236\n","Epoch: 1006, Training Loss = 0.9173558950424194\n","Epoch: 1007, Training Loss = 0.9172072410583496\n","Epoch: 1008, Training Loss = 0.9170589447021484\n","Epoch: 1009, Training Loss = 0.9169108867645264\n","Epoch: 1010, Training Loss = 0.9167632460594177\n","Accuracy =  0.6828117370605469 F1 weighted =  0.589489221572876 F1 macro =  0.25187569856643677\n","Epoch: 1011, Training Loss = 0.9166157841682434\n","Epoch: 1012, Training Loss = 0.9164685606956482\n","Epoch: 1013, Training Loss = 0.9163217544555664\n","Epoch: 1014, Training Loss = 0.9161750674247742\n","Epoch: 1015, Training Loss = 0.9160288572311401\n","Epoch: 1016, Training Loss = 0.9158827662467957\n","Epoch: 1017, Training Loss = 0.9157371520996094\n","Epoch: 1018, Training Loss = 0.9155915975570679\n","Epoch: 1019, Training Loss = 0.915446400642395\n","Epoch: 1020, Training Loss = 0.9153016209602356\n","Accuracy =  0.6829034090042114 F1 weighted =  0.5891295075416565 F1 macro =  0.2512546181678772\n","Epoch: 1021, Training Loss = 0.9151569604873657\n","Epoch: 1022, Training Loss = 0.9150125980377197\n","Epoch: 1023, Training Loss = 0.9148686528205872\n","Epoch: 1024, Training Loss = 0.9147249460220337\n","Epoch: 1025, Training Loss = 0.9145814180374146\n","Epoch: 1026, Training Loss = 0.9144381880760193\n","Epoch: 1027, Training Loss = 0.9142953753471375\n","Epoch: 1028, Training Loss = 0.9141527414321899\n","Epoch: 1029, Training Loss = 0.9140104055404663\n","Epoch: 1030, Training Loss = 0.9138684272766113\n","Accuracy =  0.683056116104126 F1 weighted =  0.5889179706573486 F1 macro =  0.2507949471473694\n","Epoch: 1031, Training Loss = 0.9137265682220459\n","Epoch: 1032, Training Loss = 0.9135850667953491\n","Epoch: 1033, Training Loss = 0.9134438037872314\n","Epoch: 1034, Training Loss = 0.9133028984069824\n","Epoch: 1035, Training Loss = 0.9131622314453125\n","Epoch: 1036, Training Loss = 0.9130218029022217\n","Epoch: 1037, Training Loss = 0.9128817915916443\n","Epoch: 1038, Training Loss = 0.9127419590950012\n","Epoch: 1039, Training Loss = 0.9126023054122925\n","Epoch: 1040, Training Loss = 0.9124628901481628\n","Accuracy =  0.6831200122833252 F1 weighted =  0.588541567325592 F1 macro =  0.2501974403858185\n","Epoch: 1041, Training Loss = 0.9123238921165466\n","Epoch: 1042, Training Loss = 0.9121851325035095\n","Epoch: 1043, Training Loss = 0.9120467901229858\n","Epoch: 1044, Training Loss = 0.9119084477424622\n","Epoch: 1045, Training Loss = 0.9117705821990967\n","Epoch: 1046, Training Loss = 0.9116328358650208\n","Epoch: 1047, Training Loss = 0.9114955067634583\n","Epoch: 1048, Training Loss = 0.9113582968711853\n","Epoch: 1049, Training Loss = 0.9112215042114258\n","Epoch: 1050, Training Loss = 0.9110849499702454\n","Accuracy =  0.68324214220047 F1 weighted =  0.588278591632843 F1 macro =  0.24973365664482117\n","Epoch: 1051, Training Loss = 0.9109485745429993\n","Epoch: 1052, Training Loss = 0.9108125567436218\n","Epoch: 1053, Training Loss = 0.9106767773628235\n","Epoch: 1054, Training Loss = 0.9105411171913147\n","Epoch: 1055, Training Loss = 0.9104059338569641\n","Epoch: 1056, Training Loss = 0.9102709293365479\n","Epoch: 1057, Training Loss = 0.9101362824440002\n","Epoch: 1058, Training Loss = 0.9100016951560974\n","Epoch: 1059, Training Loss = 0.9098676443099976\n","Epoch: 1060, Training Loss = 0.9097337126731873\n","Accuracy =  0.6834031939506531 F1 weighted =  0.5880787372589111 F1 macro =  0.24936477839946747\n","Epoch: 1061, Training Loss = 0.9095999002456665\n","Epoch: 1062, Training Loss = 0.909466564655304\n","Epoch: 1063, Training Loss = 0.9093334078788757\n","Epoch: 1064, Training Loss = 0.9092006087303162\n","Epoch: 1065, Training Loss = 0.9090679287910461\n","Epoch: 1066, Training Loss = 0.9089354872703552\n","Epoch: 1067, Training Loss = 0.9088032841682434\n","Epoch: 1068, Training Loss = 0.908671498298645\n","Epoch: 1069, Training Loss = 0.9085398316383362\n","Epoch: 1070, Training Loss = 0.908408522605896\n","Accuracy =  0.6834726333618164 F1 weighted =  0.587754487991333 F1 macro =  0.24882961809635162\n","Epoch: 1071, Training Loss = 0.9082775115966797\n","Epoch: 1072, Training Loss = 0.9081466197967529\n","Epoch: 1073, Training Loss = 0.9080160856246948\n","Epoch: 1074, Training Loss = 0.907885730266571\n","Epoch: 1075, Training Loss = 0.9077557325363159\n","Epoch: 1076, Training Loss = 0.9076260328292847\n","Epoch: 1077, Training Loss = 0.907496452331543\n","Epoch: 1078, Training Loss = 0.9073670506477356\n","Epoch: 1079, Training Loss = 0.9072380065917969\n","Epoch: 1080, Training Loss = 0.9071091413497925\n","Accuracy =  0.6835615038871765 F1 weighted =  0.5874972343444824 F1 macro =  0.24841780960559845\n","Epoch: 1081, Training Loss = 0.906980574131012\n","Epoch: 1082, Training Loss = 0.9068524837493896\n","Epoch: 1083, Training Loss = 0.9067243933677673\n","Epoch: 1084, Training Loss = 0.9065966010093689\n","Epoch: 1085, Training Loss = 0.9064691066741943\n","Epoch: 1086, Training Loss = 0.9063418507575989\n","Epoch: 1087, Training Loss = 0.906214714050293\n","Epoch: 1088, Training Loss = 0.9060879349708557\n","Epoch: 1089, Training Loss = 0.9059615135192871\n","Epoch: 1090, Training Loss = 0.9058351516723633\n","Accuracy =  0.6836447715759277 F1 weighted =  0.5872204899787903 F1 macro =  0.24798305332660675\n","Epoch: 1091, Training Loss = 0.9057090282440186\n","Epoch: 1092, Training Loss = 0.9055832624435425\n","Epoch: 1093, Training Loss = 0.9054576754570007\n","Epoch: 1094, Training Loss = 0.9053325057029724\n","Epoch: 1095, Training Loss = 0.9052073359489441\n","Epoch: 1096, Training Loss = 0.905082643032074\n","Epoch: 1097, Training Loss = 0.9049579501152039\n","Epoch: 1098, Training Loss = 0.9048336744308472\n","Epoch: 1099, Training Loss = 0.9047095775604248\n","Epoch: 1100, Training Loss = 0.9045857191085815\n","Accuracy =  0.6837031245231628 F1 weighted =  0.5869749784469604 F1 macro =  0.2475530058145523\n","Epoch: 1101, Training Loss = 0.9044622778892517\n","Epoch: 1102, Training Loss = 0.9043388962745667\n","Epoch: 1103, Training Loss = 0.9042156934738159\n","Epoch: 1104, Training Loss = 0.9040929079055786\n","Epoch: 1105, Training Loss = 0.9039701819419861\n","Epoch: 1106, Training Loss = 0.9038478136062622\n","Epoch: 1107, Training Loss = 0.9037256836891174\n","Epoch: 1108, Training Loss = 0.9036037921905518\n","Epoch: 1109, Training Loss = 0.90348219871521\n","Epoch: 1110, Training Loss = 0.9033607244491577\n","Accuracy =  0.6838002800941467 F1 weighted =  0.5867117047309875 F1 macro =  0.24705031514167786\n","Epoch: 1111, Training Loss = 0.9032394289970398\n","Epoch: 1112, Training Loss = 0.9031185507774353\n","Epoch: 1113, Training Loss = 0.9029977917671204\n","Epoch: 1114, Training Loss = 0.9028773903846741\n","Epoch: 1115, Training Loss = 0.9027571678161621\n","Epoch: 1116, Training Loss = 0.9026370644569397\n","Epoch: 1117, Training Loss = 0.9025172591209412\n","Epoch: 1118, Training Loss = 0.9023976922035217\n","Epoch: 1119, Training Loss = 0.9022784233093262\n","Epoch: 1120, Training Loss = 0.9021593928337097\n","Accuracy =  0.6838780641555786 F1 weighted =  0.5864387154579163 F1 macro =  0.24660508334636688\n","Epoch: 1121, Training Loss = 0.9020405411720276\n","Epoch: 1122, Training Loss = 0.9019220471382141\n","Epoch: 1123, Training Loss = 0.9018035531044006\n","Epoch: 1124, Training Loss = 0.9016852974891663\n","Epoch: 1125, Training Loss = 0.9015675187110901\n","Epoch: 1126, Training Loss = 0.9014498591423035\n","Epoch: 1127, Training Loss = 0.9013323783874512\n","Epoch: 1128, Training Loss = 0.9012151956558228\n","Epoch: 1129, Training Loss = 0.9010981917381287\n","Epoch: 1130, Training Loss = 0.9009813070297241\n","Accuracy =  0.6839752197265625 F1 weighted =  0.5862176418304443 F1 macro =  0.24622714519500732\n","Epoch: 1131, Training Loss = 0.900864839553833\n","Epoch: 1132, Training Loss = 0.900748610496521\n","Epoch: 1133, Training Loss = 0.9006325006484985\n","Epoch: 1134, Training Loss = 0.9005166888237\n","Epoch: 1135, Training Loss = 0.9004009962081909\n","Epoch: 1136, Training Loss = 0.9002857208251953\n","Epoch: 1137, Training Loss = 0.9001705050468445\n","Epoch: 1138, Training Loss = 0.9000555276870728\n","Epoch: 1139, Training Loss = 0.8999408483505249\n","Epoch: 1140, Training Loss = 0.8998262882232666\n","Accuracy =  0.6840335726737976 F1 weighted =  0.5859662294387817 F1 macro =  0.2457621544599533\n","Epoch: 1141, Training Loss = 0.8997119665145874\n","Epoch: 1142, Training Loss = 0.8995980024337769\n","Epoch: 1143, Training Loss = 0.8994842171669006\n","Epoch: 1144, Training Loss = 0.8993706107139587\n","Epoch: 1145, Training Loss = 0.8992571234703064\n","Epoch: 1146, Training Loss = 0.8991440534591675\n","Epoch: 1147, Training Loss = 0.8990311622619629\n","Epoch: 1148, Training Loss = 0.8989183306694031\n","Epoch: 1149, Training Loss = 0.8988059163093567\n","Epoch: 1150, Training Loss = 0.8986936211585999\n","Accuracy =  0.6841112971305847 F1 weighted =  0.5857257843017578 F1 macro =  0.24533984065055847\n","Epoch: 1151, Training Loss = 0.8985815644264221\n","Epoch: 1152, Training Loss = 0.8984697461128235\n","Epoch: 1153, Training Loss = 0.898358166217804\n","Epoch: 1154, Training Loss = 0.8982467651367188\n","Epoch: 1155, Training Loss = 0.8981354832649231\n","Epoch: 1156, Training Loss = 0.8980245590209961\n","Epoch: 1157, Training Loss = 0.8979138135910034\n","Epoch: 1158, Training Loss = 0.8978031873703003\n","Epoch: 1159, Training Loss = 0.8976929187774658\n","Epoch: 1160, Training Loss = 0.8975828289985657\n","Accuracy =  0.6841612458229065 F1 weighted =  0.5854717493057251 F1 macro =  0.24494203925132751\n","Epoch: 1161, Training Loss = 0.8974730372428894\n","Epoch: 1162, Training Loss = 0.8973633050918579\n","Epoch: 1163, Training Loss = 0.8972539305686951\n","Epoch: 1164, Training Loss = 0.8971445560455322\n","Epoch: 1165, Training Loss = 0.8970355987548828\n","Epoch: 1166, Training Loss = 0.896926760673523\n","Epoch: 1167, Training Loss = 0.8968181014060974\n","Epoch: 1168, Training Loss = 0.8967097997665405\n","Epoch: 1169, Training Loss = 0.8966015577316284\n","Epoch: 1170, Training Loss = 0.8964936137199402\n","Accuracy =  0.6842251420021057 F1 weighted =  0.5852513909339905 F1 macro =  0.24460458755493164\n","Epoch: 1171, Training Loss = 0.8963858485221863\n","Epoch: 1172, Training Loss = 0.8962783217430115\n","Epoch: 1173, Training Loss = 0.8961710333824158\n","Epoch: 1174, Training Loss = 0.8960638642311096\n","Epoch: 1175, Training Loss = 0.8959570527076721\n","Epoch: 1176, Training Loss = 0.8958503007888794\n","Epoch: 1177, Training Loss = 0.8957437872886658\n","Epoch: 1178, Training Loss = 0.8956375122070312\n","Epoch: 1179, Training Loss = 0.8955313563346863\n","Epoch: 1180, Training Loss = 0.89542555809021\n","Accuracy =  0.684252917766571 F1 weighted =  0.5849863290786743 F1 macro =  0.2442319691181183\n","Epoch: 1181, Training Loss = 0.8953198790550232\n","Epoch: 1182, Training Loss = 0.8952144980430603\n","Epoch: 1183, Training Loss = 0.895109236240387\n","Epoch: 1184, Training Loss = 0.8950040936470032\n","Epoch: 1185, Training Loss = 0.894899308681488\n","Epoch: 1186, Training Loss = 0.8947945833206177\n","Epoch: 1187, Training Loss = 0.894690215587616\n","Epoch: 1188, Training Loss = 0.8945858478546143\n","Epoch: 1189, Training Loss = 0.8944818377494812\n","Epoch: 1190, Training Loss = 0.8943781852722168\n","Accuracy =  0.6842279434204102 F1 weighted =  0.584662675857544 F1 macro =  0.2437703162431717\n","Epoch: 1191, Training Loss = 0.8942744135856628\n","Epoch: 1192, Training Loss = 0.8941710591316223\n","Epoch: 1193, Training Loss = 0.8940679430961609\n","Epoch: 1194, Training Loss = 0.8939648270606995\n","Epoch: 1195, Training Loss = 0.8938620686531067\n","Epoch: 1196, Training Loss = 0.8937593698501587\n","Epoch: 1197, Training Loss = 0.8936570286750793\n","Epoch: 1198, Training Loss = 0.8935548067092896\n","Epoch: 1199, Training Loss = 0.8934527635574341\n","Epoch: 1200, Training Loss = 0.8933510780334473\n","Accuracy =  0.6843028664588928 F1 weighted =  0.5844857096672058 F1 macro =  0.2434646189212799\n","Epoch: 1201, Training Loss = 0.8932493925094604\n","Epoch: 1202, Training Loss = 0.8931479454040527\n","Epoch: 1203, Training Loss = 0.8930466175079346\n","Epoch: 1204, Training Loss = 0.8929456472396851\n","Epoch: 1205, Training Loss = 0.8928449153900146\n","Epoch: 1206, Training Loss = 0.892744243144989\n","Epoch: 1207, Training Loss = 0.8926438093185425\n","Epoch: 1208, Training Loss = 0.892543613910675\n","Epoch: 1209, Training Loss = 0.8924435377120972\n","Epoch: 1210, Training Loss = 0.8923436403274536\n","Accuracy =  0.6843695044517517 F1 weighted =  0.584288477897644 F1 macro =  0.2431109994649887\n","Epoch: 1211, Training Loss = 0.8922439813613892\n","Epoch: 1212, Training Loss = 0.8921446204185486\n","Epoch: 1213, Training Loss = 0.8920453786849976\n","Epoch: 1214, Training Loss = 0.8919461965560913\n","Epoch: 1215, Training Loss = 0.8918472528457642\n","Epoch: 1216, Training Loss = 0.8917486071586609\n","Epoch: 1217, Training Loss = 0.8916501402854919\n","Epoch: 1218, Training Loss = 0.8915518522262573\n","Epoch: 1219, Training Loss = 0.8914538025856018\n","Epoch: 1220, Training Loss = 0.8913558721542358\n","Accuracy =  0.6845417022705078 F1 weighted =  0.584161639213562 F1 macro =  0.24284133315086365\n","Epoch: 1221, Training Loss = 0.891258180141449\n","Epoch: 1222, Training Loss = 0.8911606669425964\n","Epoch: 1223, Training Loss = 0.891063392162323\n","Epoch: 1224, Training Loss = 0.8909662365913391\n","Epoch: 1225, Training Loss = 0.8908692002296448\n","Epoch: 1226, Training Loss = 0.8907725811004639\n","Epoch: 1227, Training Loss = 0.890675961971283\n","Epoch: 1228, Training Loss = 0.8905794024467468\n","Epoch: 1229, Training Loss = 0.8904832601547241\n","Epoch: 1230, Training Loss = 0.8903872966766357\n","Accuracy =  0.6846055388450623 F1 weighted =  0.5839722752571106 F1 macro =  0.2425246238708496\n","Epoch: 1231, Training Loss = 0.8902913928031921\n","Epoch: 1232, Training Loss = 0.8901957869529724\n","Epoch: 1233, Training Loss = 0.890100359916687\n","Epoch: 1234, Training Loss = 0.8900050520896912\n","Epoch: 1235, Training Loss = 0.8899099826812744\n","Epoch: 1236, Training Loss = 0.8898150324821472\n","Epoch: 1237, Training Loss = 0.8897203803062439\n","Epoch: 1238, Training Loss = 0.8896258473396301\n","Epoch: 1239, Training Loss = 0.8895314931869507\n","Epoch: 1240, Training Loss = 0.8894373178482056\n","Accuracy =  0.6846833229064941 F1 weighted =  0.5837838649749756 F1 macro =  0.24222320318222046\n","Epoch: 1241, Training Loss = 0.88934326171875\n","Epoch: 1242, Training Loss = 0.8892494440078735\n","Epoch: 1243, Training Loss = 0.8891558647155762\n","Epoch: 1244, Training Loss = 0.8890625238418579\n","Epoch: 1245, Training Loss = 0.8889691829681396\n","Epoch: 1246, Training Loss = 0.8888760209083557\n","Epoch: 1247, Training Loss = 0.8887832760810852\n","Epoch: 1248, Training Loss = 0.8886905908584595\n","Epoch: 1249, Training Loss = 0.8885980248451233\n","Epoch: 1250, Training Loss = 0.8885055780410767\n","Accuracy =  0.6847444176673889 F1 weighted =  0.5836213231086731 F1 macro =  0.24196569621562958\n","Epoch: 1251, Training Loss = 0.8884134292602539\n","Epoch: 1252, Training Loss = 0.8883215188980103\n","Epoch: 1253, Training Loss = 0.8882296085357666\n","Epoch: 1254, Training Loss = 0.8881380558013916\n","Epoch: 1255, Training Loss = 0.8880465626716614\n","Epoch: 1256, Training Loss = 0.8879553079605103\n","Epoch: 1257, Training Loss = 0.8878642320632935\n","Epoch: 1258, Training Loss = 0.8877732157707214\n","Epoch: 1259, Training Loss = 0.8876824975013733\n","Epoch: 1260, Training Loss = 0.8875919580459595\n","Accuracy =  0.6848276853561401 F1 weighted =  0.5834538340568542 F1 macro =  0.24161396920681\n","Epoch: 1261, Training Loss = 0.8875014781951904\n","Epoch: 1262, Training Loss = 0.8874114155769348\n","Epoch: 1263, Training Loss = 0.8873213529586792\n","Epoch: 1264, Training Loss = 0.8872314691543579\n","Epoch: 1265, Training Loss = 0.8871417045593262\n","Epoch: 1266, Training Loss = 0.8870522379875183\n","Epoch: 1267, Training Loss = 0.8869629502296448\n","Epoch: 1268, Training Loss = 0.8868736624717712\n","Epoch: 1269, Training Loss = 0.8867847323417664\n","Epoch: 1270, Training Loss = 0.8866958618164062\n","Accuracy =  0.6848999261856079 F1 weighted =  0.5832964181900024 F1 macro =  0.24132542312145233\n","Epoch: 1271, Training Loss = 0.88660728931427\n","Epoch: 1272, Training Loss = 0.8865187764167786\n","Epoch: 1273, Training Loss = 0.8864305019378662\n","Epoch: 1274, Training Loss = 0.8863423466682434\n","Epoch: 1275, Training Loss = 0.8862544298171997\n","Epoch: 1276, Training Loss = 0.8861665725708008\n","Epoch: 1277, Training Loss = 0.8860790133476257\n","Epoch: 1278, Training Loss = 0.8859915137290955\n","Epoch: 1279, Training Loss = 0.8859042525291443\n","Epoch: 1280, Training Loss = 0.8858170509338379\n","Accuracy =  0.6849693059921265 F1 weighted =  0.5831263065338135 F1 macro =  0.24105434119701385\n","Epoch: 1281, Training Loss = 0.8857301473617554\n","Epoch: 1282, Training Loss = 0.8856433629989624\n","Epoch: 1283, Training Loss = 0.885556697845459\n","Epoch: 1284, Training Loss = 0.8854703903198242\n","Epoch: 1285, Training Loss = 0.8853840827941895\n","Epoch: 1286, Training Loss = 0.8852980136871338\n","Epoch: 1287, Training Loss = 0.8852120041847229\n","Epoch: 1288, Training Loss = 0.8851262331008911\n","Epoch: 1289, Training Loss = 0.8850407600402832\n","Epoch: 1290, Training Loss = 0.8849553465843201\n","Accuracy =  0.6850526332855225 F1 weighted =  0.5830265879631042 F1 macro =  0.24086450040340424\n","Epoch: 1291, Training Loss = 0.8848699331283569\n","Epoch: 1292, Training Loss = 0.8847848773002625\n","Epoch: 1293, Training Loss = 0.8846999406814575\n","Epoch: 1294, Training Loss = 0.8846151828765869\n","Epoch: 1295, Training Loss = 0.8845305442810059\n","Epoch: 1296, Training Loss = 0.8844460248947144\n","Epoch: 1297, Training Loss = 0.884361743927002\n","Epoch: 1298, Training Loss = 0.8842778205871582\n","Epoch: 1299, Training Loss = 0.8841936588287354\n","Epoch: 1300, Training Loss = 0.8841099739074707\n","Accuracy =  0.6851164698600769 F1 weighted =  0.5828527808189392 F1 macro =  0.24058039486408234\n","Epoch: 1301, Training Loss = 0.884026288986206\n","Epoch: 1302, Training Loss = 0.8839429020881653\n","Epoch: 1303, Training Loss = 0.8838594555854797\n","Epoch: 1304, Training Loss = 0.8837764263153076\n","Epoch: 1305, Training Loss = 0.8836933374404907\n","Epoch: 1306, Training Loss = 0.8836105465888977\n","Epoch: 1307, Training Loss = 0.8835278749465942\n","Epoch: 1308, Training Loss = 0.8834453821182251\n","Epoch: 1309, Training Loss = 0.8833630681037903\n","Epoch: 1310, Training Loss = 0.883280873298645\n","Accuracy =  0.6851942539215088 F1 weighted =  0.5826773047447205 F1 macro =  0.24027693271636963\n","Epoch: 1311, Training Loss = 0.8831989169120789\n","Epoch: 1312, Training Loss = 0.8831170797348022\n","Epoch: 1313, Training Loss = 0.88303542137146\n","Epoch: 1314, Training Loss = 0.8829537630081177\n","Epoch: 1315, Training Loss = 0.8828724026679993\n","Epoch: 1316, Training Loss = 0.8827911615371704\n","Epoch: 1317, Training Loss = 0.8827101588249207\n","Epoch: 1318, Training Loss = 0.8826292157173157\n","Epoch: 1319, Training Loss = 0.8825483322143555\n","Epoch: 1320, Training Loss = 0.8824678659439087\n","Accuracy =  0.6852303147315979 F1 weighted =  0.5824654698371887 F1 macro =  0.23994489014148712\n","Epoch: 1321, Training Loss = 0.8823873400688171\n","Epoch: 1322, Training Loss = 0.8823070526123047\n","Epoch: 1323, Training Loss = 0.8822269439697266\n","Epoch: 1324, Training Loss = 0.8821470141410828\n","Epoch: 1325, Training Loss = 0.8820671439170837\n","Epoch: 1326, Training Loss = 0.8819875121116638\n","Epoch: 1327, Training Loss = 0.8819079995155334\n","Epoch: 1328, Training Loss = 0.8818286061286926\n","Epoch: 1329, Training Loss = 0.8817492723464966\n","Epoch: 1330, Training Loss = 0.8816702961921692\n","Accuracy =  0.6852719783782959 F1 weighted =  0.582278847694397 F1 macro =  0.23962263762950897\n","Epoch: 1331, Training Loss = 0.8815913796424866\n","Epoch: 1332, Training Loss = 0.8815126419067383\n","Epoch: 1333, Training Loss = 0.8814340233802795\n","Epoch: 1334, Training Loss = 0.8813555240631104\n","Epoch: 1335, Training Loss = 0.8812772631645203\n","Epoch: 1336, Training Loss = 0.881199061870575\n","Epoch: 1337, Training Loss = 0.8811211585998535\n","Epoch: 1338, Training Loss = 0.8810431957244873\n","Epoch: 1339, Training Loss = 0.880965530872345\n","Epoch: 1340, Training Loss = 0.8808881640434265\n","Accuracy =  0.6853025555610657 F1 weighted =  0.5821069478988647 F1 macro =  0.2393830418586731\n","Epoch: 1341, Training Loss = 0.8808106780052185\n","Epoch: 1342, Training Loss = 0.8807333707809448\n","Epoch: 1343, Training Loss = 0.8806563019752502\n","Epoch: 1344, Training Loss = 0.8805792927742004\n","Epoch: 1345, Training Loss = 0.8805025219917297\n","Epoch: 1346, Training Loss = 0.8804258704185486\n","Epoch: 1347, Training Loss = 0.8803493976593018\n","Epoch: 1348, Training Loss = 0.8802730441093445\n","Epoch: 1349, Training Loss = 0.8801969289779663\n","Epoch: 1350, Training Loss = 0.8801207542419434\n","Accuracy =  0.6853858232498169 F1 weighted =  0.5819928646087646 F1 macro =  0.23917421698570251\n","Epoch: 1351, Training Loss = 0.8800448775291443\n","Epoch: 1352, Training Loss = 0.87996906042099\n","Epoch: 1353, Training Loss = 0.8798935413360596\n","Epoch: 1354, Training Loss = 0.8798181414604187\n","Epoch: 1355, Training Loss = 0.8797426223754883\n","Epoch: 1356, Training Loss = 0.8796674609184265\n","Epoch: 1357, Training Loss = 0.8795924782752991\n","Epoch: 1358, Training Loss = 0.8795176148414612\n","Epoch: 1359, Training Loss = 0.8794428706169128\n","Epoch: 1360, Training Loss = 0.879368245601654\n","Accuracy =  0.6853969693183899 F1 weighted =  0.5818383097648621 F1 macro =  0.23893395066261292\n","Epoch: 1361, Training Loss = 0.8792937994003296\n","Epoch: 1362, Training Loss = 0.8792193531990051\n","Epoch: 1363, Training Loss = 0.8791453242301941\n","Epoch: 1364, Training Loss = 0.8790712952613831\n","Epoch: 1365, Training Loss = 0.8789973855018616\n","Epoch: 1366, Training Loss = 0.8789235949516296\n","Epoch: 1367, Training Loss = 0.878849983215332\n","Epoch: 1368, Training Loss = 0.8787765502929688\n","Epoch: 1369, Training Loss = 0.8787031769752502\n","Epoch: 1370, Training Loss = 0.8786299824714661\n","Accuracy =  0.6853969693183899 F1 weighted =  0.5816574096679688 F1 macro =  0.23864303529262543\n","Epoch: 1371, Training Loss = 0.8785569667816162\n","Epoch: 1372, Training Loss = 0.8784841299057007\n","Epoch: 1373, Training Loss = 0.8784113526344299\n","Epoch: 1374, Training Loss = 0.8783386945724487\n","Epoch: 1375, Training Loss = 0.8782662153244019\n","Epoch: 1376, Training Loss = 0.8781939148902893\n","Epoch: 1377, Training Loss = 0.8781216144561768\n","Epoch: 1378, Training Loss = 0.8780496716499329\n","Epoch: 1379, Training Loss = 0.877977728843689\n","Epoch: 1380, Training Loss = 0.8779059648513794\n","Accuracy =  0.6854358315467834 F1 weighted =  0.5815138220787048 F1 macro =  0.23841483891010284\n","Epoch: 1381, Training Loss = 0.8778342604637146\n","Epoch: 1382, Training Loss = 0.8777627944946289\n","Epoch: 1383, Training Loss = 0.877691388130188\n","Epoch: 1384, Training Loss = 0.8776201605796814\n","Epoch: 1385, Training Loss = 0.8775491118431091\n","Epoch: 1386, Training Loss = 0.8774780631065369\n","Epoch: 1387, Training Loss = 0.8774071931838989\n","Epoch: 1388, Training Loss = 0.8773365020751953\n","Epoch: 1389, Training Loss = 0.877265989780426\n","Epoch: 1390, Training Loss = 0.8771955966949463\n","Accuracy =  0.6854052543640137 F1 weighted =  0.5813018679618835 F1 macro =  0.23811545968055725\n","Epoch: 1391, Training Loss = 0.8771254420280457\n","Epoch: 1392, Training Loss = 0.8770551085472107\n","Epoch: 1393, Training Loss = 0.8769851922988892\n","Epoch: 1394, Training Loss = 0.8769152760505676\n","Epoch: 1395, Training Loss = 0.8768454790115356\n","Epoch: 1396, Training Loss = 0.8767759203910828\n","Epoch: 1397, Training Loss = 0.8767064809799194\n","Epoch: 1398, Training Loss = 0.8766372203826904\n","Epoch: 1399, Training Loss = 0.8765679597854614\n","Epoch: 1400, Training Loss = 0.8764989376068115\n","Accuracy =  0.6854608058929443 F1 weighted =  0.5811967849731445 F1 macro =  0.23791973292827606\n","Epoch: 1401, Training Loss = 0.8764299154281616\n","Epoch: 1402, Training Loss = 0.8763611316680908\n","Epoch: 1403, Training Loss = 0.8762924671173096\n","Epoch: 1404, Training Loss = 0.8762239217758179\n","Epoch: 1405, Training Loss = 0.8761555552482605\n","Epoch: 1406, Training Loss = 0.8760873675346375\n","Epoch: 1407, Training Loss = 0.8760191798210144\n","Epoch: 1408, Training Loss = 0.8759509921073914\n","Epoch: 1409, Training Loss = 0.8758831024169922\n","Epoch: 1410, Training Loss = 0.8758155107498169\n","Accuracy =  0.6854885816574097 F1 weighted =  0.5810407400131226 F1 macro =  0.2376629263162613\n","Epoch: 1411, Training Loss = 0.8757478594779968\n","Epoch: 1412, Training Loss = 0.8756803274154663\n","Epoch: 1413, Training Loss = 0.8756130337715149\n","Epoch: 1414, Training Loss = 0.8755456805229187\n","Epoch: 1415, Training Loss = 0.8754785656929016\n","Epoch: 1416, Training Loss = 0.8754116296768188\n","Epoch: 1417, Training Loss = 0.8753448128700256\n","Epoch: 1418, Training Loss = 0.8752779960632324\n","Epoch: 1419, Training Loss = 0.8752114176750183\n","Epoch: 1420, Training Loss = 0.8751450181007385\n","Accuracy =  0.6854830384254456 F1 weighted =  0.5808518528938293 F1 macro =  0.23739734292030334\n","Epoch: 1421, Training Loss = 0.8750786185264587\n","Epoch: 1422, Training Loss = 0.8750123977661133\n","Epoch: 1423, Training Loss = 0.8749463558197021\n","Epoch: 1424, Training Loss = 0.874880313873291\n","Epoch: 1425, Training Loss = 0.8748143911361694\n","Epoch: 1426, Training Loss = 0.8747488260269165\n","Epoch: 1427, Training Loss = 0.874683141708374\n","Epoch: 1428, Training Loss = 0.8746176958084106\n","Epoch: 1429, Training Loss = 0.874552309513092\n","Epoch: 1430, Training Loss = 0.8744871616363525\n","Accuracy =  0.6855080127716064 F1 weighted =  0.5806958675384521 F1 macro =  0.23712682723999023\n","Epoch: 1431, Training Loss = 0.8744221329689026\n","Epoch: 1432, Training Loss = 0.8743571043014526\n","Epoch: 1433, Training Loss = 0.8742921948432922\n","Epoch: 1434, Training Loss = 0.8742275238037109\n","Epoch: 1435, Training Loss = 0.874163031578064\n","Epoch: 1436, Training Loss = 0.8740985989570618\n","Epoch: 1437, Training Loss = 0.8740342855453491\n","Epoch: 1438, Training Loss = 0.8739699721336365\n","Epoch: 1439, Training Loss = 0.8739057779312134\n","Epoch: 1440, Training Loss = 0.8738418221473694\n","Accuracy =  0.6855190992355347 F1 weighted =  0.5805696249008179 F1 macro =  0.23692594468593597\n","Epoch: 1441, Training Loss = 0.8737779855728149\n","Epoch: 1442, Training Loss = 0.87371426820755\n","Epoch: 1443, Training Loss = 0.8736506104469299\n","Epoch: 1444, Training Loss = 0.8735871315002441\n","Epoch: 1445, Training Loss = 0.8735238313674927\n","Epoch: 1446, Training Loss = 0.873460590839386\n","Epoch: 1447, Training Loss = 0.8733974099159241\n","Epoch: 1448, Training Loss = 0.8733344078063965\n","Epoch: 1449, Training Loss = 0.8732715845108032\n","Epoch: 1450, Training Loss = 0.87320876121521\n","Accuracy =  0.6855413317680359 F1 weighted =  0.5804333090782166 F1 macro =  0.23674096167087555\n","Epoch: 1451, Training Loss = 0.8731460571289062\n","Epoch: 1452, Training Loss = 0.8730835914611816\n","Epoch: 1453, Training Loss = 0.8730212450027466\n","Epoch: 1454, Training Loss = 0.8729588389396667\n","Epoch: 1455, Training Loss = 0.8728968501091003\n","Epoch: 1456, Training Loss = 0.8728348016738892\n","Epoch: 1457, Training Loss = 0.872772753238678\n","Epoch: 1458, Training Loss = 0.8727109432220459\n","Epoch: 1459, Training Loss = 0.8726492524147034\n","Epoch: 1460, Training Loss = 0.8725876808166504\n","Accuracy =  0.6855385303497314 F1 weighted =  0.5802754163742065 F1 macro =  0.23648636043071747\n","Epoch: 1461, Training Loss = 0.8725261688232422\n","Epoch: 1462, Training Loss = 0.8724648356437683\n","Epoch: 1463, Training Loss = 0.8724036812782288\n","Epoch: 1464, Training Loss = 0.8723425269126892\n","Epoch: 1465, Training Loss = 0.8722814917564392\n","Epoch: 1466, Training Loss = 0.8722205758094788\n","Epoch: 1467, Training Loss = 0.8721598982810974\n","Epoch: 1468, Training Loss = 0.8720992207527161\n","Epoch: 1469, Training Loss = 0.8720387816429138\n","Epoch: 1470, Training Loss = 0.8719783425331116\n","Accuracy =  0.6855274438858032 F1 weighted =  0.5800853967666626 F1 macro =  0.2361844927072525\n","Epoch: 1471, Training Loss = 0.8719180226325989\n","Epoch: 1472, Training Loss = 0.8718578219413757\n","Epoch: 1473, Training Loss = 0.8717976808547974\n","Epoch: 1474, Training Loss = 0.8717377185821533\n","Epoch: 1475, Training Loss = 0.8716779351234436\n","Epoch: 1476, Training Loss = 0.8716182112693787\n","Epoch: 1477, Training Loss = 0.8715585470199585\n","Epoch: 1478, Training Loss = 0.8714990615844727\n","Epoch: 1479, Training Loss = 0.8714397549629211\n","Epoch: 1480, Training Loss = 0.8713805079460144\n","Accuracy =  0.6855691075325012 F1 weighted =  0.579967200756073 F1 macro =  0.2359543889760971\n","Epoch: 1481, Training Loss = 0.8713212609291077\n","Epoch: 1482, Training Loss = 0.8712620735168457\n","Epoch: 1483, Training Loss = 0.8712032437324524\n","Epoch: 1484, Training Loss = 0.8711444139480591\n","Epoch: 1485, Training Loss = 0.8710857033729553\n","Epoch: 1486, Training Loss = 0.8710270524024963\n","Epoch: 1487, Training Loss = 0.8709685802459717\n","Epoch: 1488, Training Loss = 0.8709102272987366\n","Epoch: 1489, Training Loss = 0.8708519339561462\n","Epoch: 1490, Training Loss = 0.8707938194274902\n","Accuracy =  0.685558021068573 F1 weighted =  0.5798008441925049 F1 macro =  0.23570828139781952\n","Epoch: 1491, Training Loss = 0.870735764503479\n","Epoch: 1492, Training Loss = 0.8706777691841125\n","Epoch: 1493, Training Loss = 0.8706198930740356\n","Epoch: 1494, Training Loss = 0.8705621957778931\n","Epoch: 1495, Training Loss = 0.8705047369003296\n","Epoch: 1496, Training Loss = 0.8704471588134766\n","Epoch: 1497, Training Loss = 0.8703897595405579\n","Epoch: 1498, Training Loss = 0.8703324198722839\n","Epoch: 1499, Training Loss = 0.8702752590179443\n","Epoch: 1500, Training Loss = 0.8702182173728943\n","Accuracy =  0.685558021068573 F1 weighted =  0.5796215534210205 F1 macro =  0.23545168340206146\n","Epoch: 1501, Training Loss = 0.8701613545417786\n","Epoch: 1502, Training Loss = 0.8701044917106628\n","Epoch: 1503, Training Loss = 0.8700476884841919\n","Epoch: 1504, Training Loss = 0.8699911236763\n","Epoch: 1505, Training Loss = 0.869934618473053\n","Epoch: 1506, Training Loss = 0.8698781728744507\n","Epoch: 1507, Training Loss = 0.8698217868804932\n","Epoch: 1508, Training Loss = 0.8697656393051147\n","Epoch: 1509, Training Loss = 0.8697095513343811\n","Epoch: 1510, Training Loss = 0.8696535229682922\n","Accuracy =  0.6856051683425903 F1 weighted =  0.57950758934021 F1 macro =  0.23523950576782227\n","Epoch: 1511, Training Loss = 0.8695976734161377\n","Epoch: 1512, Training Loss = 0.8695418238639832\n","Epoch: 1513, Training Loss = 0.8694862723350525\n","Epoch: 1514, Training Loss = 0.8694304823875427\n","Epoch: 1515, Training Loss = 0.8693751096725464\n","Epoch: 1516, Training Loss = 0.8693197965621948\n","Epoch: 1517, Training Loss = 0.869264543056488\n","Epoch: 1518, Training Loss = 0.8692092895507812\n","Epoch: 1519, Training Loss = 0.8691543340682983\n","Epoch: 1520, Training Loss = 0.8690992593765259\n","Accuracy =  0.685588538646698 F1 weighted =  0.5793368816375732 F1 macro =  0.2350129783153534\n","Epoch: 1521, Training Loss = 0.8690446019172668\n","Epoch: 1522, Training Loss = 0.8689897060394287\n","Epoch: 1523, Training Loss = 0.868935227394104\n","Epoch: 1524, Training Loss = 0.8688806295394897\n","Epoch: 1525, Training Loss = 0.8688263297080994\n","Epoch: 1526, Training Loss = 0.8687718510627747\n","Epoch: 1527, Training Loss = 0.8687177300453186\n","Epoch: 1528, Training Loss = 0.8686635494232178\n","Epoch: 1529, Training Loss = 0.8686094284057617\n","Epoch: 1530, Training Loss = 0.8685555458068848\n","Accuracy =  0.6856357455253601 F1 weighted =  0.5792778134346008 F1 macro =  0.2348880171775818\n","Epoch: 1531, Training Loss = 0.8685017228126526\n","Epoch: 1532, Training Loss = 0.8684480786323547\n","Epoch: 1533, Training Loss = 0.8683943748474121\n","Epoch: 1534, Training Loss = 0.8683409094810486\n","Epoch: 1535, Training Loss = 0.8682874441146851\n","Epoch: 1536, Training Loss = 0.8682342171669006\n","Epoch: 1537, Training Loss = 0.8681809902191162\n","Epoch: 1538, Training Loss = 0.8681279420852661\n","Epoch: 1539, Training Loss = 0.868074893951416\n","Epoch: 1540, Training Loss = 0.8680220246315002\n","Accuracy =  0.6856523752212524 F1 weighted =  0.5791542530059814 F1 macro =  0.23471178114414215\n","Epoch: 1541, Training Loss = 0.8679691553115845\n","Epoch: 1542, Training Loss = 0.8679162859916687\n","Epoch: 1543, Training Loss = 0.8678638935089111\n","Epoch: 1544, Training Loss = 0.8678112626075745\n","Epoch: 1545, Training Loss = 0.8677588105201721\n","Epoch: 1546, Training Loss = 0.8677064776420593\n","Epoch: 1547, Training Loss = 0.8676543831825256\n","Epoch: 1548, Training Loss = 0.8676021695137024\n","Epoch: 1549, Training Loss = 0.8675501346588135\n","Epoch: 1550, Training Loss = 0.8674982786178589\n","Accuracy =  0.6856884956359863 F1 weighted =  0.5790727138519287 F1 macro =  0.23457536101341248\n","Epoch: 1551, Training Loss = 0.8674464225769043\n","Epoch: 1552, Training Loss = 0.8673946261405945\n","Epoch: 1553, Training Loss = 0.8673430681228638\n","Epoch: 1554, Training Loss = 0.8672915697097778\n","Epoch: 1555, Training Loss = 0.8672401905059814\n","Epoch: 1556, Training Loss = 0.8671888113021851\n","Epoch: 1557, Training Loss = 0.867137610912323\n","Epoch: 1558, Training Loss = 0.8670864701271057\n","Epoch: 1559, Training Loss = 0.8670353293418884\n","Epoch: 1560, Training Loss = 0.8669844269752502\n","Accuracy =  0.685702383518219 F1 weighted =  0.5789506435394287 F1 macro =  0.2343946099281311\n","Epoch: 1561, Training Loss = 0.8669334650039673\n","Epoch: 1562, Training Loss = 0.8668828010559082\n","Epoch: 1563, Training Loss = 0.8668320775032043\n","Epoch: 1564, Training Loss = 0.8667815327644348\n","Epoch: 1565, Training Loss = 0.8667309284210205\n","Epoch: 1566, Training Loss = 0.8666806221008301\n","Epoch: 1567, Training Loss = 0.8666303157806396\n","Epoch: 1568, Training Loss = 0.8665801286697388\n","Epoch: 1569, Training Loss = 0.8665299415588379\n","Epoch: 1570, Training Loss = 0.8664800524711609\n","Accuracy =  0.6857495903968811 F1 weighted =  0.5788737535476685 F1 macro =  0.2342643141746521\n","Epoch: 1571, Training Loss = 0.8664301037788391\n","Epoch: 1572, Training Loss = 0.8663803339004517\n","Epoch: 1573, Training Loss = 0.8663305044174194\n","Epoch: 1574, Training Loss = 0.8662808537483215\n","Epoch: 1575, Training Loss = 0.8662314414978027\n","Epoch: 1576, Training Loss = 0.8661819100379944\n","Epoch: 1577, Training Loss = 0.8661325573921204\n","Epoch: 1578, Training Loss = 0.8660834431648254\n","Epoch: 1579, Training Loss = 0.866034209728241\n","Epoch: 1580, Training Loss = 0.865985095500946\n","Accuracy =  0.6857773661613464 F1 weighted =  0.5787523984909058 F1 macro =  0.2340639978647232\n","Epoch: 1581, Training Loss = 0.8659361004829407\n","Epoch: 1582, Training Loss = 0.8658872842788696\n","Epoch: 1583, Training Loss = 0.865838348865509\n","Epoch: 1584, Training Loss = 0.8657896518707275\n","Epoch: 1585, Training Loss = 0.8657410144805908\n","Epoch: 1586, Training Loss = 0.8656925559043884\n","Epoch: 1587, Training Loss = 0.8656440377235413\n","Epoch: 1588, Training Loss = 0.8655957579612732\n","Epoch: 1589, Training Loss = 0.8655475974082947\n","Epoch: 1590, Training Loss = 0.8654993176460266\n","Accuracy =  0.6858217716217041 F1 weighted =  0.578686535358429 F1 macro =  0.23397979140281677\n","Epoch: 1591, Training Loss = 0.8654512763023376\n","Epoch: 1592, Training Loss = 0.8654032349586487\n","Epoch: 1593, Training Loss = 0.865355372428894\n","Epoch: 1594, Training Loss = 0.8653075695037842\n","Epoch: 1595, Training Loss = 0.8652598261833191\n","Epoch: 1596, Training Loss = 0.8652122020721436\n","Epoch: 1597, Training Loss = 0.8651646971702576\n","Epoch: 1598, Training Loss = 0.8651171922683716\n","Epoch: 1599, Training Loss = 0.8650698065757751\n","Epoch: 1600, Training Loss = 0.865022599697113\n","Accuracy =  0.6858078837394714 F1 weighted =  0.5785666704177856 F1 macro =  0.23380395770072937\n","Epoch: 1601, Training Loss = 0.8649753332138062\n","Epoch: 1602, Training Loss = 0.8649282455444336\n","Epoch: 1603, Training Loss = 0.8648812174797058\n","Epoch: 1604, Training Loss = 0.8648343682289124\n","Epoch: 1605, Training Loss = 0.8647874593734741\n","Epoch: 1606, Training Loss = 0.8647407293319702\n","Epoch: 1607, Training Loss = 0.8646940588951111\n","Epoch: 1608, Training Loss = 0.8646475076675415\n","Epoch: 1609, Training Loss = 0.8646010756492615\n","Epoch: 1610, Training Loss = 0.8645545840263367\n","Accuracy =  0.685785710811615 F1 weighted =  0.5784361958503723 F1 macro =  0.2336321920156479\n","Epoch: 1611, Training Loss = 0.8645082712173462\n","Epoch: 1612, Training Loss = 0.86446213722229\n","Epoch: 1613, Training Loss = 0.8644158840179443\n","Epoch: 1614, Training Loss = 0.864369809627533\n","Epoch: 1615, Training Loss = 0.8643238544464111\n","Epoch: 1616, Training Loss = 0.8642779588699341\n","Epoch: 1617, Training Loss = 0.8642321228981018\n","Epoch: 1618, Training Loss = 0.8641863465309143\n","Epoch: 1619, Training Loss = 0.8641408085823059\n","Epoch: 1620, Training Loss = 0.8640952110290527\n","Accuracy =  0.6858329176902771 F1 weighted =  0.5783686637878418 F1 macro =  0.2334948480129242\n","Epoch: 1621, Training Loss = 0.8640497326850891\n","Epoch: 1622, Training Loss = 0.8640044927597046\n","Epoch: 1623, Training Loss = 0.8639590740203857\n","Epoch: 1624, Training Loss = 0.8639139533042908\n","Epoch: 1625, Training Loss = 0.8638688325881958\n","Epoch: 1626, Training Loss = 0.8638237714767456\n","Epoch: 1627, Training Loss = 0.8637787699699402\n","Epoch: 1628, Training Loss = 0.8637338280677795\n","Epoch: 1629, Training Loss = 0.8636890649795532\n","Epoch: 1630, Training Loss = 0.8636442422866821\n","Accuracy =  0.6858356595039368 F1 weighted =  0.5782226920127869 F1 macro =  0.23328754305839539\n","Epoch: 1631, Training Loss = 0.8635996580123901\n","Epoch: 1632, Training Loss = 0.8635551929473877\n","Epoch: 1633, Training Loss = 0.8635106682777405\n","Epoch: 1634, Training Loss = 0.8634663224220276\n","Epoch: 1635, Training Loss = 0.8634219765663147\n","Epoch: 1636, Training Loss = 0.8633777499198914\n","Epoch: 1637, Training Loss = 0.8633336424827576\n","Epoch: 1638, Training Loss = 0.8632897138595581\n","Epoch: 1639, Training Loss = 0.8632456660270691\n","Epoch: 1640, Training Loss = 0.8632017374038696\n","Accuracy =  0.6858606338500977 F1 weighted =  0.5781291127204895 F1 macro =  0.2331443876028061\n","Epoch: 1641, Training Loss = 0.8631579279899597\n","Epoch: 1642, Training Loss = 0.8631141781806946\n","Epoch: 1643, Training Loss = 0.863070547580719\n","Epoch: 1644, Training Loss = 0.8630269169807434\n","Epoch: 1645, Training Loss = 0.8629834651947021\n","Epoch: 1646, Training Loss = 0.8629401326179504\n","Epoch: 1647, Training Loss = 0.8628968596458435\n","Epoch: 1648, Training Loss = 0.862853467464447\n","Epoch: 1649, Training Loss = 0.8628103137016296\n","Epoch: 1650, Training Loss = 0.8627673983573914\n","Accuracy =  0.6858662366867065 F1 weighted =  0.5780337452888489 F1 macro =  0.23301196098327637\n","Epoch: 1651, Training Loss = 0.862724244594574\n","Epoch: 1652, Training Loss = 0.8626813888549805\n","Epoch: 1653, Training Loss = 0.8626384735107422\n","Epoch: 1654, Training Loss = 0.8625957369804382\n","Epoch: 1655, Training Loss = 0.8625530004501343\n","Epoch: 1656, Training Loss = 0.8625103831291199\n","Epoch: 1657, Training Loss = 0.862467885017395\n","Epoch: 1658, Training Loss = 0.8624254465103149\n","Epoch: 1659, Training Loss = 0.8623830676078796\n","Epoch: 1660, Training Loss = 0.8623408079147339\n","Accuracy =  0.6858662366867065 F1 weighted =  0.5779359936714172 F1 macro =  0.2328728884458542\n","Epoch: 1661, Training Loss = 0.8622985482215881\n","Epoch: 1662, Training Loss = 0.8622564077377319\n","Epoch: 1663, Training Loss = 0.8622142672538757\n","Epoch: 1664, Training Loss = 0.8621723651885986\n","Epoch: 1665, Training Loss = 0.8621304035186768\n","Epoch: 1666, Training Loss = 0.8620885610580444\n","Epoch: 1667, Training Loss = 0.8620467782020569\n","Epoch: 1668, Training Loss = 0.8620051741600037\n","Epoch: 1669, Training Loss = 0.8619635701179504\n","Epoch: 1670, Training Loss = 0.861922025680542\n","Accuracy =  0.685888409614563 F1 weighted =  0.5778641700744629 F1 macro =  0.23277859389781952\n","Epoch: 1671, Training Loss = 0.8618806004524231\n","Epoch: 1672, Training Loss = 0.8618392944335938\n","Epoch: 1673, Training Loss = 0.8617978692054749\n","Epoch: 1674, Training Loss = 0.8617566227912903\n","Epoch: 1675, Training Loss = 0.86171555519104\n","Epoch: 1676, Training Loss = 0.861674427986145\n","Epoch: 1677, Training Loss = 0.8616334199905396\n","Epoch: 1678, Training Loss = 0.8615925908088684\n","Epoch: 1679, Training Loss = 0.8615517616271973\n","Epoch: 1680, Training Loss = 0.8615108728408813\n","Accuracy =  0.6858773231506348 F1 weighted =  0.5777236223220825 F1 macro =  0.23256593942642212\n","Epoch: 1681, Training Loss = 0.8614702224731445\n","Epoch: 1682, Training Loss = 0.8614295721054077\n","Epoch: 1683, Training Loss = 0.8613889813423157\n","Epoch: 1684, Training Loss = 0.8613485097885132\n","Epoch: 1685, Training Loss = 0.8613080978393555\n","Epoch: 1686, Training Loss = 0.8612678647041321\n","Epoch: 1687, Training Loss = 0.8612275719642639\n","Epoch: 1688, Training Loss = 0.8611873984336853\n","Epoch: 1689, Training Loss = 0.8611472249031067\n","Epoch: 1690, Training Loss = 0.8611072301864624\n","Accuracy =  0.6859217286109924 F1 weighted =  0.5777021646499634 F1 macro =  0.2325221598148346\n","Epoch: 1691, Training Loss = 0.8610673546791077\n","Epoch: 1692, Training Loss = 0.8610274195671082\n","Epoch: 1693, Training Loss = 0.8609876036643982\n","Epoch: 1694, Training Loss = 0.8609477877616882\n","Epoch: 1695, Training Loss = 0.8609082698822021\n","Epoch: 1696, Training Loss = 0.8608686327934265\n","Epoch: 1697, Training Loss = 0.8608291149139404\n","Epoch: 1698, Training Loss = 0.8607895374298096\n","Epoch: 1699, Training Loss = 0.8607503175735474\n","Epoch: 1700, Training Loss = 0.8607109189033508\n","Accuracy =  0.685930073261261 F1 weighted =  0.5776110291481018 F1 macro =  0.23238655924797058\n","Epoch: 1701, Training Loss = 0.8606717586517334\n","Epoch: 1702, Training Loss = 0.860632598400116\n","Epoch: 1703, Training Loss = 0.8605935573577881\n","Epoch: 1704, Training Loss = 0.8605544567108154\n","Epoch: 1705, Training Loss = 0.8605154752731323\n","Epoch: 1706, Training Loss = 0.8604766130447388\n","Epoch: 1707, Training Loss = 0.86043781042099\n","Epoch: 1708, Training Loss = 0.8603991270065308\n","Epoch: 1709, Training Loss = 0.8603604435920715\n","Epoch: 1710, Training Loss = 0.8603218793869019\n","Accuracy =  0.6859134435653687 F1 weighted =  0.5774989128112793 F1 macro =  0.23224176466464996\n","Epoch: 1711, Training Loss = 0.8602834939956665\n","Epoch: 1712, Training Loss = 0.8602449297904968\n","Epoch: 1713, Training Loss = 0.8602066040039062\n","Epoch: 1714, Training Loss = 0.8601682186126709\n","Epoch: 1715, Training Loss = 0.8601300716400146\n","Epoch: 1716, Training Loss = 0.8600918054580688\n","Epoch: 1717, Training Loss = 0.8600536584854126\n","Epoch: 1718, Training Loss = 0.8600157499313354\n","Epoch: 1719, Training Loss = 0.8599777817726135\n","Epoch: 1720, Training Loss = 0.8599398136138916\n","Accuracy =  0.6859189867973328 F1 weighted =  0.5774251818656921 F1 macro =  0.23212257027626038\n","Epoch: 1721, Training Loss = 0.859902024269104\n","Epoch: 1722, Training Loss = 0.859864354133606\n","Epoch: 1723, Training Loss = 0.8598266243934631\n","Epoch: 1724, Training Loss = 0.8597890138626099\n","Epoch: 1725, Training Loss = 0.8597514629364014\n","Epoch: 1726, Training Loss = 0.8597139120101929\n","Epoch: 1727, Training Loss = 0.8596765995025635\n","Epoch: 1728, Training Loss = 0.8596391081809998\n","Epoch: 1729, Training Loss = 0.8596019148826599\n","Epoch: 1730, Training Loss = 0.8595646619796753\n","Accuracy =  0.6859578490257263 F1 weighted =  0.5773853063583374 F1 macro =  0.23206007480621338\n","Epoch: 1731, Training Loss = 0.859527587890625\n","Epoch: 1732, Training Loss = 0.8594904541969299\n","Epoch: 1733, Training Loss = 0.8594534397125244\n","Epoch: 1734, Training Loss = 0.8594166040420532\n","Epoch: 1735, Training Loss = 0.8593795895576477\n","Epoch: 1736, Training Loss = 0.8593427538871765\n","Epoch: 1737, Training Loss = 0.8593059778213501\n","Epoch: 1738, Training Loss = 0.8592694401741028\n","Epoch: 1739, Training Loss = 0.8592328429222107\n","Epoch: 1740, Training Loss = 0.8591962456703186\n","Accuracy =  0.6859467625617981 F1 weighted =  0.5772785544395447 F1 macro =  0.23191170394420624\n","Epoch: 1741, Training Loss = 0.8591597676277161\n","Epoch: 1742, Training Loss = 0.8591234087944031\n","Epoch: 1743, Training Loss = 0.8590870499610901\n","Epoch: 1744, Training Loss = 0.8590507507324219\n","Epoch: 1745, Training Loss = 0.8590145111083984\n","Epoch: 1746, Training Loss = 0.8589783906936646\n","Epoch: 1747, Training Loss = 0.8589422702789307\n","Epoch: 1748, Training Loss = 0.8589062094688416\n","Epoch: 1749, Training Loss = 0.858870267868042\n","Epoch: 1750, Training Loss = 0.858834445476532\n","Accuracy =  0.6859356164932251 F1 weighted =  0.577155590057373 F1 macro =  0.23175466060638428\n","Epoch: 1751, Training Loss = 0.858798623085022\n","Epoch: 1752, Training Loss = 0.8587628602981567\n","Epoch: 1753, Training Loss = 0.8587271571159363\n","Epoch: 1754, Training Loss = 0.8586915731430054\n","Epoch: 1755, Training Loss = 0.8586559295654297\n","Epoch: 1756, Training Loss = 0.8586205244064331\n","Epoch: 1757, Training Loss = 0.8585850596427917\n","Epoch: 1758, Training Loss = 0.8585496544837952\n","Epoch: 1759, Training Loss = 0.8585143685340881\n","Epoch: 1760, Training Loss = 0.8584792017936707\n","Accuracy =  0.6859495043754578 F1 weighted =  0.577077329158783 F1 macro =  0.23163466155529022\n","Epoch: 1761, Training Loss = 0.8584439754486084\n","Epoch: 1762, Training Loss = 0.8584088683128357\n","Epoch: 1763, Training Loss = 0.8583738207817078\n","Epoch: 1764, Training Loss = 0.8583388328552246\n","Epoch: 1765, Training Loss = 0.8583039045333862\n","Epoch: 1766, Training Loss = 0.8582689166069031\n","Epoch: 1767, Training Loss = 0.8582342863082886\n","Epoch: 1768, Training Loss = 0.8581994771957397\n","Epoch: 1769, Training Loss = 0.8581647872924805\n","Epoch: 1770, Training Loss = 0.858130156993866\n","Accuracy =  0.6859439611434937 F1 weighted =  0.576984167098999 F1 macro =  0.23149530589580536\n","Epoch: 1771, Training Loss = 0.8580955862998962\n","Epoch: 1772, Training Loss = 0.8580610752105713\n","Epoch: 1773, Training Loss = 0.8580266833305359\n","Epoch: 1774, Training Loss = 0.8579923510551453\n","Epoch: 1775, Training Loss = 0.8579579591751099\n","Epoch: 1776, Training Loss = 0.8579238653182983\n","Epoch: 1777, Training Loss = 0.8578895330429077\n","Epoch: 1778, Training Loss = 0.857855498790741\n","Epoch: 1779, Training Loss = 0.8578213453292847\n","Epoch: 1780, Training Loss = 0.8577873706817627\n","Accuracy =  0.6859633922576904 F1 weighted =  0.5769340395927429 F1 macro =  0.2314186692237854\n","Epoch: 1781, Training Loss = 0.8577535152435303\n","Epoch: 1782, Training Loss = 0.8577196002006531\n","Epoch: 1783, Training Loss = 0.8576858043670654\n","Epoch: 1784, Training Loss = 0.857651948928833\n","Epoch: 1785, Training Loss = 0.8576182723045349\n","Epoch: 1786, Training Loss = 0.8575847148895264\n","Epoch: 1787, Training Loss = 0.857551097869873\n","Epoch: 1788, Training Loss = 0.8575176000595093\n","Epoch: 1789, Training Loss = 0.8574841022491455\n","Epoch: 1790, Training Loss = 0.8574506640434265\n","Accuracy =  0.6859633922576904 F1 weighted =  0.5768477916717529 F1 macro =  0.23129820823669434\n","Epoch: 1791, Training Loss = 0.8574173450469971\n","Epoch: 1792, Training Loss = 0.857384204864502\n","Epoch: 1793, Training Loss = 0.8573510050773621\n","Epoch: 1794, Training Loss = 0.8573177456855774\n","Epoch: 1795, Training Loss = 0.857284665107727\n","Epoch: 1796, Training Loss = 0.8572516441345215\n","Epoch: 1797, Training Loss = 0.8572186231613159\n","Epoch: 1798, Training Loss = 0.8571856617927551\n","Epoch: 1799, Training Loss = 0.8571528792381287\n","Epoch: 1800, Training Loss = 0.8571200966835022\n","Accuracy =  0.6859800815582275 F1 weighted =  0.576794445514679 F1 macro =  0.23120687901973724\n","Epoch: 1801, Training Loss = 0.8570873141288757\n","Epoch: 1802, Training Loss = 0.8570547103881836\n","Epoch: 1803, Training Loss = 0.8570219874382019\n","Epoch: 1804, Training Loss = 0.8569893836975098\n","Epoch: 1805, Training Loss = 0.8569568991661072\n","Epoch: 1806, Training Loss = 0.8569244742393494\n","Epoch: 1807, Training Loss = 0.8568921685218811\n","Epoch: 1808, Training Loss = 0.8568597435951233\n","Epoch: 1809, Training Loss = 0.8568274974822998\n","Epoch: 1810, Training Loss = 0.8567953109741211\n","Accuracy =  0.6859745383262634 F1 weighted =  0.5767220258712769 F1 macro =  0.23111224174499512\n","Epoch: 1811, Training Loss = 0.8567631244659424\n","Epoch: 1812, Training Loss = 0.8567309379577637\n","Epoch: 1813, Training Loss = 0.8566988706588745\n","Epoch: 1814, Training Loss = 0.8566669225692749\n","Epoch: 1815, Training Loss = 0.8566350340843201\n","Epoch: 1816, Training Loss = 0.8566030859947205\n","Epoch: 1817, Training Loss = 0.8565712571144104\n","Epoch: 1818, Training Loss = 0.8565395474433899\n","Epoch: 1819, Training Loss = 0.8565078377723694\n","Epoch: 1820, Training Loss = 0.8564761877059937\n","Accuracy =  0.6859689354896545 F1 weighted =  0.5766339302062988 F1 macro =  0.23098669946193695\n","Epoch: 1821, Training Loss = 0.8564445376396179\n","Epoch: 1822, Training Loss = 0.8564130067825317\n","Epoch: 1823, Training Loss = 0.8563814759254456\n","Epoch: 1824, Training Loss = 0.8563501834869385\n","Epoch: 1825, Training Loss = 0.8563188314437866\n","Epoch: 1826, Training Loss = 0.8562875390052795\n","Epoch: 1827, Training Loss = 0.8562562465667725\n","Epoch: 1828, Training Loss = 0.8562250137329102\n","Epoch: 1829, Training Loss = 0.8561939001083374\n","Epoch: 1830, Training Loss = 0.8561627268791199\n","Accuracy =  0.6859911680221558 F1 weighted =  0.576585054397583 F1 macro =  0.2309189885854721\n","Epoch: 1831, Training Loss = 0.8561316728591919\n","Epoch: 1832, Training Loss = 0.8561007380485535\n","Epoch: 1833, Training Loss = 0.856069803237915\n","Epoch: 1834, Training Loss = 0.8560389876365662\n","Epoch: 1835, Training Loss = 0.8560081124305725\n","Epoch: 1836, Training Loss = 0.8559773564338684\n","Epoch: 1837, Training Loss = 0.8559466004371643\n","Epoch: 1838, Training Loss = 0.8559159636497498\n","Epoch: 1839, Training Loss = 0.8558853268623352\n","Epoch: 1840, Training Loss = 0.8558548092842102\n","Accuracy =  0.686002254486084 F1 weighted =  0.5765166282653809 F1 macro =  0.23081421852111816\n","Epoch: 1841, Training Loss = 0.8558242917060852\n","Epoch: 1842, Training Loss = 0.855793833732605\n","Epoch: 1843, Training Loss = 0.8557634949684143\n","Epoch: 1844, Training Loss = 0.8557331562042236\n","Epoch: 1845, Training Loss = 0.8557029366493225\n","Epoch: 1846, Training Loss = 0.8556725978851318\n","Epoch: 1847, Training Loss = 0.8556424379348755\n","Epoch: 1848, Training Loss = 0.8556123375892639\n","Epoch: 1849, Training Loss = 0.8555822372436523\n","Epoch: 1850, Training Loss = 0.8555522561073303\n","Accuracy =  0.6860411763191223 F1 weighted =  0.5764771699905396 F1 macro =  0.23073363304138184\n","Epoch: 1851, Training Loss = 0.8555222749710083\n","Epoch: 1852, Training Loss = 0.855492353439331\n","Epoch: 1853, Training Loss = 0.8554625511169434\n","Epoch: 1854, Training Loss = 0.8554326295852661\n","Epoch: 1855, Training Loss = 0.8554030060768127\n","Epoch: 1856, Training Loss = 0.8553730845451355\n","Epoch: 1857, Training Loss = 0.8553435802459717\n","Epoch: 1858, Training Loss = 0.8553140163421631\n","Epoch: 1859, Training Loss = 0.8552845120429993\n","Epoch: 1860, Training Loss = 0.8552549481391907\n","Accuracy =  0.6860411763191223 F1 weighted =  0.5764229893684387 F1 macro =  0.23066586256027222\n","Epoch: 1861, Training Loss = 0.8552254438400269\n","Epoch: 1862, Training Loss = 0.8551961183547974\n","Epoch: 1863, Training Loss = 0.8551667928695679\n","Epoch: 1864, Training Loss = 0.8551374077796936\n","Epoch: 1865, Training Loss = 0.8551081418991089\n","Epoch: 1866, Training Loss = 0.8550790548324585\n","Epoch: 1867, Training Loss = 0.8550499677658081\n","Epoch: 1868, Training Loss = 0.8550207614898682\n","Epoch: 1869, Training Loss = 0.8549917340278625\n","Epoch: 1870, Training Loss = 0.8549628257751465\n","Accuracy =  0.686055064201355 F1 weighted =  0.576372504234314 F1 macro =  0.23057898879051208\n","Epoch: 1871, Training Loss = 0.8549339175224304\n","Epoch: 1872, Training Loss = 0.8549050688743591\n","Epoch: 1873, Training Loss = 0.8548762202262878\n","Epoch: 1874, Training Loss = 0.8548473715782166\n","Epoch: 1875, Training Loss = 0.8548187613487244\n","Epoch: 1876, Training Loss = 0.8547900319099426\n","Epoch: 1877, Training Loss = 0.8547613024711609\n","Epoch: 1878, Training Loss = 0.8547328114509583\n","Epoch: 1879, Training Loss = 0.8547042012214661\n","Epoch: 1880, Training Loss = 0.854675829410553\n","Accuracy =  0.686043918132782 F1 weighted =  0.5763070583343506 F1 macro =  0.23048532009124756\n","Epoch: 1881, Training Loss = 0.8546473383903503\n","Epoch: 1882, Training Loss = 0.8546189665794373\n","Epoch: 1883, Training Loss = 0.8545907139778137\n","Epoch: 1884, Training Loss = 0.8545624017715454\n","Epoch: 1885, Training Loss = 0.8545342087745667\n","Epoch: 1886, Training Loss = 0.8545059561729431\n","Epoch: 1887, Training Loss = 0.8544779419898987\n","Epoch: 1888, Training Loss = 0.8544497489929199\n","Epoch: 1889, Training Loss = 0.8544217348098755\n","Epoch: 1890, Training Loss = 0.8543936610221863\n","Accuracy =  0.6860606074333191 F1 weighted =  0.5762276649475098 F1 macro =  0.23036818206310272\n","Epoch: 1891, Training Loss = 0.8543657660484314\n","Epoch: 1892, Training Loss = 0.8543379306793213\n","Epoch: 1893, Training Loss = 0.8543100357055664\n","Epoch: 1894, Training Loss = 0.8542822003364563\n","Epoch: 1895, Training Loss = 0.8542546033859253\n","Epoch: 1896, Training Loss = 0.85422682762146\n","Epoch: 1897, Training Loss = 0.8541991710662842\n","Epoch: 1898, Training Loss = 0.8541715741157532\n","Epoch: 1899, Training Loss = 0.8541440367698669\n","Epoch: 1900, Training Loss = 0.8541165590286255\n","Accuracy =  0.6860688924789429 F1 weighted =  0.5761873722076416 F1 macro =  0.2303137183189392\n","Epoch: 1901, Training Loss = 0.8540890216827393\n","Epoch: 1902, Training Loss = 0.8540616631507874\n","Epoch: 1903, Training Loss = 0.8540343046188354\n","Epoch: 1904, Training Loss = 0.8540070056915283\n","Epoch: 1905, Training Loss = 0.8539797067642212\n","Epoch: 1906, Training Loss = 0.8539524674415588\n","Epoch: 1907, Training Loss = 0.853925347328186\n","Epoch: 1908, Training Loss = 0.8538981676101685\n","Epoch: 1909, Training Loss = 0.8538711071014404\n","Epoch: 1910, Training Loss = 0.853844165802002\n","Accuracy =  0.6860744953155518 F1 weighted =  0.5761353969573975 F1 macro =  0.23024706542491913\n","Epoch: 1911, Training Loss = 0.8538171648979187\n","Epoch: 1912, Training Loss = 0.8537901639938354\n","Epoch: 1913, Training Loss = 0.8537633419036865\n","Epoch: 1914, Training Loss = 0.8537365794181824\n","Epoch: 1915, Training Loss = 0.8537096977233887\n","Epoch: 1916, Training Loss = 0.8536828756332397\n","Epoch: 1917, Training Loss = 0.8536562323570251\n","Epoch: 1918, Training Loss = 0.8536295294761658\n","Epoch: 1919, Training Loss = 0.8536028861999512\n","Epoch: 1920, Training Loss = 0.8535763621330261\n","Accuracy =  0.6860911250114441 F1 weighted =  0.5760666728019714 F1 macro =  0.23013773560523987\n","Epoch: 1921, Training Loss = 0.8535498380661011\n","Epoch: 1922, Training Loss = 0.8535233736038208\n","Epoch: 1923, Training Loss = 0.8534969091415405\n","Epoch: 1924, Training Loss = 0.853470504283905\n","Epoch: 1925, Training Loss = 0.8534442186355591\n","Epoch: 1926, Training Loss = 0.8534179925918579\n","Epoch: 1927, Training Loss = 0.8533917665481567\n","Epoch: 1928, Training Loss = 0.8533654808998108\n","Epoch: 1929, Training Loss = 0.8533393144607544\n","Epoch: 1930, Training Loss = 0.8533132672309875\n","Accuracy =  0.686116099357605 F1 weighted =  0.5760135650634766 F1 macro =  0.23005571961402893\n","Epoch: 1931, Training Loss = 0.8532872200012207\n","Epoch: 1932, Training Loss = 0.8532610535621643\n","Epoch: 1933, Training Loss = 0.853235125541687\n","Epoch: 1934, Training Loss = 0.8532092571258545\n","Epoch: 1935, Training Loss = 0.8531833291053772\n","Epoch: 1936, Training Loss = 0.8531575202941895\n","Epoch: 1937, Training Loss = 0.8531317114830017\n","Epoch: 1938, Training Loss = 0.8531059622764587\n","Epoch: 1939, Training Loss = 0.8530802130699158\n","Epoch: 1940, Training Loss = 0.8530546426773071\n","Accuracy =  0.6861244440078735 F1 weighted =  0.5759498476982117 F1 macro =  0.229964017868042\n","Epoch: 1941, Training Loss = 0.8530289530754089\n","Epoch: 1942, Training Loss = 0.8530033826828003\n","Epoch: 1943, Training Loss = 0.8529778122901917\n","Epoch: 1944, Training Loss = 0.8529523015022278\n","Epoch: 1945, Training Loss = 0.8529268503189087\n","Epoch: 1946, Training Loss = 0.8529015779495239\n","Epoch: 1947, Training Loss = 0.8528761863708496\n","Epoch: 1948, Training Loss = 0.8528508543968201\n","Epoch: 1949, Training Loss = 0.8528256416320801\n","Epoch: 1950, Training Loss = 0.8528003692626953\n","Accuracy =  0.6861494183540344 F1 weighted =  0.5759173035621643 F1 macro =  0.2299100011587143\n","Epoch: 1951, Training Loss = 0.8527752161026001\n","Epoch: 1952, Training Loss = 0.8527500629425049\n","Epoch: 1953, Training Loss = 0.8527249097824097\n","Epoch: 1954, Training Loss = 0.8526999354362488\n","Epoch: 1955, Training Loss = 0.8526749014854431\n","Epoch: 1956, Training Loss = 0.8526499271392822\n","Epoch: 1957, Training Loss = 0.8526250123977661\n","Epoch: 1958, Training Loss = 0.85260009765625\n","Epoch: 1959, Training Loss = 0.8525751233100891\n","Epoch: 1960, Training Loss = 0.8525503873825073\n","Accuracy =  0.6861605644226074 F1 weighted =  0.5758688449859619 F1 macro =  0.22982758283615112\n","Epoch: 1961, Training Loss = 0.8525257110595703\n","Epoch: 1962, Training Loss = 0.8525009751319885\n","Epoch: 1963, Training Loss = 0.8524764180183411\n","Epoch: 1964, Training Loss = 0.8524516224861145\n","Epoch: 1965, Training Loss = 0.852427065372467\n","Epoch: 1966, Training Loss = 0.8524025082588196\n","Epoch: 1967, Training Loss = 0.8523779511451721\n","Epoch: 1968, Training Loss = 0.852353572845459\n","Epoch: 1969, Training Loss = 0.8523290157318115\n","Epoch: 1970, Training Loss = 0.8523046970367432\n","Accuracy =  0.6861744523048401 F1 weighted =  0.5758286118507385 F1 macro =  0.22978243231773376\n","Epoch: 1971, Training Loss = 0.8522804379463196\n","Epoch: 1972, Training Loss = 0.8522560000419617\n","Epoch: 1973, Training Loss = 0.8522318005561829\n","Epoch: 1974, Training Loss = 0.8522076606750488\n","Epoch: 1975, Training Loss = 0.8521834015846252\n","Epoch: 1976, Training Loss = 0.852159321308136\n","Epoch: 1977, Training Loss = 0.852135181427002\n","Epoch: 1978, Training Loss = 0.8521111011505127\n","Epoch: 1979, Training Loss = 0.852087140083313\n","Epoch: 1980, Training Loss = 0.8520631194114685\n","Accuracy =  0.6861799955368042 F1 weighted =  0.5757860541343689 F1 macro =  0.2297269105911255\n","Epoch: 1981, Training Loss = 0.8520392179489136\n","Epoch: 1982, Training Loss = 0.8520152568817139\n","Epoch: 1983, Training Loss = 0.8519914150238037\n","Epoch: 1984, Training Loss = 0.8519675731658936\n","Epoch: 1985, Training Loss = 0.8519437909126282\n","Epoch: 1986, Training Loss = 0.8519200682640076\n","Epoch: 1987, Training Loss = 0.8518964052200317\n","Epoch: 1988, Training Loss = 0.8518728017807007\n","Epoch: 1989, Training Loss = 0.8518491983413696\n","Epoch: 1990, Training Loss = 0.8518256545066833\n","Accuracy =  0.6861855387687683 F1 weighted =  0.5757330656051636 F1 macro =  0.22965973615646362\n","Epoch: 1991, Training Loss = 0.8518021106719971\n","Epoch: 1992, Training Loss = 0.8517786264419556\n","Epoch: 1993, Training Loss = 0.8517550826072693\n","Epoch: 1994, Training Loss = 0.8517317771911621\n","Epoch: 1995, Training Loss = 0.8517083525657654\n","Epoch: 1996, Training Loss = 0.8516849875450134\n","Epoch: 1997, Training Loss = 0.8516616821289062\n","Epoch: 1998, Training Loss = 0.8516384363174438\n","Epoch: 1999, Training Loss = 0.8516151309013367\n"]}],"source":["from torchmetrics import F1Score, Accuracy\n","\n","model = Model(88, 176, 88, qp_graph.etypes)\n","query_feats = qp_graph.nodes['query'].data['embed']\n","product_feats = qp_graph.nodes['product'].data['embed']\n","node_features = {'query': query_feats, 'product': product_feats}\n","\n","acc_list = []\n","f1_w = []\n","f1_m = []\n","\n","opt = torch.optim.Adam(model.parameters(), lr=0.001)\n","for epoch in range(2000):\n","    model.train()\n","    logits = model(qp_graph, node_features, dec_graph)\n","    loss = F.cross_entropy(logits[train_mask], edge_label[train_mask])\n","    opt.zero_grad()\n","    loss.backward()\n","    opt.step()\n","    print(f\"Epoch: {epoch}, Training Loss = {loss.item()}\")\n","\n","    if epoch % 10 == 0:\n","      model.eval()\n","      with torch.no_grad():\n","          logits = model(qp_graph, node_features, dec_graph)\n","          logits = logits[val_mask]\n","          labels = edge_label[val_mask]\n","          _, indices = torch.max(logits, dim=1)\n","          correct = torch.sum(indices == labels)\n","          f1 = F1Score(num_classes=4, average = 'weighted')\n","          f1_weighted = f1(indices, labels)\n","          f1 = F1Score(num_classes=4, average = 'macro')\n","          f1_macro = f1(indices, labels)\n","          accuracy = Accuracy()\n","          acc = accuracy(indices, labels)\n","          acc_list.append(acc.item())\n","          f1_w.append(f1_weighted.item())\n","          f1_m.append(f1_macro.item())\n","          print(\"Accuracy = \", acc.item(), \"F1 weighted = \", f1_weighted.item(), \"F1 macro = \", f1_macro.item())"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1651919311849,"user":{"displayName":"Vivian Huang","userId":"04275850260165431564"},"user_tz":300},"id":"l5Y338-zd3qu","outputId":"1c35de7e-a537-4108-86d5-789be2d4b703"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 864x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.rcParams[\"figure.figsize\"] = (12,8)\n","plt.plot(list(range(200)), acc_list, label=\"Accuracy\")\n","plt.plot(list(range(200)), f1_w, label=\"F1 Weighted\")\n","plt.plot(list(range(200)), f1_m, label=\"F1 Macro\")\n","plt.legend(loc=\"lower right\")\n","plt.title(\"GNN Training Detail\")\n","plt.xlabel(\"epoches (*10)\")\n","plt.xticks(np.arange(0, 200, 10))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fvYLhhIqV-76"},"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"31-heteograph-approach-88D.ipynb","provenance":[{"file_id":"1wOHKWuVK01UvCgY1qm2g8t8_cYwQS_D-","timestamp":1651888980171}],"authorship_tag":"ABX9TyOAN8RzAJAuPk7Me3SFoPdM"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}